nohup: ignoring input
jobs/environment.sh: line 1: module: command not found
jobs/environment.sh: line 2: module: command not found
jobs/environment.sh: line 3: module: command not found
jobs/environment.sh: line 5: cd: /root/fast_robust_early_exit: No such file or directory
usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...
conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'build', 'content-trust', 'convert', 'debug', 'develop', 'doctor', 'index', 'inspect', 'metapackage', 'render', 'skeleton', 'env')
Requirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.30.1)
Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.0)
Requirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.19.1)
Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.2.0)
Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.20.1)
Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.4.2)
Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.5.0)
Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.1.2)
Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (3.8.1)
Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.21.0)
Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.4.2)
Requirement already satisfied: transformers==4.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (4.28.1)
Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.9.0)
Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.11.1)
Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (3.13.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (0.23.1)
Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (1.26.3)
Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (2024.5.15)
Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (2.31.0)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (0.13.3)
Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 12)) (4.65.0)
Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (5.9.0)
Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (0.4.3)
Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->-r requirements.txt (line 2)) (4.9.0)
Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->-r requirements.txt (line 2)) (1.12)
Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->-r requirements.txt (line 2)) (3.1)
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->-r requirements.txt (line 2)) (3.1.2)
Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->-r requirements.txt (line 2)) (2023.12.2)
Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.8)
Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.2.2)
Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.4.1)
Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.16)
Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.9.5)
Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.13.1)
Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.4.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.5.0)
Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score->-r requirements.txt (line 8)) (2.1.0)
Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score->-r requirements.txt (line 8)) (1.16.0)
Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 9)) (8.1.7)
Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.7.0)
Requirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (3.20.0)
Requirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (0.16.0)
Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.1.0)
Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.0.2)
Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (0.2.3)
Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.0.0)
Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.1.0)
Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 11)) (2.8.2)
Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 11)) (0.9.0)
Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 11)) (0.4.6)
Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 11)) (5.2.2)
Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (1.2.1)
Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (4.51.0)
Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (1.4.5)
Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (10.0.1)
Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (3.1.2)
Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (2.9.0.post0)
Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (23.1.0)
Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.9.4)
Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (4.0.3)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 12)) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 12)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 12)) (1.26.18)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 12)) (2023.11.17)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->-r requirements.txt (line 2)) (2.1.3)
Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2023.3.post1)
Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2024.1)
Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->-r requirements.txt (line 2)) (1.3.0)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 05:18:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 05:18:07 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_05-18-07_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Generating dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 05:18:13 - INFO - datasets.builder - Generating dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Downloading and preparing dataset cnn_dailymail/3.0.0 to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d...
05/24/2024 05:18:13 - INFO - datasets.builder - Downloading and preparing dataset cnn_dailymail/3.0.0 to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d...
hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00001-of-00003.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843.incomplete
05/24/2024 05:18:14 - INFO - datasets.utils.file_utils - hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00001-of-00003.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843.incomplete
Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]Downloading data:   4%|▍         | 10.5M/257M [00:01<00:32, 7.63MB/s]Downloading data:   8%|▊         | 21.0M/257M [00:01<00:15, 15.3MB/s]Downloading data:  12%|█▏        | 31.5M/257M [00:01<00:09, 23.4MB/s]Downloading data:  16%|█▋        | 41.9M/257M [00:01<00:07, 30.1MB/s]Downloading data:  20%|██        | 52.4M/257M [00:02<00:05, 36.9MB/s]Downloading data:  25%|██▍       | 62.9M/257M [00:02<00:04, 41.0MB/s]Downloading data:  29%|██▊       | 73.4M/257M [00:02<00:04, 44.1MB/s]Downloading data:  33%|███▎      | 83.9M/257M [00:02<00:03, 44.0MB/s]Downloading data:  37%|███▋      | 94.4M/257M [00:02<00:03, 46.3MB/s]Downloading data:  41%|████      | 105M/257M [00:03<00:02, 50.9MB/s] Downloading data:  45%|████▍     | 115M/257M [00:03<00:02, 50.5MB/s]Downloading data:  49%|████▉     | 126M/257M [00:03<00:02, 53.5MB/s]Downloading data:  53%|█████▎    | 136M/257M [00:03<00:02, 53.9MB/s]Downloading data:  57%|█████▋    | 147M/257M [00:03<00:02, 53.3MB/s]Downloading data:  61%|██████▏   | 157M/257M [00:04<00:01, 55.5MB/s]Downloading data:  65%|██████▌   | 168M/257M [00:04<00:01, 55.0MB/s]Downloading data:  69%|██████▉   | 178M/257M [00:04<00:01, 54.4MB/s]Downloading data:  74%|███████▎  | 189M/257M [00:04<00:01, 55.2MB/s]Downloading data:  78%|███████▊  | 199M/257M [00:04<00:01, 55.8MB/s]Downloading data:  82%|████████▏ | 210M/257M [00:04<00:00, 56.7MB/s]Downloading data:  86%|████████▌ | 220M/257M [00:05<00:00, 55.0MB/s]Downloading data:  90%|████████▉ | 231M/257M [00:05<00:00, 55.7MB/s]Downloading data:  94%|█████████▍| 241M/257M [00:05<00:00, 56.6MB/s]Downloading data:  98%|█████████▊| 252M/257M [00:05<00:00, 56.3MB/s]Downloading data: 100%|██████████| 257M/257M [00:05<00:00, 43.9MB/s]
storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00001-of-00003.parquet in cache at /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843
05/24/2024 05:18:20 - INFO - datasets.utils.file_utils - storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00001-of-00003.parquet in cache at /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843
creating metadata file for /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843
05/24/2024 05:18:20 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/ef33d63f5582f0bd54d0a6a13e232aa0e6c1a45c269124467f3cb322e35b4843
hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00002-of-00003.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451.incomplete
05/24/2024 05:18:20 - INFO - datasets.utils.file_utils - hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00002-of-00003.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451.incomplete
Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]Downloading data:   4%|▍         | 10.5M/259M [00:00<00:16, 15.4MB/s]Downloading data:   8%|▊         | 21.0M/259M [00:00<00:07, 30.1MB/s]Downloading data:  12%|█▏        | 31.5M/259M [00:00<00:05, 43.2MB/s]Downloading data:  16%|█▌        | 41.9M/259M [00:01<00:03, 54.8MB/s]Downloading data:  20%|██        | 52.4M/259M [00:01<00:03, 64.1MB/s]Downloading data:  24%|██▍       | 62.9M/259M [00:01<00:02, 71.7MB/s]Downloading data:  28%|██▊       | 73.4M/259M [00:01<00:02, 77.2MB/s]Downloading data:  32%|███▏      | 83.9M/259M [00:01<00:02, 81.4MB/s]Downloading data:  36%|███▋      | 94.4M/259M [00:01<00:01, 84.6MB/s]Downloading data:  40%|████      | 105M/259M [00:01<00:01, 87.1MB/s] Downloading data:  44%|████▍     | 115M/259M [00:01<00:01, 88.9MB/s]Downloading data:  49%|████▊     | 126M/259M [00:01<00:01, 90.0MB/s]Downloading data:  53%|█████▎    | 136M/259M [00:02<00:01, 90.5MB/s]Downloading data:  57%|█████▋    | 147M/259M [00:02<00:01, 91.1MB/s]Downloading data:  61%|██████    | 157M/259M [00:02<00:01, 91.5MB/s]Downloading data:  65%|██████▍   | 168M/259M [00:02<00:00, 91.9MB/s]Downloading data:  69%|██████▊   | 178M/259M [00:02<00:00, 91.8MB/s]Downloading data:  73%|███████▎  | 189M/259M [00:02<00:00, 92.0MB/s]Downloading data:  77%|███████▋  | 199M/259M [00:02<00:00, 92.2MB/s]Downloading data:  81%|████████  | 210M/259M [00:02<00:00, 92.1MB/s]Downloading data:  85%|████████▍ | 220M/259M [00:02<00:00, 92.4MB/s]Downloading data:  89%|████████▉ | 231M/259M [00:03<00:00, 92.4MB/s]Downloading data:  93%|█████████▎| 241M/259M [00:03<00:00, 92.2MB/s]Downloading data:  97%|█████████▋| 252M/259M [00:03<00:00, 92.4MB/s]Downloading data: 100%|██████████| 259M/259M [00:03<00:00, 76.7MB/s]
storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00002-of-00003.parquet in cache at /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451
05/24/2024 05:18:23 - INFO - datasets.utils.file_utils - storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/train-00002-of-00003.parquet in cache at /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451
creating metadata file for /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451
05/24/2024 05:18:23 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/8ac10e1020ed8dd15b4bcc9bc2bf77f292b5144ad3a018ba76a7c8d333f75451
hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/validation-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1.incomplete
05/24/2024 05:18:24 - INFO - datasets.utils.file_utils - hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/validation-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1.incomplete
Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]Downloading data:  30%|███       | 10.5M/34.7M [00:00<00:01, 15.1MB/s]Downloading data:  60%|██████    | 21.0M/34.7M [00:00<00:00, 29.8MB/s]Downloading data:  91%|█████████ | 31.5M/34.7M [00:00<00:00, 43.1MB/s]Downloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 36.1MB/s]
storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/validation-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1
05/24/2024 05:18:25 - INFO - datasets.utils.file_utils - storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/validation-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1
creating metadata file for /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1
05/24/2024 05:18:25 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/a03efbf4e32e88e09a04d2905e38f50d3a2262ce6ceee7ddc88f174d8de958f1
hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae.incomplete
05/24/2024 05:18:25 - INFO - datasets.utils.file_utils - hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae.incomplete
Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]Downloading data:  35%|███▍      | 10.5M/30.0M [00:00<00:01, 11.3MB/s]Downloading data:  70%|██████▉   | 21.0M/30.0M [00:01<00:00, 23.3MB/s]Downloading data: 100%|██████████| 30.0M/30.0M [00:01<00:00, 26.2MB/s]
storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/test-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae
05/24/2024 05:18:27 - INFO - datasets.utils.file_utils - storing hf://datasets/cnn_dailymail@96df5e686bee6baa90b8bee7c28b81fa3fa6223d/3.0.0/test-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae
creating metadata file for /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae
05/24/2024 05:18:27 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/b3f3332f654d3da6b150ec6cfea52d602a0f78b5146beb93fb888399476c92ae
Downloading took 0.0 min
05/24/2024 05:18:27 - INFO - datasets.download.download_manager - Downloading took 0.0 min
Checksum Computation took 0.0 min
05/24/2024 05:18:27 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
Generating train split
05/24/2024 05:18:27 - INFO - datasets.builder - Generating train split
Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]Generating train split:   2%|▏         | 7000/287113 [00:00<00:04, 59411.45 examples/s]Generating train split:   5%|▌         | 15000/287113 [00:00<00:04, 66066.54 examples/s]Generating train split:   8%|▊         | 23000/287113 [00:00<00:04, 65940.14 examples/s]Generating train split:  11%|█         | 31000/287113 [00:00<00:03, 64684.51 examples/s]Generating train split:  13%|█▎        | 38000/287113 [00:00<00:03, 63164.47 examples/s]Generating train split:  16%|█▌        | 45000/287113 [00:00<00:03, 61902.48 examples/s]Generating train split:  18%|█▊        | 52000/287113 [00:00<00:03, 61157.02 examples/s]Generating train split:  21%|██        | 59000/287113 [00:00<00:03, 60038.99 examples/s]Generating train split:  24%|██▎       | 68000/287113 [00:01<00:03, 56299.59 examples/s]Generating train split:  26%|██▌       | 75000/287113 [00:01<00:03, 55745.40 examples/s]Generating train split:  29%|██▊       | 82000/287113 [00:01<00:03, 56623.23 examples/s]Generating train split:  31%|███       | 89000/287113 [00:01<00:03, 58568.31 examples/s]Generating train split:  33%|███▎      | 95000/287113 [00:01<00:03, 58234.71 examples/s]Generating train split:  36%|███▌      | 102705/287113 [00:01<00:03, 59637.00 examples/s]Generating train split:  38%|███▊      | 109705/287113 [00:01<00:02, 61436.27 examples/s]Generating train split:  41%|████      | 117705/287113 [00:01<00:02, 64494.42 examples/s]Generating train split:  43%|████▎     | 124705/287113 [00:02<00:02, 65422.94 examples/s]Generating train split:  46%|████▌     | 132705/287113 [00:02<00:02, 65039.44 examples/s]Generating train split:  49%|████▉     | 140705/287113 [00:02<00:02, 65921.32 examples/s]Generating train split:  51%|█████▏    | 147705/287113 [00:02<00:02, 66950.87 examples/s]Generating train split:  54%|█████▍    | 154705/287113 [00:02<00:02, 65213.73 examples/s]Generating train split:  57%|█████▋    | 162705/287113 [00:02<00:01, 66514.42 examples/s]Generating train split:  59%|█████▉    | 170705/287113 [00:02<00:01, 68164.75 examples/s]Generating train split:  62%|██████▏   | 178705/287113 [00:02<00:01, 67343.45 examples/s]Generating train split:  65%|██████▌   | 186705/287113 [00:02<00:01, 68792.20 examples/s]Generating train split:  68%|██████▊   | 194409/287113 [00:03<00:01, 68263.88 examples/s]Generating train split:  70%|███████   | 202409/287113 [00:03<00:01, 68395.40 examples/s]Generating train split:  74%|███████▎  | 211409/287113 [00:03<00:01, 70753.83 examples/s]Generating train split:  76%|███████▋  | 219409/287113 [00:03<00:00, 71488.54 examples/s]Generating train split:  79%|███████▉  | 227409/287113 [00:03<00:00, 70051.69 examples/s]Generating train split:  82%|████████▏ | 235409/287113 [00:03<00:00, 67955.85 examples/s]Generating train split:  84%|████████▍ | 242409/287113 [00:03<00:00, 66030.15 examples/s]Generating train split:  87%|████████▋ | 249409/287113 [00:03<00:00, 64437.00 examples/s]Generating train split:  89%|████████▉ | 256409/287113 [00:03<00:00, 63286.46 examples/s]Generating train split:  92%|█████████▏| 264409/287113 [00:04<00:00, 64299.16 examples/s]Generating train split:  95%|█████████▍| 272409/287113 [00:04<00:00, 65053.57 examples/s]Generating train split:  98%|█████████▊| 280409/287113 [00:04<00:00, 65486.63 examples/s]Generating train split: 100%|██████████| 287113/287113 [00:04<00:00, 64738.71 examples/s]Generating train split: 100%|██████████| 287113/287113 [00:04<00:00, 64276.35 examples/s]
Generating validation split
05/24/2024 05:18:31 - INFO - datasets.builder - Generating validation split
Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]Generating validation split:  52%|█████▏    | 7000/13368 [00:00<00:00, 64036.85 examples/s]Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 63547.25 examples/s]
Generating test split
05/24/2024 05:18:31 - INFO - datasets.builder - Generating test split
Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]Generating test split:  61%|██████    | 7000/11490 [00:00<00:00, 63085.25 examples/s]Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 57221.81 examples/s]
All the splits matched successfully.
05/24/2024 05:18:31 - INFO - datasets.utils.info_utils - All the splits matched successfully.
Dataset cnn_dailymail downloaded and prepared to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d. Subsequent calls will reuse this data.
05/24/2024 05:18:31 - INFO - datasets.builder - Dataset cnn_dailymail downloaded and prepared to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d. Subsequent calls will reuse this data.
[INFO|configuration_utils.py:666] 2024-05-24 05:18:31,949 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:18:31,951 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 05:18:32,068 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 05:18:32,187 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:18:32,189 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:18:32,439 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:18:32,439 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:18:32,439 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:18:32,439 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:18:32,439 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 05:18:32,439 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:18:32,441 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 05:18:32,486 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 05:18:33,784 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 05:19:00,101 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[INFO|modeling_utils.py:3198] 2024-05-24 05:19:00,102 >> All the weights of EffT5ForConditionalGeneration were initialized from the model checkpoint at checkpoints/CNNDM.
If your task is similar to the task the model of the checkpoint was trained on, you can already use EffT5ForConditionalGeneration for predictions without further training.
[INFO|modeling_utils.py:2839] 2024-05-24 05:19:00,111 >> Generation config file not found, using a generation config created from the model config.
Caching indices mapping at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 05:19:00 - INFO - datasets.arrow_dataset - Caching indices mapping at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Running tokenizer on validation dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-1bf096f2d803ecd2.arrow
05/24/2024 05:19:01 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-1bf096f2d803ecd2.arrow
Running tokenizer on validation dataset:  33%|███▎      | 1000/3000 [00:00<00:01, 1270.02 examples/s]Running tokenizer on validation dataset:  67%|██████▋   | 2000/3000 [00:01<00:00, 1278.64 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1296.50 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1285.77 examples/s]
Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<00:00, 18.7MB/s]
05/24/2024 05:19:04 - INFO - __main__ - *** Evaluate ***
[WARNING|logging.py:280] 2024-05-24 05:19:04,304 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[INFO|configuration_utils.py:575] 2024-05-24 05:19:04,313 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:15<11:27,  7.55s/it]  3%|▎         | 3/93 [00:29<15:52, 10.58s/it]  4%|▍         | 4/93 [00:43<17:32, 11.82s/it]  5%|▌         | 5/93 [00:59<19:20, 13.19s/it]  6%|▋         | 6/93 [01:15<20:21, 14.04s/it]  8%|▊         | 7/93 [01:30<20:29, 14.30s/it]  9%|▊         | 8/93 [01:44<20:20, 14.36s/it] 10%|▉         | 9/93 [02:00<20:40, 14.77s/it] 11%|█         | 10/93 [02:16<20:49, 15.06s/it] 12%|█▏        | 11/93 [02:31<20:50, 15.25s/it] 13%|█▎        | 12/93 [02:47<20:45, 15.38s/it] 14%|█▍        | 13/93 [03:02<20:11, 15.14s/it] 15%|█▌        | 14/93 [03:15<19:10, 14.56s/it] 16%|█▌        | 15/93 [03:30<19:22, 14.90s/it] 17%|█▋        | 16/93 [03:44<18:34, 14.47s/it] 18%|█▊        | 17/93 [04:00<18:48, 14.85s/it] 19%|█▉        | 18/93 [04:14<18:32, 14.83s/it] 20%|██        | 19/93 [04:29<18:14, 14.79s/it] 22%|██▏       | 20/93 [04:44<18:07, 14.90s/it] 23%|██▎       | 21/93 [04:59<17:40, 14.72s/it] 24%|██▎       | 22/93 [05:13<17:12, 14.54s/it] 25%|██▍       | 23/93 [05:28<17:20, 14.86s/it] 26%|██▌       | 24/93 [05:44<17:23, 15.13s/it] 27%|██▋       | 25/93 [06:00<17:16, 15.25s/it] 28%|██▊       | 26/93 [06:15<17:10, 15.38s/it] 29%|██▉       | 27/93 [06:31<17:01, 15.48s/it] 30%|███       | 28/93 [06:47<16:50, 15.55s/it] 31%|███       | 29/93 [07:02<16:39, 15.62s/it] 32%|███▏      | 30/93 [07:18<16:26, 15.65s/it] 33%|███▎      | 31/93 [07:34<16:08, 15.62s/it] 34%|███▍      | 32/93 [07:47<15:17, 15.04s/it] 35%|███▌      | 33/93 [08:03<15:15, 15.25s/it] 37%|███▋      | 34/93 [08:18<14:49, 15.08s/it] 38%|███▊      | 35/93 [08:32<14:16, 14.78s/it] 39%|███▊      | 36/93 [08:48<14:18, 15.06s/it] 40%|███▉      | 37/93 [09:03<14:14, 15.26s/it] 41%|████      | 38/93 [09:19<14:06, 15.39s/it] 42%|████▏     | 39/93 [09:33<13:29, 14.99s/it] 43%|████▎     | 40/93 [09:48<13:18, 15.07s/it] 44%|████▍     | 41/93 [10:04<13:13, 15.26s/it] 45%|████▌     | 42/93 [10:15<11:58, 14.09s/it] 46%|████▌     | 43/93 [10:31<12:09, 14.59s/it] 47%|████▋     | 44/93 [10:46<11:58, 14.67s/it] 48%|████▊     | 45/93 [11:02<11:59, 14.98s/it] 49%|████▉     | 46/93 [11:16<11:32, 14.72s/it] 51%|█████     | 47/93 [11:32<11:31, 15.03s/it] 52%|█████▏    | 48/93 [11:47<11:25, 15.24s/it] 53%|█████▎    | 49/93 [12:03<11:17, 15.39s/it] 54%|█████▍    | 50/93 [12:16<10:30, 14.66s/it] 55%|█████▍    | 51/93 [12:30<10:03, 14.38s/it] 56%|█████▌    | 52/93 [12:45<10:05, 14.76s/it] 57%|█████▋    | 53/93 [13:01<10:03, 15.08s/it] 58%|█████▊    | 54/93 [13:16<09:46, 15.04s/it] 59%|█████▉    | 55/93 [13:32<09:36, 15.17s/it] 60%|██████    | 56/93 [13:47<09:27, 15.33s/it] 61%|██████▏   | 57/93 [14:03<09:16, 15.46s/it] 62%|██████▏   | 58/93 [14:19<09:03, 15.54s/it] 63%|██████▎   | 59/93 [14:32<08:28, 14.94s/it] 65%|██████▍   | 60/93 [14:48<08:21, 15.20s/it] 66%|██████▌   | 61/93 [15:04<08:12, 15.38s/it] 67%|██████▋   | 62/93 [15:20<07:59, 15.47s/it] 68%|██████▊   | 63/93 [15:35<07:46, 15.55s/it] 69%|██████▉   | 64/93 [15:49<07:17, 15.10s/it] 70%|██████▉   | 65/93 [16:05<07:07, 15.26s/it] 71%|███████   | 66/93 [16:21<06:55, 15.40s/it] 72%|███████▏  | 67/93 [16:37<06:42, 15.49s/it] 73%|███████▎  | 68/93 [16:52<06:28, 15.54s/it] 74%|███████▍  | 69/93 [17:06<05:58, 14.95s/it] 75%|███████▌  | 70/93 [17:21<05:48, 15.17s/it] 76%|███████▋  | 71/93 [17:37<05:36, 15.30s/it] 77%|███████▋  | 72/93 [17:52<05:18, 15.16s/it] 78%|███████▊  | 73/93 [18:06<04:58, 14.91s/it] 80%|███████▉  | 74/93 [18:20<04:39, 14.70s/it] 81%|████████  | 75/93 [18:36<04:30, 15.04s/it] 82%|████████▏ | 76/93 [18:52<04:19, 15.26s/it] 83%|████████▎ | 77/93 [19:08<04:06, 15.41s/it] 84%|████████▍ | 78/93 [19:21<03:41, 14.76s/it] 85%|████████▍ | 79/93 [19:37<03:31, 15.08s/it] 86%|████████▌ | 80/93 [19:51<03:12, 14.82s/it] 87%|████████▋ | 81/93 [20:07<03:01, 15.09s/it] 88%|████████▊ | 82/93 [20:23<02:48, 15.29s/it] 89%|████████▉ | 83/93 [20:37<02:30, 15.02s/it] 90%|█████████ | 84/93 [20:53<02:16, 15.22s/it] 91%|█████████▏| 85/93 [21:08<02:03, 15.38s/it] 92%|█████████▏| 86/93 [21:21<01:41, 14.53s/it] 94%|█████████▎| 87/93 [21:36<01:27, 14.61s/it] 95%|█████████▍| 88/93 [21:51<01:13, 14.74s/it] 96%|█████████▌| 89/93 [22:06<01:00, 15.03s/it] 97%|█████████▋| 90/93 [22:22<00:45, 15.23s/it] 98%|█████████▊| 91/93 [22:37<00:30, 15.12s/it] 99%|█████████▉| 92/93 [22:51<00:14, 14.79s/it]100%|██████████| 93/93 [23:07<00:00, 15.07s/it]100%|██████████| 93/93 [23:24<00:00, 15.10s/it]
***** eval metrics *****
  eval_block_avg          =        0.0
  eval_gen_len            =    70.5521
  eval_loss               =     1.4048
  eval_rouge1             =    43.7501
  eval_rouge2             =    21.1161
  eval_rougeL             =    31.3872
  eval_rougeLsum          =    40.9628
  eval_runtime            = 0:23:40.84
  eval_samples            =       3000
  eval_samples_per_second =      2.111
  eval_steps_per_second   =      0.066
[INFO|modelcard.py:451] 2024-05-24 05:42:45,383 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'cnn_dailymail 3.0.0', 'type': 'cnn_dailymail', 'args': '3.0.0'}}
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 05:42:55 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 05:42:55 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_05-42-55_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 05:43:05 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 05:43:05 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 05:43:05 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 05:43:05 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 05:43:05,892 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:43:05,894 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 05:43:06,015 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 05:43:06,133 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:43:06,135 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:43:06,377 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:43:06,377 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:43:06,377 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:43:06,377 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 05:43:06,377 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 05:43:06,377 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 05:43:06,378 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 05:43:06,438 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 05:43:07,798 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 05:43:34,488 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[WARNING|modeling_utils.py:3192] 2024-05-24 05:43:34,488 >> Some weights of EffT5ForConditionalGeneration were not initialized from the model checkpoint at checkpoints/CNNDM and are newly initialized: ['cm_head.0.weight', 'cm_head.2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:2839] 2024-05-24 05:43:34,497 >> Generation config file not found, using a generation config created from the model config.
Running tokenizer on train dataset:   0%|          | 0/7000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
05/24/2024 05:43:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
Running tokenizer on train dataset:  14%|█▍        | 1000/7000 [00:00<00:04, 1350.62 examples/s]Running tokenizer on train dataset:  29%|██▊       | 2000/7000 [00:01<00:03, 1301.66 examples/s]Running tokenizer on train dataset:  43%|████▎     | 3000/7000 [00:02<00:03, 1308.54 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 4000/7000 [00:03<00:02, 1301.12 examples/s]Running tokenizer on train dataset:  71%|███████▏  | 5000/7000 [00:03<00:01, 1289.13 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 6000/7000 [00:04<00:00, 1273.03 examples/s]Running tokenizer on train dataset: 100%|██████████| 7000/7000 [00:05<00:00, 1261.28 examples/s]Running tokenizer on train dataset: 100%|██████████| 7000/7000 [00:05<00:00, 1279.22 examples/s]
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 05:43:40 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Running tokenizer on validation dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-4296e0f2b35597fe.arrow
05/24/2024 05:43:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-4296e0f2b35597fe.arrow
Running tokenizer on validation dataset:  33%|███▎      | 1000/3000 [00:00<00:01, 1122.45 examples/s]Running tokenizer on validation dataset:  67%|██████▋   | 2000/3000 [00:01<00:00, 1141.39 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1062.61 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1077.44 examples/s]
[INFO|trainer.py:1769] 2024-05-24 05:43:44,615 >> ***** Running training *****
[INFO|trainer.py:1770] 2024-05-24 05:43:44,615 >>   Num examples = 7,000
[INFO|trainer.py:1771] 2024-05-24 05:43:44,615 >>   Num Epochs = 5
[INFO|trainer.py:1772] 2024-05-24 05:43:44,615 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1773] 2024-05-24 05:43:44,615 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1774] 2024-05-24 05:43:44,615 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1775] 2024-05-24 05:43:44,616 >>   Total optimization steps = 1,090
[INFO|trainer.py:1776] 2024-05-24 05:43:44,618 >>   Number of trainable parameters = 3,147,776
  0%|          | 0/1090 [00:00<?, ?it/s][WARNING|logging.py:280] 2024-05-24 05:43:44,634 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1090 [00:02<46:46,  2.58s/it]  0%|          | 2/1090 [00:04<43:19,  2.39s/it]  0%|          | 3/1090 [00:07<42:45,  2.36s/it]  0%|          | 4/1090 [00:09<42:46,  2.36s/it]  0%|          | 5/1090 [00:11<40:06,  2.22s/it]  1%|          | 6/1090 [00:13<40:00,  2.21s/it]  1%|          | 7/1090 [00:15<39:41,  2.20s/it]  1%|          | 8/1090 [00:18<39:21,  2.18s/it]  1%|          | 9/1090 [00:20<39:10,  2.17s/it]  1%|          | 10/1090 [00:22<38:28,  2.14s/it]  1%|          | 11/1090 [00:24<38:14,  2.13s/it]  1%|          | 12/1090 [00:26<38:05,  2.12s/it]  1%|          | 13/1090 [00:28<38:04,  2.12s/it]  1%|▏         | 14/1090 [00:30<38:05,  2.12s/it]  1%|▏         | 15/1090 [00:32<38:09,  2.13s/it]  1%|▏         | 16/1090 [00:34<37:47,  2.11s/it]  2%|▏         | 17/1090 [00:36<37:40,  2.11s/it]  2%|▏         | 18/1090 [00:39<37:31,  2.10s/it]  2%|▏         | 19/1090 [00:41<36:53,  2.07s/it]  2%|▏         | 20/1090 [00:43<37:20,  2.09s/it]  2%|▏         | 21/1090 [00:45<37:38,  2.11s/it]  2%|▏         | 22/1090 [00:47<38:11,  2.15s/it]  2%|▏         | 23/1090 [00:49<38:32,  2.17s/it]  2%|▏         | 24/1090 [00:52<39:39,  2.23s/it]  2%|▏         | 25/1090 [00:54<39:20,  2.22s/it]  2%|▏         | 26/1090 [00:56<39:12,  2.21s/it]  2%|▏         | 27/1090 [00:58<38:09,  2.15s/it]  3%|▎         | 28/1090 [01:00<37:27,  2.12s/it]  3%|▎         | 29/1090 [01:02<37:41,  2.13s/it]  3%|▎         | 30/1090 [01:04<37:16,  2.11s/it]  3%|▎         | 31/1090 [01:06<37:06,  2.10s/it]  3%|▎         | 32/1090 [01:09<37:49,  2.14s/it]  3%|▎         | 33/1090 [01:11<37:46,  2.14s/it]  3%|▎         | 34/1090 [01:13<36:54,  2.10s/it]  3%|▎         | 35/1090 [01:15<36:44,  2.09s/it]  3%|▎         | 36/1090 [01:17<36:48,  2.10s/it]  3%|▎         | 37/1090 [01:19<37:00,  2.11s/it]  3%|▎         | 38/1090 [01:21<36:49,  2.10s/it]  4%|▎         | 39/1090 [01:23<37:18,  2.13s/it]  4%|▎         | 40/1090 [01:25<36:32,  2.09s/it]  4%|▍         | 41/1090 [01:28<36:51,  2.11s/it]  4%|▍         | 42/1090 [01:30<36:39,  2.10s/it]  4%|▍         | 43/1090 [01:32<36:39,  2.10s/it]  4%|▍         | 44/1090 [01:34<36:43,  2.11s/it]  4%|▍         | 45/1090 [01:36<37:24,  2.15s/it]  4%|▍         | 46/1090 [01:38<37:44,  2.17s/it]  4%|▍         | 47/1090 [01:40<37:30,  2.16s/it]  4%|▍         | 48/1090 [01:43<37:27,  2.16s/it]  4%|▍         | 49/1090 [01:45<37:31,  2.16s/it]  5%|▍         | 50/1090 [01:47<36:52,  2.13s/it]  5%|▍         | 51/1090 [01:49<36:41,  2.12s/it]  5%|▍         | 52/1090 [01:51<36:27,  2.11s/it]  5%|▍         | 53/1090 [01:53<36:36,  2.12s/it]  5%|▍         | 54/1090 [01:55<36:48,  2.13s/it]  5%|▌         | 55/1090 [01:58<37:27,  2.17s/it]  5%|▌         | 56/1090 [02:00<37:44,  2.19s/it]  5%|▌         | 57/1090 [02:02<38:53,  2.26s/it]  5%|▌         | 58/1090 [02:05<39:02,  2.27s/it]  5%|▌         | 59/1090 [02:07<38:34,  2.24s/it]  6%|▌         | 60/1090 [02:09<37:13,  2.17s/it]  6%|▌         | 61/1090 [02:11<36:51,  2.15s/it]  6%|▌         | 62/1090 [02:13<36:44,  2.14s/it]  6%|▌         | 63/1090 [02:15<36:40,  2.14s/it]  6%|▌         | 64/1090 [02:17<36:28,  2.13s/it]  6%|▌         | 65/1090 [02:19<37:14,  2.18s/it]  6%|▌         | 66/1090 [02:22<36:55,  2.16s/it]  6%|▌         | 67/1090 [02:24<36:50,  2.16s/it]  6%|▌         | 68/1090 [02:26<36:30,  2.14s/it]  6%|▋         | 69/1090 [02:28<35:39,  2.10s/it]  6%|▋         | 70/1090 [02:30<35:52,  2.11s/it]  7%|▋         | 71/1090 [02:32<35:51,  2.11s/it]  7%|▋         | 72/1090 [02:34<35:54,  2.12s/it]  7%|▋         | 73/1090 [02:36<35:53,  2.12s/it]  7%|▋         | 74/1090 [02:39<36:11,  2.14s/it]  7%|▋         | 75/1090 [02:41<36:00,  2.13s/it]  7%|▋         | 76/1090 [02:43<35:03,  2.07s/it]  7%|▋         | 77/1090 [02:45<35:18,  2.09s/it]  7%|▋         | 78/1090 [02:47<35:11,  2.09s/it]  7%|▋         | 79/1090 [02:49<35:29,  2.11s/it]  7%|▋         | 80/1090 [02:51<35:30,  2.11s/it]  7%|▋         | 81/1090 [02:53<35:44,  2.13s/it]  8%|▊         | 82/1090 [02:55<35:48,  2.13s/it]  8%|▊         | 83/1090 [02:57<35:39,  2.12s/it]  8%|▊         | 84/1090 [03:00<35:26,  2.11s/it]  8%|▊         | 85/1090 [03:02<35:01,  2.09s/it]  8%|▊         | 86/1090 [03:04<34:57,  2.09s/it]  8%|▊         | 87/1090 [03:06<34:49,  2.08s/it]  8%|▊         | 88/1090 [03:08<35:05,  2.10s/it]  8%|▊         | 89/1090 [03:10<35:41,  2.14s/it]  8%|▊         | 90/1090 [03:12<36:22,  2.18s/it]  8%|▊         | 91/1090 [03:15<36:12,  2.17s/it]  8%|▊         | 92/1090 [03:17<35:25,  2.13s/it]  9%|▊         | 93/1090 [03:19<34:59,  2.11s/it]  9%|▊         | 94/1090 [03:21<36:44,  2.21s/it]  9%|▊         | 95/1090 [03:23<35:58,  2.17s/it]  9%|▉         | 96/1090 [03:25<35:21,  2.13s/it]  9%|▉         | 97/1090 [03:28<36:19,  2.19s/it]  9%|▉         | 98/1090 [03:30<37:01,  2.24s/it]  9%|▉         | 99/1090 [03:32<36:40,  2.22s/it]  9%|▉         | 100/1090 [03:34<36:26,  2.21s/it]  9%|▉         | 101/1090 [03:36<35:26,  2.15s/it]  9%|▉         | 102/1090 [03:38<35:17,  2.14s/it]  9%|▉         | 103/1090 [03:40<34:46,  2.11s/it] 10%|▉         | 104/1090 [03:43<34:46,  2.12s/it] 10%|▉         | 105/1090 [03:45<35:14,  2.15s/it] 10%|▉         | 106/1090 [03:47<35:22,  2.16s/it] 10%|▉         | 107/1090 [03:49<35:17,  2.15s/it] 10%|▉         | 108/1090 [03:51<35:23,  2.16s/it] 10%|█         | 109/1090 [03:54<35:50,  2.19s/it] 10%|█         | 110/1090 [03:56<35:05,  2.15s/it] 10%|█         | 111/1090 [03:58<35:06,  2.15s/it] 10%|█         | 112/1090 [04:00<35:10,  2.16s/it] 10%|█         | 113/1090 [04:02<35:10,  2.16s/it] 10%|█         | 114/1090 [04:04<34:44,  2.14s/it] 11%|█         | 115/1090 [04:06<34:32,  2.13s/it] 11%|█         | 116/1090 [04:08<34:03,  2.10s/it] 11%|█         | 117/1090 [04:10<34:06,  2.10s/it] 11%|█         | 118/1090 [04:13<34:17,  2.12s/it] 11%|█         | 119/1090 [04:15<34:54,  2.16s/it] 11%|█         | 120/1090 [04:17<34:43,  2.15s/it] 11%|█         | 121/1090 [04:19<34:29,  2.14s/it] 11%|█         | 122/1090 [04:21<34:25,  2.13s/it] 11%|█▏        | 123/1090 [04:23<33:59,  2.11s/it] 11%|█▏        | 124/1090 [04:26<35:52,  2.23s/it] 11%|█▏        | 125/1090 [04:28<35:23,  2.20s/it] 12%|█▏        | 126/1090 [04:30<35:20,  2.20s/it] 12%|█▏        | 127/1090 [04:32<35:34,  2.22s/it] 12%|█▏        | 128/1090 [04:35<35:27,  2.21s/it] 12%|█▏        | 129/1090 [04:37<35:52,  2.24s/it] 12%|█▏        | 130/1090 [04:39<35:23,  2.21s/it] 12%|█▏        | 131/1090 [04:41<34:46,  2.18s/it] 12%|█▏        | 132/1090 [04:43<34:30,  2.16s/it] 12%|█▏        | 133/1090 [04:45<34:21,  2.15s/it] 12%|█▏        | 134/1090 [04:48<36:16,  2.28s/it] 12%|█▏        | 135/1090 [04:50<35:34,  2.24s/it] 12%|█▏        | 136/1090 [04:52<34:53,  2.19s/it] 13%|█▎        | 137/1090 [04:54<34:21,  2.16s/it] 13%|█▎        | 138/1090 [04:56<34:27,  2.17s/it] 13%|█▎        | 139/1090 [04:59<34:32,  2.18s/it] 13%|█▎        | 140/1090 [05:01<34:28,  2.18s/it] 13%|█▎        | 141/1090 [05:03<33:54,  2.14s/it] 13%|█▎        | 142/1090 [05:05<33:21,  2.11s/it] 13%|█▎        | 143/1090 [05:07<33:04,  2.10s/it] 13%|█▎        | 144/1090 [05:09<33:43,  2.14s/it] 13%|█▎        | 145/1090 [05:11<34:06,  2.17s/it] 13%|█▎        | 146/1090 [05:14<33:51,  2.15s/it] 13%|█▎        | 147/1090 [05:16<34:36,  2.20s/it] 14%|█▎        | 148/1090 [05:18<34:24,  2.19s/it] 14%|█▎        | 149/1090 [05:20<34:45,  2.22s/it] 14%|█▍        | 150/1090 [05:23<35:05,  2.24s/it] 14%|█▍        | 151/1090 [05:25<35:39,  2.28s/it] 14%|█▍        | 152/1090 [05:27<34:25,  2.20s/it] 14%|█▍        | 153/1090 [05:29<33:59,  2.18s/it] 14%|█▍        | 154/1090 [05:31<33:39,  2.16s/it] 14%|█▍        | 155/1090 [05:33<33:19,  2.14s/it] 14%|█▍        | 156/1090 [05:36<33:54,  2.18s/it] 14%|█▍        | 157/1090 [05:38<33:55,  2.18s/it] 14%|█▍        | 158/1090 [05:40<34:46,  2.24s/it] 15%|█▍        | 159/1090 [05:42<34:48,  2.24s/it] 15%|█▍        | 160/1090 [05:45<35:24,  2.28s/it] 15%|█▍        | 161/1090 [05:47<35:01,  2.26s/it] 15%|█▍        | 162/1090 [05:49<34:25,  2.23s/it] 15%|█▍        | 163/1090 [05:51<33:23,  2.16s/it] 15%|█▌        | 164/1090 [05:53<32:49,  2.13s/it] 15%|█▌        | 165/1090 [05:55<33:13,  2.16s/it] 15%|█▌        | 166/1090 [05:58<33:21,  2.17s/it] 15%|█▌        | 167/1090 [06:00<33:27,  2.18s/it] 15%|█▌        | 168/1090 [06:02<33:40,  2.19s/it] 16%|█▌        | 169/1090 [06:04<33:34,  2.19s/it] 16%|█▌        | 170/1090 [06:07<33:56,  2.21s/it] 16%|█▌        | 171/1090 [06:09<34:17,  2.24s/it] 16%|█▌        | 172/1090 [06:11<34:12,  2.24s/it] 16%|█▌        | 173/1090 [06:13<33:50,  2.21s/it] 16%|█▌        | 174/1090 [06:15<33:18,  2.18s/it] 16%|█▌        | 175/1090 [06:17<32:56,  2.16s/it] 16%|█▌        | 176/1090 [06:19<32:30,  2.13s/it] 16%|█▌        | 177/1090 [06:22<32:37,  2.14s/it] 16%|█▋        | 178/1090 [06:24<32:38,  2.15s/it] 16%|█▋        | 179/1090 [06:26<32:48,  2.16s/it] 17%|█▋        | 180/1090 [06:28<32:36,  2.15s/it] 17%|█▋        | 181/1090 [06:30<32:21,  2.14s/it] 17%|█▋        | 182/1090 [06:32<32:30,  2.15s/it] 17%|█▋        | 183/1090 [06:35<32:34,  2.16s/it] 17%|█▋        | 184/1090 [06:37<33:00,  2.19s/it] 17%|█▋        | 185/1090 [06:39<33:44,  2.24s/it] 17%|█▋        | 186/1090 [06:41<32:29,  2.16s/it] 17%|█▋        | 187/1090 [06:43<32:22,  2.15s/it] 17%|█▋        | 188/1090 [06:45<32:13,  2.14s/it] 17%|█▋        | 189/1090 [06:48<31:54,  2.13s/it] 17%|█▋        | 190/1090 [06:50<32:36,  2.17s/it] 18%|█▊        | 191/1090 [06:52<32:15,  2.15s/it] 18%|█▊        | 192/1090 [06:54<32:40,  2.18s/it] 18%|█▊        | 193/1090 [06:56<32:48,  2.19s/it] 18%|█▊        | 194/1090 [06:58<32:22,  2.17s/it] 18%|█▊        | 195/1090 [07:01<32:36,  2.19s/it] 18%|█▊        | 196/1090 [07:03<32:06,  2.16s/it] 18%|█▊        | 197/1090 [07:05<31:58,  2.15s/it] 18%|█▊        | 198/1090 [07:07<32:03,  2.16s/it] 18%|█▊        | 199/1090 [07:09<31:35,  2.13s/it] 18%|█▊        | 200/1090 [07:11<31:30,  2.12s/it] 18%|█▊        | 201/1090 [07:14<32:05,  2.17s/it] 19%|█▊        | 202/1090 [07:16<31:47,  2.15s/it] 19%|█▊        | 203/1090 [07:18<31:23,  2.12s/it] 19%|█▊        | 204/1090 [07:20<31:14,  2.12s/it] 19%|█▉        | 205/1090 [07:22<31:46,  2.15s/it] 19%|█▉        | 206/1090 [07:24<32:02,  2.17s/it] 19%|█▉        | 207/1090 [07:26<31:13,  2.12s/it] 19%|█▉        | 208/1090 [07:28<31:31,  2.14s/it] 19%|█▉        | 209/1090 [07:30<30:40,  2.09s/it] 19%|█▉        | 210/1090 [07:33<31:29,  2.15s/it] 19%|█▉        | 211/1090 [07:35<31:34,  2.16s/it] 19%|█▉        | 212/1090 [07:37<31:22,  2.14s/it] 20%|█▉        | 213/1090 [07:39<31:07,  2.13s/it] 20%|█▉        | 214/1090 [07:41<31:27,  2.16s/it] 20%|█▉        | 215/1090 [07:43<31:09,  2.14s/it] 20%|█▉        | 216/1090 [07:46<33:32,  2.30s/it] 20%|█▉        | 217/1090 [07:48<32:29,  2.23s/it] 20%|██        | 218/1090 [07:50<32:26,  2.23s/it] 20%|██        | 219/1090 [07:53<32:25,  2.23s/it] 20%|██        | 220/1090 [07:55<32:03,  2.21s/it] 20%|██        | 221/1090 [07:57<32:30,  2.24s/it] 20%|██        | 222/1090 [07:59<32:00,  2.21s/it] 20%|██        | 223/1090 [08:02<32:29,  2.25s/it] 21%|██        | 224/1090 [08:04<32:37,  2.26s/it] 21%|██        | 225/1090 [08:06<33:22,  2.32s/it] 21%|██        | 226/1090 [08:08<32:34,  2.26s/it] 21%|██        | 227/1090 [08:10<31:26,  2.19s/it] 21%|██        | 228/1090 [08:13<30:51,  2.15s/it] 21%|██        | 229/1090 [08:15<31:21,  2.19s/it] 21%|██        | 230/1090 [08:17<30:46,  2.15s/it] 21%|██        | 231/1090 [08:19<30:49,  2.15s/it] 21%|██▏       | 232/1090 [08:21<30:36,  2.14s/it] 21%|██▏       | 233/1090 [08:23<30:35,  2.14s/it] 21%|██▏       | 234/1090 [08:26<31:03,  2.18s/it] 22%|██▏       | 235/1090 [08:28<31:10,  2.19s/it] 22%|██▏       | 236/1090 [08:30<31:33,  2.22s/it] 22%|██▏       | 237/1090 [08:32<31:41,  2.23s/it] 22%|██▏       | 238/1090 [08:34<30:46,  2.17s/it] 22%|██▏       | 239/1090 [08:36<30:33,  2.15s/it] 22%|██▏       | 240/1090 [08:39<30:35,  2.16s/it] 22%|██▏       | 241/1090 [08:41<30:07,  2.13s/it] 22%|██▏       | 242/1090 [08:43<29:54,  2.12s/it] 22%|██▏       | 243/1090 [08:45<30:12,  2.14s/it] 22%|██▏       | 244/1090 [08:47<30:02,  2.13s/it] 22%|██▏       | 245/1090 [08:49<31:17,  2.22s/it] 23%|██▎       | 246/1090 [08:52<30:49,  2.19s/it] 23%|██▎       | 247/1090 [08:54<30:08,  2.15s/it] 23%|██▎       | 248/1090 [08:56<29:57,  2.13s/it] 23%|██▎       | 249/1090 [08:58<30:32,  2.18s/it] 23%|██▎       | 250/1090 [09:00<30:32,  2.18s/it] 23%|██▎       | 251/1090 [09:02<30:36,  2.19s/it] 23%|██▎       | 252/1090 [09:05<30:45,  2.20s/it] 23%|██▎       | 253/1090 [09:07<30:29,  2.19s/it] 23%|██▎       | 254/1090 [09:09<30:32,  2.19s/it] 23%|██▎       | 255/1090 [09:11<30:10,  2.17s/it] 23%|██▎       | 256/1090 [09:13<29:49,  2.15s/it] 24%|██▎       | 257/1090 [09:15<29:41,  2.14s/it] 24%|██▎       | 258/1090 [09:18<29:43,  2.14s/it] 24%|██▍       | 259/1090 [09:20<30:02,  2.17s/it] 24%|██▍       | 260/1090 [09:22<30:10,  2.18s/it] 24%|██▍       | 261/1090 [09:24<30:25,  2.20s/it] 24%|██▍       | 262/1090 [09:26<30:21,  2.20s/it] 24%|██▍       | 263/1090 [09:29<30:37,  2.22s/it] 24%|██▍       | 264/1090 [09:31<30:45,  2.23s/it] 24%|██▍       | 265/1090 [09:33<29:50,  2.17s/it] 24%|██▍       | 266/1090 [09:35<29:32,  2.15s/it] 24%|██▍       | 267/1090 [09:37<29:41,  2.17s/it] 25%|██▍       | 268/1090 [09:39<29:45,  2.17s/it] 25%|██▍       | 269/1090 [09:42<29:27,  2.15s/it] 25%|██▍       | 270/1090 [09:44<29:08,  2.13s/it] 25%|██▍       | 271/1090 [09:46<29:14,  2.14s/it] 25%|██▍       | 272/1090 [09:48<29:20,  2.15s/it] 25%|██▌       | 273/1090 [09:50<28:50,  2.12s/it] 25%|██▌       | 274/1090 [09:52<28:47,  2.12s/it] 25%|██▌       | 275/1090 [09:54<28:26,  2.09s/it] 25%|██▌       | 276/1090 [09:56<28:08,  2.07s/it] 25%|██▌       | 277/1090 [09:58<27:55,  2.06s/it] 26%|██▌       | 278/1090 [10:00<28:24,  2.10s/it] 26%|██▌       | 279/1090 [10:03<28:56,  2.14s/it] 26%|██▌       | 280/1090 [10:05<28:39,  2.12s/it] 26%|██▌       | 281/1090 [10:07<28:18,  2.10s/it] 26%|██▌       | 282/1090 [10:09<27:57,  2.08s/it] 26%|██▌       | 283/1090 [10:11<28:14,  2.10s/it] 26%|██▌       | 284/1090 [10:13<28:28,  2.12s/it] 26%|██▌       | 285/1090 [10:15<28:17,  2.11s/it] 26%|██▌       | 286/1090 [10:17<28:25,  2.12s/it] 26%|██▋       | 287/1090 [10:20<29:17,  2.19s/it] 26%|██▋       | 288/1090 [10:22<29:21,  2.20s/it] 27%|██▋       | 289/1090 [10:24<29:34,  2.22s/it] 27%|██▋       | 290/1090 [10:26<29:27,  2.21s/it] 27%|██▋       | 291/1090 [10:29<29:24,  2.21s/it] 27%|██▋       | 292/1090 [10:31<29:19,  2.21s/it] 27%|██▋       | 293/1090 [10:33<28:37,  2.15s/it] 27%|██▋       | 294/1090 [10:35<28:10,  2.12s/it] 27%|██▋       | 295/1090 [10:37<27:55,  2.11s/it] 27%|██▋       | 296/1090 [10:39<28:00,  2.12s/it] 27%|██▋       | 297/1090 [10:41<28:34,  2.16s/it] 27%|██▋       | 298/1090 [10:44<28:38,  2.17s/it] 27%|██▋       | 299/1090 [10:46<29:27,  2.23s/it] 28%|██▊       | 300/1090 [10:48<29:18,  2.23s/it] 28%|██▊       | 301/1090 [10:51<29:59,  2.28s/it] 28%|██▊       | 302/1090 [10:53<29:22,  2.24s/it] 28%|██▊       | 303/1090 [10:55<28:08,  2.15s/it] 28%|██▊       | 304/1090 [10:57<27:49,  2.12s/it] 28%|██▊       | 305/1090 [10:59<27:25,  2.10s/it] 28%|██▊       | 306/1090 [11:01<27:13,  2.08s/it] 28%|██▊       | 307/1090 [11:03<27:21,  2.10s/it] 28%|██▊       | 308/1090 [11:05<27:25,  2.10s/it] 28%|██▊       | 309/1090 [11:07<27:28,  2.11s/it] 28%|██▊       | 310/1090 [11:09<27:34,  2.12s/it] 29%|██▊       | 311/1090 [11:11<27:25,  2.11s/it] 29%|██▊       | 312/1090 [11:14<27:44,  2.14s/it] 29%|██▊       | 313/1090 [11:16<27:36,  2.13s/it] 29%|██▉       | 314/1090 [11:18<27:18,  2.11s/it] 29%|██▉       | 315/1090 [11:20<27:07,  2.10s/it] 29%|██▉       | 316/1090 [11:22<27:25,  2.13s/it] 29%|██▉       | 317/1090 [11:24<27:46,  2.16s/it] 29%|██▉       | 318/1090 [11:27<28:12,  2.19s/it] 29%|██▉       | 319/1090 [11:29<28:14,  2.20s/it] 29%|██▉       | 320/1090 [11:31<28:21,  2.21s/it] 29%|██▉       | 321/1090 [11:33<28:55,  2.26s/it] 30%|██▉       | 322/1090 [11:36<28:46,  2.25s/it] 30%|██▉       | 323/1090 [11:38<28:16,  2.21s/it] 30%|██▉       | 324/1090 [11:40<28:51,  2.26s/it] 30%|██▉       | 325/1090 [11:42<28:48,  2.26s/it] 30%|██▉       | 326/1090 [11:45<28:40,  2.25s/it] 30%|███       | 327/1090 [11:47<27:53,  2.19s/it] 30%|███       | 328/1090 [11:49<27:35,  2.17s/it] 30%|███       | 329/1090 [11:51<27:24,  2.16s/it] 30%|███       | 330/1090 [11:53<27:58,  2.21s/it] 30%|███       | 331/1090 [11:55<27:36,  2.18s/it] 30%|███       | 332/1090 [11:57<26:55,  2.13s/it] 31%|███       | 333/1090 [11:59<26:50,  2.13s/it] 31%|███       | 334/1090 [12:02<26:56,  2.14s/it] 31%|███       | 335/1090 [12:04<26:10,  2.08s/it] 31%|███       | 336/1090 [12:06<26:30,  2.11s/it] 31%|███       | 337/1090 [12:08<26:29,  2.11s/it] 31%|███       | 338/1090 [12:10<25:54,  2.07s/it] 31%|███       | 339/1090 [12:12<26:01,  2.08s/it] 31%|███       | 340/1090 [12:14<26:37,  2.13s/it] 31%|███▏      | 341/1090 [12:16<26:57,  2.16s/it] 31%|███▏      | 342/1090 [12:19<27:21,  2.19s/it] 31%|███▏      | 343/1090 [12:21<26:39,  2.14s/it] 32%|███▏      | 344/1090 [12:23<26:21,  2.12s/it] 32%|███▏      | 345/1090 [12:25<26:35,  2.14s/it] 32%|███▏      | 346/1090 [12:27<26:53,  2.17s/it] 32%|███▏      | 347/1090 [12:29<26:51,  2.17s/it] 32%|███▏      | 348/1090 [12:32<27:30,  2.22s/it] 32%|███▏      | 349/1090 [12:34<27:22,  2.22s/it] 32%|███▏      | 350/1090 [12:36<27:21,  2.22s/it] 32%|███▏      | 351/1090 [12:38<27:33,  2.24s/it] 32%|███▏      | 352/1090 [12:41<27:23,  2.23s/it] 32%|███▏      | 353/1090 [12:43<27:02,  2.20s/it] 32%|███▏      | 354/1090 [12:45<27:12,  2.22s/it] 33%|███▎      | 355/1090 [12:47<27:04,  2.21s/it] 33%|███▎      | 356/1090 [12:49<27:18,  2.23s/it] 33%|███▎      | 357/1090 [12:52<26:34,  2.18s/it] 33%|███▎      | 358/1090 [12:54<26:24,  2.17s/it] 33%|███▎      | 359/1090 [12:56<26:04,  2.14s/it] 33%|███▎      | 360/1090 [12:58<25:33,  2.10s/it] 33%|███▎      | 361/1090 [13:00<26:02,  2.14s/it] 33%|███▎      | 362/1090 [13:02<26:39,  2.20s/it] 33%|███▎      | 363/1090 [13:04<26:32,  2.19s/it] 33%|███▎      | 364/1090 [13:07<26:21,  2.18s/it] 33%|███▎      | 365/1090 [13:09<26:23,  2.18s/it] 34%|███▎      | 366/1090 [13:11<25:53,  2.15s/it] 34%|███▎      | 367/1090 [13:13<25:45,  2.14s/it] 34%|███▍      | 368/1090 [13:15<25:43,  2.14s/it] 34%|███▍      | 369/1090 [13:17<26:02,  2.17s/it] 34%|███▍      | 370/1090 [13:19<25:35,  2.13s/it] 34%|███▍      | 371/1090 [13:22<25:43,  2.15s/it] 34%|███▍      | 372/1090 [13:24<26:08,  2.18s/it] 34%|███▍      | 373/1090 [13:26<26:11,  2.19s/it] 34%|███▍      | 374/1090 [13:28<26:11,  2.19s/it] 34%|███▍      | 375/1090 [13:30<25:32,  2.14s/it] 34%|███▍      | 376/1090 [13:32<25:10,  2.12s/it] 35%|███▍      | 377/1090 [13:34<25:00,  2.10s/it] 35%|███▍      | 378/1090 [13:37<25:30,  2.15s/it] 35%|███▍      | 379/1090 [13:39<25:38,  2.16s/it] 35%|███▍      | 380/1090 [13:41<25:19,  2.14s/it] 35%|███▍      | 381/1090 [13:43<25:34,  2.17s/it] 35%|███▌      | 382/1090 [13:45<25:56,  2.20s/it] 35%|███▌      | 383/1090 [13:47<25:07,  2.13s/it] 35%|███▌      | 384/1090 [13:50<24:52,  2.11s/it] 35%|███▌      | 385/1090 [13:52<25:00,  2.13s/it] 35%|███▌      | 386/1090 [13:54<25:03,  2.14s/it] 36%|███▌      | 387/1090 [13:56<25:30,  2.18s/it] 36%|███▌      | 388/1090 [13:58<25:43,  2.20s/it] 36%|███▌      | 389/1090 [14:01<25:45,  2.20s/it] 36%|███▌      | 390/1090 [14:03<25:27,  2.18s/it] 36%|███▌      | 391/1090 [14:05<25:43,  2.21s/it] 36%|███▌      | 392/1090 [14:07<25:55,  2.23s/it] 36%|███▌      | 393/1090 [14:09<25:10,  2.17s/it] 36%|███▌      | 394/1090 [14:11<24:40,  2.13s/it] 36%|███▌      | 395/1090 [14:13<24:47,  2.14s/it] 36%|███▋      | 396/1090 [14:16<24:53,  2.15s/it] 36%|███▋      | 397/1090 [14:18<24:23,  2.11s/it] 37%|███▋      | 398/1090 [14:20<24:28,  2.12s/it] 37%|███▋      | 399/1090 [14:22<23:54,  2.08s/it] 37%|███▋      | 400/1090 [14:24<23:57,  2.08s/it] 37%|███▋      | 401/1090 [14:26<23:36,  2.06s/it] 37%|███▋      | 402/1090 [14:28<23:41,  2.07s/it] 37%|███▋      | 403/1090 [14:30<23:50,  2.08s/it] 37%|███▋      | 404/1090 [14:32<24:04,  2.11s/it] 37%|███▋      | 405/1090 [14:34<24:10,  2.12s/it] 37%|███▋      | 406/1090 [14:36<23:52,  2.09s/it] 37%|███▋      | 407/1090 [14:39<23:58,  2.11s/it] 37%|███▋      | 408/1090 [14:41<23:52,  2.10s/it] 38%|███▊      | 409/1090 [14:43<24:16,  2.14s/it] 38%|███▊      | 410/1090 [14:45<23:42,  2.09s/it] 38%|███▊      | 411/1090 [14:47<23:38,  2.09s/it] 38%|███▊      | 412/1090 [14:49<24:04,  2.13s/it] 38%|███▊      | 413/1090 [14:51<24:26,  2.17s/it] 38%|███▊      | 414/1090 [14:54<24:33,  2.18s/it] 38%|███▊      | 415/1090 [14:56<24:52,  2.21s/it] 38%|███▊      | 416/1090 [14:58<24:45,  2.20s/it] 38%|███▊      | 417/1090 [15:00<24:13,  2.16s/it] 38%|███▊      | 418/1090 [15:02<23:54,  2.13s/it] 38%|███▊      | 419/1090 [15:04<24:00,  2.15s/it] 39%|███▊      | 420/1090 [15:07<24:27,  2.19s/it] 39%|███▊      | 421/1090 [15:09<24:03,  2.16s/it] 39%|███▊      | 422/1090 [15:11<24:01,  2.16s/it] 39%|███▉      | 423/1090 [15:13<24:00,  2.16s/it] 39%|███▉      | 424/1090 [15:15<23:33,  2.12s/it] 39%|███▉      | 425/1090 [15:17<23:47,  2.15s/it] 39%|███▉      | 426/1090 [15:20<23:56,  2.16s/it] 39%|███▉      | 427/1090 [15:22<24:13,  2.19s/it] 39%|███▉      | 428/1090 [15:24<24:12,  2.19s/it] 39%|███▉      | 429/1090 [15:26<24:08,  2.19s/it] 39%|███▉      | 430/1090 [15:28<23:22,  2.13s/it] 40%|███▉      | 431/1090 [15:30<23:36,  2.15s/it] 40%|███▉      | 432/1090 [15:33<23:51,  2.18s/it] 40%|███▉      | 433/1090 [15:35<23:38,  2.16s/it] 40%|███▉      | 434/1090 [15:37<23:30,  2.15s/it] 40%|███▉      | 435/1090 [15:39<23:07,  2.12s/it] 40%|████      | 436/1090 [15:41<23:10,  2.13s/it] 40%|████      | 437/1090 [15:43<22:46,  2.09s/it] 40%|████      | 438/1090 [15:45<22:50,  2.10s/it] 40%|████      | 439/1090 [15:47<23:04,  2.13s/it] 40%|████      | 440/1090 [15:49<22:58,  2.12s/it] 40%|████      | 441/1090 [15:52<22:56,  2.12s/it] 41%|████      | 442/1090 [15:54<22:53,  2.12s/it] 41%|████      | 443/1090 [15:56<22:44,  2.11s/it] 41%|████      | 444/1090 [15:58<22:42,  2.11s/it] 41%|████      | 445/1090 [16:00<22:44,  2.11s/it] 41%|████      | 446/1090 [16:02<22:26,  2.09s/it] 41%|████      | 447/1090 [16:04<22:38,  2.11s/it] 41%|████      | 448/1090 [16:06<22:53,  2.14s/it] 41%|████      | 449/1090 [16:09<22:45,  2.13s/it] 41%|████▏     | 450/1090 [16:11<22:13,  2.08s/it] 41%|████▏     | 451/1090 [16:13<22:30,  2.11s/it] 41%|████▏     | 452/1090 [16:15<22:27,  2.11s/it] 42%|████▏     | 453/1090 [16:17<22:12,  2.09s/it] 42%|████▏     | 454/1090 [16:19<22:20,  2.11s/it] 42%|████▏     | 455/1090 [16:21<22:30,  2.13s/it] 42%|████▏     | 456/1090 [16:23<22:44,  2.15s/it] 42%|████▏     | 457/1090 [16:26<22:47,  2.16s/it] 42%|████▏     | 458/1090 [16:28<23:18,  2.21s/it] 42%|████▏     | 459/1090 [16:30<23:18,  2.22s/it] 42%|████▏     | 460/1090 [16:32<23:21,  2.22s/it] 42%|████▏     | 461/1090 [16:34<22:57,  2.19s/it] 42%|████▏     | 462/1090 [16:37<22:34,  2.16s/it] 42%|████▏     | 463/1090 [16:39<22:28,  2.15s/it] 43%|████▎     | 464/1090 [16:41<22:11,  2.13s/it] 43%|████▎     | 465/1090 [16:43<22:10,  2.13s/it] 43%|████▎     | 466/1090 [16:45<22:10,  2.13s/it] 43%|████▎     | 467/1090 [16:47<22:09,  2.13s/it] 43%|████▎     | 468/1090 [16:49<22:18,  2.15s/it] 43%|████▎     | 469/1090 [16:52<22:34,  2.18s/it] 43%|████▎     | 470/1090 [16:54<22:44,  2.20s/it] 43%|████▎     | 471/1090 [16:56<22:50,  2.21s/it] 43%|████▎     | 472/1090 [16:58<23:00,  2.23s/it] 43%|████▎     | 473/1090 [17:01<22:54,  2.23s/it] 43%|████▎     | 474/1090 [17:03<22:35,  2.20s/it] 44%|████▎     | 475/1090 [17:05<22:10,  2.16s/it] 44%|████▎     | 476/1090 [17:07<21:59,  2.15s/it] 44%|████▍     | 477/1090 [17:09<21:56,  2.15s/it] 44%|████▍     | 478/1090 [17:11<22:18,  2.19s/it] 44%|████▍     | 479/1090 [17:14<22:17,  2.19s/it] 44%|████▍     | 480/1090 [17:16<21:55,  2.16s/it] 44%|████▍     | 481/1090 [17:18<21:50,  2.15s/it] 44%|████▍     | 482/1090 [17:20<21:45,  2.15s/it] 44%|████▍     | 483/1090 [17:22<21:51,  2.16s/it] 44%|████▍     | 484/1090 [17:24<22:20,  2.21s/it] 44%|████▍     | 485/1090 [17:27<22:01,  2.18s/it] 45%|████▍     | 486/1090 [17:29<22:06,  2.20s/it] 45%|████▍     | 487/1090 [17:31<21:37,  2.15s/it] 45%|████▍     | 488/1090 [17:33<21:23,  2.13s/it] 45%|████▍     | 489/1090 [17:35<21:19,  2.13s/it] 45%|████▍     | 490/1090 [17:37<21:28,  2.15s/it] 45%|████▌     | 491/1090 [17:39<21:24,  2.14s/it] 45%|████▌     | 492/1090 [17:42<21:28,  2.15s/it] 45%|████▌     | 493/1090 [17:44<21:29,  2.16s/it] 45%|████▌     | 494/1090 [17:46<21:36,  2.17s/it] 45%|████▌     | 495/1090 [17:48<22:00,  2.22s/it] 46%|████▌     | 496/1090 [17:50<21:34,  2.18s/it] 46%|████▌     | 497/1090 [17:52<21:27,  2.17s/it] 46%|████▌     | 498/1090 [17:55<21:05,  2.14s/it] 46%|████▌     | 499/1090 [17:57<20:54,  2.12s/it] 46%|████▌     | 500/1090 [17:59<21:05,  2.15s/it]                                                  {'loss': 0.4614, 'learning_rate': 2.7064220183486238e-05, 'epoch': 2.29}
 46%|████▌     | 500/1090 [17:59<21:05,  2.15s/it][INFO|configuration_utils.py:575] 2024-05-24 06:01:43,984 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}


  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:22<17:19, 11.42s/it][A
  3%|▎         | 3/93 [00:47<25:24, 16.94s/it][A
  4%|▍         | 4/93 [01:11<29:00, 19.56s/it][A
  5%|▌         | 5/93 [01:36<31:17, 21.33s/it][A
  6%|▋         | 6/93 [01:58<31:26, 21.69s/it][A
  8%|▊         | 7/93 [02:19<30:42, 21.43s/it][A
  9%|▊         | 8/93 [02:39<29:41, 20.96s/it][A
 10%|▉         | 9/93 [02:59<29:11, 20.85s/it][A
 11%|█         | 10/93 [03:23<29:50, 21.57s/it][A
 12%|█▏        | 11/93 [03:47<30:46, 22.52s/it][A
 13%|█▎        | 12/93 [04:11<30:45, 22.79s/it][A
 14%|█▍        | 13/93 [04:35<31:09, 23.36s/it][A
 15%|█▌        | 14/93 [04:54<29:02, 22.06s/it][A
 16%|█▌        | 15/93 [05:18<29:08, 22.42s/it][A
 17%|█▋        | 16/93 [05:40<28:52, 22.50s/it][A
 18%|█▊        | 17/93 [06:02<28:14, 22.29s/it][A
 19%|█▉        | 18/93 [06:26<28:25, 22.73s/it][A
 20%|██        | 19/93 [06:51<28:45, 23.32s/it][A
 22%|██▏       | 20/93 [07:12<27:33, 22.66s/it][A
 23%|██▎       | 21/93 [07:32<26:23, 22.00s/it][A
 24%|██▎       | 22/93 [07:56<26:35, 22.47s/it][A
 25%|██▍       | 23/93 [08:20<26:40, 22.86s/it][A
 26%|██▌       | 24/93 [08:43<26:36, 23.14s/it][A
 27%|██▋       | 25/93 [09:07<26:28, 23.36s/it][A
 28%|██▊       | 26/93 [09:30<25:57, 23.24s/it][A
 29%|██▉       | 27/93 [09:55<26:03, 23.69s/it][A
 30%|███       | 28/93 [10:19<25:41, 23.71s/it][A
 31%|███       | 29/93 [10:41<24:59, 23.43s/it][A
 32%|███▏      | 30/93 [11:05<24:43, 23.55s/it][A
 33%|███▎      | 31/93 [11:28<24:10, 23.40s/it][A
 34%|███▍      | 32/93 [11:53<24:12, 23.82s/it][A
 35%|███▌      | 33/93 [12:18<24:05, 24.09s/it][A
 37%|███▋      | 34/93 [12:43<23:52, 24.27s/it][A
 38%|███▊      | 35/93 [13:03<22:28, 23.25s/it][A
 39%|███▊      | 36/93 [13:25<21:44, 22.88s/it][A
 40%|███▉      | 37/93 [13:50<21:41, 23.24s/it][A
 41%|████      | 38/93 [14:14<21:43, 23.71s/it][A
 42%|████▏     | 39/93 [14:36<20:51, 23.18s/it][A
 43%|████▎     | 40/93 [14:58<20:00, 22.66s/it][A
 44%|████▍     | 41/93 [15:21<19:53, 22.96s/it][A
 45%|████▌     | 42/93 [15:43<19:04, 22.43s/it][A
 46%|████▌     | 43/93 [16:05<18:47, 22.55s/it][A
 47%|████▋     | 44/93 [16:26<17:54, 21.92s/it][A
 48%|████▊     | 45/93 [16:48<17:34, 21.97s/it][A
 49%|████▉     | 46/93 [17:13<17:51, 22.80s/it][A
 51%|█████     | 47/93 [17:34<17:06, 22.32s/it][A
 52%|█████▏    | 48/93 [17:57<16:48, 22.42s/it][A
 53%|█████▎    | 49/93 [18:21<16:56, 23.09s/it][A
 54%|█████▍    | 50/93 [18:40<15:40, 21.87s/it][A
 55%|█████▍    | 51/93 [19:02<15:19, 21.89s/it][A
 56%|█████▌    | 52/93 [19:25<15:13, 22.29s/it][A
 57%|█████▋    | 53/93 [19:48<15:01, 22.53s/it][A
 58%|█████▊    | 54/93 [20:10<14:25, 22.18s/it][A
 59%|█████▉    | 55/93 [20:33<14:12, 22.43s/it][A
 60%|██████    | 56/93 [20:55<13:52, 22.49s/it][A
 61%|██████▏   | 57/93 [21:19<13:43, 22.88s/it][A
 62%|██████▏   | 58/93 [21:43<13:27, 23.06s/it][A
 63%|██████▎   | 59/93 [22:06<13:06, 23.15s/it][A
 65%|██████▍   | 60/93 [22:31<12:59, 23.63s/it][A
 66%|██████▌   | 61/93 [22:53<12:26, 23.33s/it][A
 67%|██████▋   | 62/93 [23:18<12:15, 23.73s/it][A
 68%|██████▊   | 63/93 [23:41<11:42, 23.43s/it][A
 69%|██████▉   | 64/93 [24:05<11:27, 23.69s/it][A
 70%|██████▉   | 65/93 [24:29<11:01, 23.62s/it][A
 71%|███████   | 66/93 [24:52<10:38, 23.64s/it][A
 72%|███████▏  | 67/93 [25:14<10:02, 23.19s/it][A
 73%|███████▎  | 68/93 [25:35<09:17, 22.32s/it][A
 74%|███████▍  | 69/93 [25:58<09:03, 22.66s/it][A
 75%|███████▌  | 70/93 [26:22<08:50, 23.07s/it][A
 76%|███████▋  | 71/93 [26:47<08:39, 23.60s/it][A
 77%|███████▋  | 72/93 [27:11<08:18, 23.72s/it][A
 78%|███████▊  | 73/93 [27:36<08:01, 24.09s/it][A
 80%|███████▉  | 74/93 [27:57<07:21, 23.23s/it][A
 81%|████████  | 75/93 [28:21<07:01, 23.43s/it][A
 82%|████████▏ | 76/93 [28:45<06:38, 23.47s/it][A
 83%|████████▎ | 77/93 [29:06<06:07, 22.98s/it][A
 84%|████████▍ | 78/93 [29:28<05:40, 22.68s/it][A
 85%|████████▍ | 79/93 [29:53<05:26, 23.29s/it][A
 86%|████████▌ | 80/93 [30:16<05:01, 23.23s/it][A
 87%|████████▋ | 81/93 [30:39<04:37, 23.16s/it][A
 88%|████████▊ | 82/93 [31:03<04:15, 23.26s/it][A
 89%|████████▉ | 83/93 [31:27<03:56, 23.68s/it][A
 90%|█████████ | 84/93 [31:52<03:35, 23.94s/it][A
 91%|█████████▏| 85/93 [32:09<02:56, 22.02s/it][A
 92%|█████████▏| 86/93 [32:34<02:38, 22.66s/it][A
 94%|█████████▎| 87/93 [32:56<02:15, 22.51s/it][A
 95%|█████████▍| 88/93 [33:17<01:50, 22.11s/it][A
 96%|█████████▌| 89/93 [33:41<01:31, 22.79s/it][A
 97%|█████████▋| 90/93 [34:06<01:10, 23.38s/it][A
 98%|█████████▊| 91/93 [34:28<00:46, 23.03s/it][A
 99%|█████████▉| 92/93 [34:49<00:22, 22.21s/it][A
100%|██████████| 93/93 [35:10<00:00, 21.95s/it][A                                                  
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 40.4773, 'eval_rouge2': 17.4589, 'eval_rougeL': 28.2757, 'eval_rougeLsum': 37.7674, 'eval_gen_len': 71.5440188172043, 'eval_runtime': 2147.6238, 'eval_samples_per_second': 1.397, 'eval_steps_per_second': 0.044, 'eval_block_avg': 15.15179130862871, 'epoch': 2.29}
 46%|████▌     | 500/1090 [53:46<21:05,  2.15s/it]
100%|██████████| 93/93 [35:27<00:00, 21.95s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 06:37:31,590 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-500
[INFO|configuration_utils.py:457] 2024-05-24 06:37:31,592 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/config.json
[INFO|configuration_utils.py:362] 2024-05-24 06:37:31,592 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 06:37:33,764 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 06:37:33,765 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 06:37:33,765 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 06:37:33,794 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-500/spiece.model
 46%|████▌     | 501/1090 [53:51<105:52:39, 647.13s/it] 46%|████▌     | 502/1090 [53:53<74:06:02, 453.68s/it]  46%|████▌     | 503/1090 [53:55<51:53:15, 318.22s/it] 46%|████▌     | 504/1090 [53:58<36:21:56, 223.41s/it] 46%|████▋     | 505/1090 [54:00<25:31:42, 157.10s/it] 46%|████▋     | 506/1090 [54:02<17:56:49, 110.63s/it] 47%|████▋     | 507/1090 [54:04<12:38:11, 78.03s/it]  47%|████▋     | 508/1090 [54:06<8:56:04, 55.27s/it]  47%|████▋     | 509/1090 [54:08<6:20:47, 39.33s/it] 47%|████▋     | 510/1090 [54:11<4:32:19, 28.17s/it] 47%|████▋     | 511/1090 [54:13<3:16:42, 20.38s/it] 47%|████▋     | 512/1090 [54:15<2:23:33, 14.90s/it] 47%|████▋     | 513/1090 [54:17<1:46:52, 11.11s/it] 47%|████▋     | 514/1090 [54:19<1:21:02,  8.44s/it] 47%|████▋     | 515/1090 [54:22<1:03:00,  6.57s/it] 47%|████▋     | 516/1090 [54:24<50:21,  5.26s/it]   47%|████▋     | 517/1090 [54:26<41:02,  4.30s/it] 48%|████▊     | 518/1090 [54:28<34:50,  3.65s/it] 48%|████▊     | 519/1090 [54:30<30:25,  3.20s/it] 48%|████▊     | 520/1090 [54:32<27:12,  2.86s/it] 48%|████▊     | 521/1090 [54:35<26:01,  2.75s/it] 48%|████▊     | 522/1090 [54:37<24:05,  2.55s/it] 48%|████▊     | 523/1090 [54:39<23:19,  2.47s/it] 48%|████▊     | 524/1090 [54:41<22:31,  2.39s/it] 48%|████▊     | 525/1090 [54:43<22:02,  2.34s/it] 48%|████▊     | 526/1090 [54:46<21:41,  2.31s/it] 48%|████▊     | 527/1090 [54:48<21:41,  2.31s/it] 48%|████▊     | 528/1090 [54:50<21:00,  2.24s/it] 49%|████▊     | 529/1090 [54:52<20:23,  2.18s/it] 49%|████▊     | 530/1090 [54:54<20:04,  2.15s/it] 49%|████▊     | 531/1090 [54:56<19:51,  2.13s/it] 49%|████▉     | 532/1090 [54:58<19:54,  2.14s/it] 49%|████▉     | 533/1090 [55:01<20:17,  2.19s/it] 49%|████▉     | 534/1090 [55:03<20:12,  2.18s/it] 49%|████▉     | 535/1090 [55:05<19:59,  2.16s/it] 49%|████▉     | 536/1090 [55:07<19:58,  2.16s/it] 49%|████▉     | 537/1090 [55:09<19:44,  2.14s/it] 49%|████▉     | 538/1090 [55:11<19:55,  2.17s/it] 49%|████▉     | 539/1090 [55:14<19:50,  2.16s/it] 50%|████▉     | 540/1090 [55:16<19:40,  2.15s/it] 50%|████▉     | 541/1090 [55:18<19:22,  2.12s/it] 50%|████▉     | 542/1090 [55:20<19:15,  2.11s/it] 50%|████▉     | 543/1090 [55:22<19:07,  2.10s/it] 50%|████▉     | 544/1090 [55:24<19:14,  2.12s/it] 50%|█████     | 545/1090 [55:26<19:29,  2.15s/it] 50%|█████     | 546/1090 [55:29<19:40,  2.17s/it] 50%|█████     | 547/1090 [55:31<19:05,  2.11s/it] 50%|█████     | 548/1090 [55:33<19:58,  2.21s/it] 50%|█████     | 549/1090 [55:35<19:36,  2.18s/it] 50%|█████     | 550/1090 [55:37<19:20,  2.15s/it] 51%|█████     | 551/1090 [55:39<19:23,  2.16s/it] 51%|█████     | 552/1090 [55:41<19:13,  2.14s/it] 51%|█████     | 553/1090 [55:44<19:09,  2.14s/it] 51%|█████     | 554/1090 [55:46<19:06,  2.14s/it] 51%|█████     | 555/1090 [55:48<19:16,  2.16s/it] 51%|█████     | 556/1090 [55:50<19:09,  2.15s/it] 51%|█████     | 557/1090 [55:52<18:51,  2.12s/it] 51%|█████     | 558/1090 [55:54<18:37,  2.10s/it] 51%|█████▏    | 559/1090 [55:56<18:34,  2.10s/it] 51%|█████▏    | 560/1090 [55:58<18:31,  2.10s/it] 51%|█████▏    | 561/1090 [56:01<18:42,  2.12s/it] 52%|█████▏    | 562/1090 [56:03<18:58,  2.16s/it] 52%|█████▏    | 563/1090 [56:05<18:49,  2.14s/it] 52%|█████▏    | 564/1090 [56:07<18:17,  2.09s/it] 52%|█████▏    | 565/1090 [56:09<18:22,  2.10s/it] 52%|█████▏    | 566/1090 [56:11<18:46,  2.15s/it] 52%|█████▏    | 567/1090 [56:13<18:31,  2.12s/it] 52%|█████▏    | 568/1090 [56:15<18:17,  2.10s/it] 52%|█████▏    | 569/1090 [56:17<18:07,  2.09s/it] 52%|█████▏    | 570/1090 [56:20<18:31,  2.14s/it] 52%|█████▏    | 571/1090 [56:22<18:20,  2.12s/it] 52%|█████▏    | 572/1090 [56:24<18:24,  2.13s/it] 53%|█████▎    | 573/1090 [56:26<18:10,  2.11s/it] 53%|█████▎    | 574/1090 [56:28<18:05,  2.10s/it] 53%|█████▎    | 575/1090 [56:30<17:57,  2.09s/it] 53%|█████▎    | 576/1090 [56:32<18:19,  2.14s/it] 53%|█████▎    | 577/1090 [56:35<18:30,  2.16s/it] 53%|█████▎    | 578/1090 [56:37<18:44,  2.20s/it] 53%|█████▎    | 579/1090 [56:39<18:22,  2.16s/it] 53%|█████▎    | 580/1090 [56:41<18:51,  2.22s/it] 53%|█████▎    | 581/1090 [56:44<18:54,  2.23s/it] 53%|█████▎    | 582/1090 [56:46<18:28,  2.18s/it] 53%|█████▎    | 583/1090 [56:48<18:56,  2.24s/it] 54%|█████▎    | 584/1090 [56:50<18:27,  2.19s/it] 54%|█████▎    | 585/1090 [56:52<18:15,  2.17s/it] 54%|█████▍    | 586/1090 [56:54<17:59,  2.14s/it] 54%|█████▍    | 587/1090 [56:56<17:44,  2.12s/it] 54%|█████▍    | 588/1090 [56:59<17:55,  2.14s/it] 54%|█████▍    | 589/1090 [57:01<18:03,  2.16s/it] 54%|█████▍    | 590/1090 [57:03<18:41,  2.24s/it] 54%|█████▍    | 591/1090 [57:05<18:38,  2.24s/it] 54%|█████▍    | 592/1090 [57:08<18:39,  2.25s/it] 54%|█████▍    | 593/1090 [57:10<18:31,  2.24s/it] 54%|█████▍    | 594/1090 [57:12<18:52,  2.28s/it] 55%|█████▍    | 595/1090 [57:14<18:17,  2.22s/it] 55%|█████▍    | 596/1090 [57:16<17:45,  2.16s/it] 55%|█████▍    | 597/1090 [57:18<17:34,  2.14s/it] 55%|█████▍    | 598/1090 [57:21<17:32,  2.14s/it] 55%|█████▍    | 599/1090 [57:23<17:43,  2.17s/it] 55%|█████▌    | 600/1090 [57:25<17:34,  2.15s/it] 55%|█████▌    | 601/1090 [57:27<17:45,  2.18s/it] 55%|█████▌    | 602/1090 [57:29<17:46,  2.19s/it] 55%|█████▌    | 603/1090 [57:32<17:58,  2.21s/it] 55%|█████▌    | 604/1090 [57:34<17:26,  2.15s/it] 56%|█████▌    | 605/1090 [57:36<17:11,  2.13s/it] 56%|█████▌    | 606/1090 [57:38<17:05,  2.12s/it] 56%|█████▌    | 607/1090 [57:40<17:06,  2.12s/it] 56%|█████▌    | 608/1090 [57:42<16:58,  2.11s/it] 56%|█████▌    | 609/1090 [57:44<17:17,  2.16s/it] 56%|█████▌    | 610/1090 [57:46<17:20,  2.17s/it] 56%|█████▌    | 611/1090 [57:49<17:42,  2.22s/it] 56%|█████▌    | 612/1090 [57:51<17:28,  2.19s/it] 56%|█████▌    | 613/1090 [57:53<17:40,  2.22s/it] 56%|█████▋    | 614/1090 [57:56<17:54,  2.26s/it] 56%|█████▋    | 615/1090 [57:58<17:38,  2.23s/it] 57%|█████▋    | 616/1090 [58:00<17:07,  2.17s/it] 57%|█████▋    | 617/1090 [58:02<17:05,  2.17s/it] 57%|█████▋    | 618/1090 [58:04<16:40,  2.12s/it] 57%|█████▋    | 619/1090 [58:06<16:51,  2.15s/it] 57%|█████▋    | 620/1090 [58:08<16:48,  2.15s/it] 57%|█████▋    | 621/1090 [58:11<17:00,  2.18s/it] 57%|█████▋    | 622/1090 [58:13<16:59,  2.18s/it] 57%|█████▋    | 623/1090 [58:15<16:58,  2.18s/it] 57%|█████▋    | 624/1090 [58:17<17:03,  2.20s/it] 57%|█████▋    | 625/1090 [58:19<16:48,  2.17s/it] 57%|█████▋    | 626/1090 [58:21<16:33,  2.14s/it] 58%|█████▊    | 627/1090 [58:23<16:27,  2.13s/it] 58%|█████▊    | 628/1090 [58:25<16:11,  2.10s/it] 58%|█████▊    | 629/1090 [58:28<16:14,  2.11s/it] 58%|█████▊    | 630/1090 [58:30<16:29,  2.15s/it] 58%|█████▊    | 631/1090 [58:32<16:46,  2.19s/it] 58%|█████▊    | 632/1090 [58:34<16:40,  2.18s/it] 58%|█████▊    | 633/1090 [58:37<16:42,  2.19s/it] 58%|█████▊    | 634/1090 [58:39<16:23,  2.16s/it] 58%|█████▊    | 635/1090 [58:41<16:26,  2.17s/it] 58%|█████▊    | 636/1090 [58:43<16:23,  2.17s/it] 58%|█████▊    | 637/1090 [58:45<16:09,  2.14s/it] 59%|█████▊    | 638/1090 [58:47<16:13,  2.15s/it] 59%|█████▊    | 639/1090 [58:49<16:12,  2.16s/it] 59%|█████▊    | 640/1090 [58:52<16:11,  2.16s/it] 59%|█████▉    | 641/1090 [58:54<16:30,  2.21s/it] 59%|█████▉    | 642/1090 [58:56<16:26,  2.20s/it] 59%|█████▉    | 643/1090 [58:58<16:26,  2.21s/it] 59%|█████▉    | 644/1090 [59:00<16:05,  2.17s/it] 59%|█████▉    | 645/1090 [59:02<15:55,  2.15s/it] 59%|█████▉    | 646/1090 [59:05<15:40,  2.12s/it] 59%|█████▉    | 647/1090 [59:07<15:37,  2.12s/it] 59%|█████▉    | 648/1090 [59:09<15:49,  2.15s/it] 60%|█████▉    | 649/1090 [59:11<16:03,  2.18s/it] 60%|█████▉    | 650/1090 [59:13<16:12,  2.21s/it] 60%|█████▉    | 651/1090 [59:16<16:17,  2.23s/it] 60%|█████▉    | 652/1090 [59:18<16:02,  2.20s/it] 60%|█████▉    | 653/1090 [59:20<16:08,  2.22s/it] 60%|██████    | 654/1090 [59:22<16:28,  2.27s/it] 60%|██████    | 655/1090 [59:24<16:00,  2.21s/it] 60%|██████    | 656/1090 [59:27<15:52,  2.19s/it] 60%|██████    | 657/1090 [59:29<15:48,  2.19s/it] 60%|██████    | 658/1090 [59:31<15:37,  2.17s/it] 60%|██████    | 659/1090 [59:33<15:31,  2.16s/it] 61%|██████    | 660/1090 [59:35<15:29,  2.16s/it] 61%|██████    | 661/1090 [59:37<15:11,  2.12s/it] 61%|██████    | 662/1090 [59:39<15:08,  2.12s/it] 61%|██████    | 663/1090 [59:42<15:15,  2.14s/it] 61%|██████    | 664/1090 [59:44<15:17,  2.15s/it] 61%|██████    | 665/1090 [59:46<15:35,  2.20s/it] 61%|██████    | 666/1090 [59:48<15:17,  2.16s/it] 61%|██████    | 667/1090 [59:50<15:25,  2.19s/it] 61%|██████▏   | 668/1090 [59:53<15:28,  2.20s/it] 61%|██████▏   | 669/1090 [59:55<14:55,  2.13s/it] 61%|██████▏   | 670/1090 [59:57<14:53,  2.13s/it] 62%|██████▏   | 671/1090 [59:59<14:54,  2.13s/it] 62%|██████▏   | 672/1090 [1:00:01<15:10,  2.18s/it] 62%|██████▏   | 673/1090 [1:00:03<15:26,  2.22s/it] 62%|██████▏   | 674/1090 [1:00:06<15:18,  2.21s/it] 62%|██████▏   | 675/1090 [1:00:08<15:09,  2.19s/it] 62%|██████▏   | 676/1090 [1:00:10<14:46,  2.14s/it] 62%|██████▏   | 677/1090 [1:00:12<14:40,  2.13s/it] 62%|██████▏   | 678/1090 [1:00:14<15:01,  2.19s/it] 62%|██████▏   | 679/1090 [1:00:16<14:59,  2.19s/it] 62%|██████▏   | 680/1090 [1:00:19<14:49,  2.17s/it] 62%|██████▏   | 681/1090 [1:00:21<14:57,  2.19s/it] 63%|██████▎   | 682/1090 [1:00:23<14:59,  2.21s/it] 63%|██████▎   | 683/1090 [1:00:25<14:49,  2.19s/it] 63%|██████▎   | 684/1090 [1:00:27<14:43,  2.18s/it] 63%|██████▎   | 685/1090 [1:00:30<14:37,  2.17s/it] 63%|██████▎   | 686/1090 [1:00:32<14:40,  2.18s/it] 63%|██████▎   | 687/1090 [1:00:34<14:19,  2.13s/it] 63%|██████▎   | 688/1090 [1:00:36<14:06,  2.10s/it] 63%|██████▎   | 689/1090 [1:00:38<14:29,  2.17s/it] 63%|██████▎   | 690/1090 [1:00:40<14:30,  2.18s/it] 63%|██████▎   | 691/1090 [1:00:42<14:18,  2.15s/it] 63%|██████▎   | 692/1090 [1:00:44<14:02,  2.12s/it] 64%|██████▎   | 693/1090 [1:00:47<14:03,  2.13s/it] 64%|██████▎   | 694/1090 [1:00:49<14:14,  2.16s/it] 64%|██████▍   | 695/1090 [1:00:51<13:57,  2.12s/it] 64%|██████▍   | 696/1090 [1:00:53<13:54,  2.12s/it] 64%|██████▍   | 697/1090 [1:00:55<13:56,  2.13s/it] 64%|██████▍   | 698/1090 [1:00:57<13:52,  2.12s/it] 64%|██████▍   | 699/1090 [1:00:59<13:44,  2.11s/it] 64%|██████▍   | 700/1090 [1:01:01<13:52,  2.13s/it] 64%|██████▍   | 701/1090 [1:01:04<13:57,  2.15s/it] 64%|██████▍   | 702/1090 [1:01:06<14:07,  2.18s/it] 64%|██████▍   | 703/1090 [1:01:08<14:00,  2.17s/it] 65%|██████▍   | 704/1090 [1:01:10<13:44,  2.14s/it] 65%|██████▍   | 705/1090 [1:01:12<13:35,  2.12s/it] 65%|██████▍   | 706/1090 [1:01:14<13:35,  2.12s/it] 65%|██████▍   | 707/1090 [1:01:16<13:24,  2.10s/it] 65%|██████▍   | 708/1090 [1:01:19<13:26,  2.11s/it] 65%|██████▌   | 709/1090 [1:01:21<13:36,  2.14s/it] 65%|██████▌   | 710/1090 [1:01:23<13:47,  2.18s/it] 65%|██████▌   | 711/1090 [1:01:25<14:08,  2.24s/it] 65%|██████▌   | 712/1090 [1:01:28<14:23,  2.28s/it] 65%|██████▌   | 713/1090 [1:01:30<14:18,  2.28s/it] 66%|██████▌   | 714/1090 [1:01:32<14:27,  2.31s/it] 66%|██████▌   | 715/1090 [1:01:35<14:27,  2.31s/it] 66%|██████▌   | 716/1090 [1:01:37<14:22,  2.31s/it] 66%|██████▌   | 717/1090 [1:01:39<14:02,  2.26s/it] 66%|██████▌   | 718/1090 [1:01:41<13:51,  2.23s/it] 66%|██████▌   | 719/1090 [1:01:43<13:27,  2.18s/it] 66%|██████▌   | 720/1090 [1:01:45<13:14,  2.15s/it] 66%|██████▌   | 721/1090 [1:01:48<13:09,  2.14s/it] 66%|██████▌   | 722/1090 [1:01:50<13:13,  2.16s/it] 66%|██████▋   | 723/1090 [1:01:52<13:05,  2.14s/it] 66%|██████▋   | 724/1090 [1:01:54<13:07,  2.15s/it] 67%|██████▋   | 725/1090 [1:01:56<13:16,  2.18s/it] 67%|██████▋   | 726/1090 [1:01:59<13:24,  2.21s/it] 67%|██████▋   | 727/1090 [1:02:01<13:06,  2.17s/it] 67%|██████▋   | 728/1090 [1:02:03<12:52,  2.13s/it] 67%|██████▋   | 729/1090 [1:02:05<12:46,  2.12s/it] 67%|██████▋   | 730/1090 [1:02:07<12:40,  2.11s/it] 67%|██████▋   | 731/1090 [1:02:09<12:43,  2.13s/it] 67%|██████▋   | 732/1090 [1:02:11<13:06,  2.20s/it] 67%|██████▋   | 733/1090 [1:02:14<13:02,  2.19s/it] 67%|██████▋   | 734/1090 [1:02:16<13:00,  2.19s/it] 67%|██████▋   | 735/1090 [1:02:18<12:41,  2.15s/it] 68%|██████▊   | 736/1090 [1:02:20<12:28,  2.12s/it] 68%|██████▊   | 737/1090 [1:02:22<12:22,  2.10s/it] 68%|██████▊   | 738/1090 [1:02:24<12:31,  2.13s/it] 68%|██████▊   | 739/1090 [1:02:26<12:24,  2.12s/it] 68%|██████▊   | 740/1090 [1:02:28<12:29,  2.14s/it] 68%|██████▊   | 741/1090 [1:02:31<12:42,  2.18s/it] 68%|██████▊   | 742/1090 [1:02:33<12:39,  2.18s/it] 68%|██████▊   | 743/1090 [1:02:35<12:43,  2.20s/it] 68%|██████▊   | 744/1090 [1:02:37<12:22,  2.15s/it] 68%|██████▊   | 745/1090 [1:02:39<12:18,  2.14s/it] 68%|██████▊   | 746/1090 [1:02:42<12:27,  2.17s/it] 69%|██████▊   | 747/1090 [1:02:44<12:20,  2.16s/it] 69%|██████▊   | 748/1090 [1:02:46<12:16,  2.15s/it] 69%|██████▊   | 749/1090 [1:02:48<12:13,  2.15s/it] 69%|██████▉   | 750/1090 [1:02:50<12:07,  2.14s/it] 69%|██████▉   | 751/1090 [1:02:52<12:04,  2.14s/it] 69%|██████▉   | 752/1090 [1:02:54<12:06,  2.15s/it] 69%|██████▉   | 753/1090 [1:02:57<12:14,  2.18s/it] 69%|██████▉   | 754/1090 [1:02:59<12:03,  2.15s/it] 69%|██████▉   | 755/1090 [1:03:01<11:57,  2.14s/it] 69%|██████▉   | 756/1090 [1:03:03<11:50,  2.13s/it] 69%|██████▉   | 757/1090 [1:03:05<12:05,  2.18s/it] 70%|██████▉   | 758/1090 [1:03:07<12:06,  2.19s/it] 70%|██████▉   | 759/1090 [1:03:10<12:04,  2.19s/it] 70%|██████▉   | 760/1090 [1:03:12<12:16,  2.23s/it] 70%|██████▉   | 761/1090 [1:03:14<12:16,  2.24s/it] 70%|██████▉   | 762/1090 [1:03:17<12:20,  2.26s/it] 70%|███████   | 763/1090 [1:03:19<12:03,  2.21s/it] 70%|███████   | 764/1090 [1:03:21<12:39,  2.33s/it] 70%|███████   | 765/1090 [1:03:23<12:26,  2.30s/it] 70%|███████   | 766/1090 [1:03:26<12:08,  2.25s/it] 70%|███████   | 767/1090 [1:03:28<11:50,  2.20s/it] 70%|███████   | 768/1090 [1:03:30<11:41,  2.18s/it] 71%|███████   | 769/1090 [1:03:32<11:40,  2.18s/it] 71%|███████   | 770/1090 [1:03:34<11:29,  2.15s/it] 71%|███████   | 771/1090 [1:03:36<11:17,  2.12s/it] 71%|███████   | 772/1090 [1:03:38<11:36,  2.19s/it] 71%|███████   | 773/1090 [1:03:41<11:37,  2.20s/it] 71%|███████   | 774/1090 [1:03:43<11:38,  2.21s/it] 71%|███████   | 775/1090 [1:03:45<11:45,  2.24s/it] 71%|███████   | 776/1090 [1:03:48<11:52,  2.27s/it] 71%|███████▏  | 777/1090 [1:03:50<11:33,  2.22s/it] 71%|███████▏  | 778/1090 [1:03:52<11:47,  2.27s/it] 71%|███████▏  | 779/1090 [1:03:54<11:39,  2.25s/it] 72%|███████▏  | 780/1090 [1:03:56<11:32,  2.24s/it] 72%|███████▏  | 781/1090 [1:03:59<11:21,  2.21s/it] 72%|███████▏  | 782/1090 [1:04:01<11:09,  2.17s/it] 72%|███████▏  | 783/1090 [1:04:03<11:01,  2.15s/it] 72%|███████▏  | 784/1090 [1:04:05<10:52,  2.13s/it] 72%|███████▏  | 785/1090 [1:04:07<10:42,  2.11s/it] 72%|███████▏  | 786/1090 [1:04:09<10:56,  2.16s/it] 72%|███████▏  | 787/1090 [1:04:12<11:08,  2.21s/it] 72%|███████▏  | 788/1090 [1:04:14<11:03,  2.20s/it] 72%|███████▏  | 789/1090 [1:04:16<10:58,  2.19s/it] 72%|███████▏  | 790/1090 [1:04:18<10:51,  2.17s/it] 73%|███████▎  | 791/1090 [1:04:20<10:38,  2.13s/it] 73%|███████▎  | 792/1090 [1:04:22<10:30,  2.11s/it] 73%|███████▎  | 793/1090 [1:04:24<10:28,  2.12s/it] 73%|███████▎  | 794/1090 [1:04:26<10:33,  2.14s/it] 73%|███████▎  | 795/1090 [1:04:29<10:26,  2.12s/it] 73%|███████▎  | 796/1090 [1:04:31<10:21,  2.11s/it] 73%|███████▎  | 797/1090 [1:04:33<10:17,  2.11s/it] 73%|███████▎  | 798/1090 [1:04:35<10:19,  2.12s/it] 73%|███████▎  | 799/1090 [1:04:37<10:11,  2.10s/it] 73%|███████▎  | 800/1090 [1:04:39<10:08,  2.10s/it] 73%|███████▎  | 801/1090 [1:04:41<10:05,  2.10s/it] 74%|███████▎  | 802/1090 [1:04:43<10:00,  2.08s/it] 74%|███████▎  | 803/1090 [1:04:45<10:08,  2.12s/it] 74%|███████▍  | 804/1090 [1:04:48<10:17,  2.16s/it] 74%|███████▍  | 805/1090 [1:04:50<10:11,  2.14s/it] 74%|███████▍  | 806/1090 [1:04:52<10:06,  2.14s/it] 74%|███████▍  | 807/1090 [1:04:54<09:58,  2.11s/it] 74%|███████▍  | 808/1090 [1:04:56<09:43,  2.07s/it] 74%|███████▍  | 809/1090 [1:04:58<09:42,  2.07s/it] 74%|███████▍  | 810/1090 [1:05:00<09:48,  2.10s/it] 74%|███████▍  | 811/1090 [1:05:02<09:51,  2.12s/it] 74%|███████▍  | 812/1090 [1:05:04<09:49,  2.12s/it] 75%|███████▍  | 813/1090 [1:05:06<09:36,  2.08s/it] 75%|███████▍  | 814/1090 [1:05:08<09:31,  2.07s/it] 75%|███████▍  | 815/1090 [1:05:10<09:21,  2.04s/it] 75%|███████▍  | 816/1090 [1:05:13<09:23,  2.05s/it] 75%|███████▍  | 817/1090 [1:05:15<09:29,  2.09s/it] 75%|███████▌  | 818/1090 [1:05:17<09:40,  2.13s/it] 75%|███████▌  | 819/1090 [1:05:19<09:35,  2.12s/it] 75%|███████▌  | 820/1090 [1:05:21<09:27,  2.10s/it] 75%|███████▌  | 821/1090 [1:05:23<09:29,  2.12s/it] 75%|███████▌  | 822/1090 [1:05:25<09:31,  2.13s/it] 76%|███████▌  | 823/1090 [1:05:28<09:31,  2.14s/it] 76%|███████▌  | 824/1090 [1:05:30<09:35,  2.16s/it] 76%|███████▌  | 825/1090 [1:05:32<09:27,  2.14s/it] 76%|███████▌  | 826/1090 [1:05:34<09:25,  2.14s/it] 76%|███████▌  | 827/1090 [1:05:36<09:35,  2.19s/it] 76%|███████▌  | 828/1090 [1:05:38<09:32,  2.18s/it] 76%|███████▌  | 829/1090 [1:05:41<09:31,  2.19s/it] 76%|███████▌  | 830/1090 [1:05:43<09:24,  2.17s/it] 76%|███████▌  | 831/1090 [1:05:45<09:10,  2.13s/it] 76%|███████▋  | 832/1090 [1:05:47<09:08,  2.13s/it] 76%|███████▋  | 833/1090 [1:05:49<08:57,  2.09s/it] 77%|███████▋  | 834/1090 [1:05:51<08:52,  2.08s/it] 77%|███████▋  | 835/1090 [1:05:53<08:58,  2.11s/it] 77%|███████▋  | 836/1090 [1:05:55<09:07,  2.16s/it] 77%|███████▋  | 837/1090 [1:05:58<09:06,  2.16s/it] 77%|███████▋  | 838/1090 [1:06:00<09:04,  2.16s/it] 77%|███████▋  | 839/1090 [1:06:02<09:11,  2.20s/it] 77%|███████▋  | 840/1090 [1:06:04<09:24,  2.26s/it] 77%|███████▋  | 841/1090 [1:06:06<09:05,  2.19s/it] 77%|███████▋  | 842/1090 [1:06:09<08:58,  2.17s/it] 77%|███████▋  | 843/1090 [1:06:11<08:55,  2.17s/it] 77%|███████▋  | 844/1090 [1:06:13<08:43,  2.13s/it] 78%|███████▊  | 845/1090 [1:06:15<08:50,  2.16s/it] 78%|███████▊  | 846/1090 [1:06:17<08:49,  2.17s/it] 78%|███████▊  | 847/1090 [1:06:19<08:52,  2.19s/it] 78%|███████▊  | 848/1090 [1:06:22<08:46,  2.18s/it] 78%|███████▊  | 849/1090 [1:06:24<08:45,  2.18s/it] 78%|███████▊  | 850/1090 [1:06:26<08:39,  2.16s/it] 78%|███████▊  | 851/1090 [1:06:28<08:34,  2.15s/it] 78%|███████▊  | 852/1090 [1:06:30<08:34,  2.16s/it] 78%|███████▊  | 853/1090 [1:06:32<08:23,  2.13s/it] 78%|███████▊  | 854/1090 [1:06:34<08:20,  2.12s/it] 78%|███████▊  | 855/1090 [1:06:37<08:25,  2.15s/it] 79%|███████▊  | 856/1090 [1:06:39<08:23,  2.15s/it] 79%|███████▊  | 857/1090 [1:06:41<08:27,  2.18s/it] 79%|███████▊  | 858/1090 [1:06:43<08:27,  2.19s/it] 79%|███████▉  | 859/1090 [1:06:45<08:25,  2.19s/it] 79%|███████▉  | 860/1090 [1:06:48<08:18,  2.17s/it] 79%|███████▉  | 861/1090 [1:06:50<08:12,  2.15s/it] 79%|███████▉  | 862/1090 [1:06:52<08:03,  2.12s/it] 79%|███████▉  | 863/1090 [1:06:54<08:00,  2.12s/it] 79%|███████▉  | 864/1090 [1:06:56<08:13,  2.18s/it] 79%|███████▉  | 865/1090 [1:06:58<08:09,  2.18s/it] 79%|███████▉  | 866/1090 [1:07:01<08:13,  2.20s/it] 80%|███████▉  | 867/1090 [1:07:03<08:12,  2.21s/it] 80%|███████▉  | 868/1090 [1:07:05<08:07,  2.20s/it] 80%|███████▉  | 869/1090 [1:07:07<07:51,  2.13s/it] 80%|███████▉  | 870/1090 [1:07:09<07:50,  2.14s/it] 80%|███████▉  | 871/1090 [1:07:11<07:40,  2.10s/it] 80%|████████  | 872/1090 [1:07:13<07:42,  2.12s/it] 80%|████████  | 873/1090 [1:07:16<07:59,  2.21s/it] 80%|████████  | 874/1090 [1:07:18<08:10,  2.27s/it] 80%|████████  | 875/1090 [1:07:20<08:03,  2.25s/it] 80%|████████  | 876/1090 [1:07:22<07:55,  2.22s/it] 80%|████████  | 877/1090 [1:07:25<07:55,  2.23s/it] 81%|████████  | 878/1090 [1:07:27<07:56,  2.25s/it] 81%|████████  | 879/1090 [1:07:29<07:45,  2.21s/it] 81%|████████  | 880/1090 [1:07:31<07:34,  2.17s/it] 81%|████████  | 881/1090 [1:07:33<07:30,  2.16s/it] 81%|████████  | 882/1090 [1:07:35<07:24,  2.14s/it] 81%|████████  | 883/1090 [1:07:38<07:31,  2.18s/it] 81%|████████  | 884/1090 [1:07:40<07:35,  2.21s/it] 81%|████████  | 885/1090 [1:07:42<07:31,  2.20s/it] 81%|████████▏ | 886/1090 [1:07:44<07:29,  2.21s/it] 81%|████████▏ | 887/1090 [1:07:47<07:28,  2.21s/it] 81%|████████▏ | 888/1090 [1:07:49<07:27,  2.21s/it] 82%|████████▏ | 889/1090 [1:07:51<07:15,  2.17s/it] 82%|████████▏ | 890/1090 [1:07:53<07:08,  2.14s/it] 82%|████████▏ | 891/1090 [1:07:55<07:04,  2.13s/it] 82%|████████▏ | 892/1090 [1:07:57<06:58,  2.11s/it] 82%|████████▏ | 893/1090 [1:07:59<07:05,  2.16s/it] 82%|████████▏ | 894/1090 [1:08:02<07:08,  2.19s/it] 82%|████████▏ | 895/1090 [1:08:04<07:02,  2.17s/it] 82%|████████▏ | 896/1090 [1:08:06<07:10,  2.22s/it] 82%|████████▏ | 897/1090 [1:08:08<07:11,  2.24s/it] 82%|████████▏ | 898/1090 [1:08:11<07:09,  2.24s/it] 82%|████████▏ | 899/1090 [1:08:13<07:00,  2.20s/it] 83%|████████▎ | 900/1090 [1:08:15<06:53,  2.17s/it] 83%|████████▎ | 901/1090 [1:08:17<06:43,  2.14s/it] 83%|████████▎ | 902/1090 [1:08:19<06:41,  2.14s/it] 83%|████████▎ | 903/1090 [1:08:21<06:50,  2.20s/it] 83%|████████▎ | 904/1090 [1:08:24<06:50,  2.20s/it] 83%|████████▎ | 905/1090 [1:08:26<06:48,  2.21s/it] 83%|████████▎ | 906/1090 [1:08:28<06:46,  2.21s/it] 83%|████████▎ | 907/1090 [1:08:30<06:47,  2.23s/it] 83%|████████▎ | 908/1090 [1:08:33<06:47,  2.24s/it] 83%|████████▎ | 909/1090 [1:08:35<06:32,  2.17s/it] 83%|████████▎ | 910/1090 [1:08:37<06:27,  2.15s/it] 84%|████████▎ | 911/1090 [1:08:39<06:19,  2.12s/it] 84%|████████▎ | 912/1090 [1:08:41<06:25,  2.17s/it] 84%|████████▍ | 913/1090 [1:08:43<06:27,  2.19s/it] 84%|████████▍ | 914/1090 [1:08:46<06:31,  2.22s/it] 84%|████████▍ | 915/1090 [1:08:48<06:29,  2.23s/it] 84%|████████▍ | 916/1090 [1:08:50<06:24,  2.21s/it] 84%|████████▍ | 917/1090 [1:08:52<06:30,  2.26s/it] 84%|████████▍ | 918/1090 [1:08:55<06:38,  2.32s/it] 84%|████████▍ | 919/1090 [1:08:57<06:37,  2.32s/it] 84%|████████▍ | 920/1090 [1:08:59<06:30,  2.30s/it] 84%|████████▍ | 921/1090 [1:09:01<06:15,  2.22s/it] 85%|████████▍ | 922/1090 [1:09:03<06:05,  2.17s/it] 85%|████████▍ | 923/1090 [1:09:06<06:01,  2.17s/it] 85%|████████▍ | 924/1090 [1:09:08<05:57,  2.15s/it] 85%|████████▍ | 925/1090 [1:09:10<05:59,  2.18s/it] 85%|████████▍ | 926/1090 [1:09:12<05:54,  2.16s/it] 85%|████████▌ | 927/1090 [1:09:14<05:51,  2.16s/it] 85%|████████▌ | 928/1090 [1:09:16<05:50,  2.16s/it] 85%|████████▌ | 929/1090 [1:09:18<05:44,  2.14s/it] 85%|████████▌ | 930/1090 [1:09:21<05:45,  2.16s/it] 85%|████████▌ | 931/1090 [1:09:23<05:48,  2.19s/it] 86%|████████▌ | 932/1090 [1:09:25<05:49,  2.21s/it] 86%|████████▌ | 933/1090 [1:09:27<05:41,  2.17s/it] 86%|████████▌ | 934/1090 [1:09:29<05:37,  2.16s/it] 86%|████████▌ | 935/1090 [1:09:32<05:36,  2.17s/it] 86%|████████▌ | 936/1090 [1:09:34<05:33,  2.16s/it] 86%|████████▌ | 937/1090 [1:09:36<05:22,  2.11s/it] 86%|████████▌ | 938/1090 [1:09:38<05:38,  2.23s/it] 86%|████████▌ | 939/1090 [1:09:40<05:33,  2.21s/it] 86%|████████▌ | 940/1090 [1:09:43<05:25,  2.17s/it] 86%|████████▋ | 941/1090 [1:09:45<05:22,  2.17s/it] 86%|████████▋ | 942/1090 [1:09:47<05:14,  2.12s/it] 87%|████████▋ | 943/1090 [1:09:49<05:14,  2.14s/it] 87%|████████▋ | 944/1090 [1:09:51<05:13,  2.15s/it] 87%|████████▋ | 945/1090 [1:09:53<05:18,  2.19s/it] 87%|████████▋ | 946/1090 [1:09:56<05:18,  2.21s/it] 87%|████████▋ | 947/1090 [1:09:58<05:13,  2.19s/it] 87%|████████▋ | 948/1090 [1:10:00<05:08,  2.17s/it] 87%|████████▋ | 949/1090 [1:10:02<04:58,  2.12s/it] 87%|████████▋ | 950/1090 [1:10:04<04:56,  2.12s/it] 87%|████████▋ | 951/1090 [1:10:06<04:55,  2.12s/it] 87%|████████▋ | 952/1090 [1:10:08<04:58,  2.16s/it] 87%|████████▋ | 953/1090 [1:10:11<04:55,  2.16s/it] 88%|████████▊ | 954/1090 [1:10:13<04:58,  2.19s/it] 88%|████████▊ | 955/1090 [1:10:15<04:53,  2.17s/it] 88%|████████▊ | 956/1090 [1:10:17<04:54,  2.20s/it] 88%|████████▊ | 957/1090 [1:10:19<04:57,  2.23s/it] 88%|████████▊ | 958/1090 [1:10:22<04:56,  2.25s/it] 88%|████████▊ | 959/1090 [1:10:24<04:46,  2.19s/it] 88%|████████▊ | 960/1090 [1:10:26<04:45,  2.19s/it] 88%|████████▊ | 961/1090 [1:10:28<04:36,  2.14s/it] 88%|████████▊ | 962/1090 [1:10:30<04:30,  2.12s/it] 88%|████████▊ | 963/1090 [1:10:32<04:33,  2.15s/it] 88%|████████▊ | 964/1090 [1:10:35<04:35,  2.18s/it] 89%|████████▊ | 965/1090 [1:10:37<04:32,  2.18s/it] 89%|████████▊ | 966/1090 [1:10:39<04:30,  2.18s/it] 89%|████████▊ | 967/1090 [1:10:41<04:32,  2.21s/it] 89%|████████▉ | 968/1090 [1:10:43<04:29,  2.21s/it] 89%|████████▉ | 969/1090 [1:10:46<04:23,  2.18s/it] 89%|████████▉ | 970/1090 [1:10:48<04:20,  2.17s/it] 89%|████████▉ | 971/1090 [1:10:50<04:14,  2.14s/it] 89%|████████▉ | 972/1090 [1:10:52<04:10,  2.12s/it] 89%|████████▉ | 973/1090 [1:10:54<04:11,  2.15s/it] 89%|████████▉ | 974/1090 [1:10:56<04:14,  2.19s/it] 89%|████████▉ | 975/1090 [1:10:59<04:14,  2.21s/it] 90%|████████▉ | 976/1090 [1:11:01<04:10,  2.20s/it] 90%|████████▉ | 977/1090 [1:11:03<04:07,  2.19s/it] 90%|████████▉ | 978/1090 [1:11:05<04:00,  2.15s/it] 90%|████████▉ | 979/1090 [1:11:07<04:08,  2.24s/it] 90%|████████▉ | 980/1090 [1:11:10<04:02,  2.20s/it] 90%|█████████ | 981/1090 [1:11:12<03:58,  2.19s/it] 90%|█████████ | 982/1090 [1:11:14<03:53,  2.16s/it] 90%|█████████ | 983/1090 [1:11:16<03:51,  2.16s/it] 90%|█████████ | 984/1090 [1:11:18<03:46,  2.14s/it] 90%|█████████ | 985/1090 [1:11:20<03:45,  2.15s/it] 90%|█████████ | 986/1090 [1:11:22<03:44,  2.16s/it] 91%|█████████ | 987/1090 [1:11:25<03:43,  2.17s/it] 91%|█████████ | 988/1090 [1:11:27<03:43,  2.19s/it] 91%|█████████ | 989/1090 [1:11:29<03:38,  2.16s/it] 91%|█████████ | 990/1090 [1:11:31<03:33,  2.13s/it] 91%|█████████ | 991/1090 [1:11:33<03:28,  2.11s/it] 91%|█████████ | 992/1090 [1:11:35<03:28,  2.13s/it] 91%|█████████ | 993/1090 [1:11:37<03:25,  2.12s/it] 91%|█████████ | 994/1090 [1:11:40<03:26,  2.15s/it] 91%|█████████▏| 995/1090 [1:11:42<03:22,  2.13s/it] 91%|█████████▏| 996/1090 [1:11:44<03:27,  2.21s/it] 91%|█████████▏| 997/1090 [1:11:46<03:21,  2.17s/it] 92%|█████████▏| 998/1090 [1:11:48<03:19,  2.17s/it] 92%|█████████▏| 999/1090 [1:11:50<03:15,  2.15s/it] 92%|█████████▏| 1000/1090 [1:11:53<03:16,  2.19s/it]                                                     {'loss': 0.4403, 'learning_rate': 4.128440366972477e-06, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:11:53<03:16,  2.19s/it]
  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:18<13:42,  9.04s/it][A
  3%|▎         | 3/93 [00:40<21:56, 14.62s/it][A
  4%|▍         | 4/93 [01:05<27:17, 18.40s/it][A
  5%|▌         | 5/93 [01:28<29:24, 20.05s/it][A
  6%|▋         | 6/93 [01:50<30:17, 20.89s/it][A
  8%|▊         | 7/93 [02:12<30:03, 20.97s/it][A
  9%|▊         | 8/93 [02:33<29:56, 21.13s/it][A
 10%|▉         | 9/93 [02:58<31:02, 22.17s/it][A
 11%|█         | 10/93 [03:20<30:34, 22.10s/it][A
 12%|█▏        | 11/93 [03:44<31:03, 22.73s/it][A
 13%|█▎        | 12/93 [04:07<30:46, 22.80s/it][A
 14%|█▍        | 13/93 [04:30<30:48, 23.11s/it][A
 15%|█▌        | 14/93 [04:50<28:48, 21.88s/it][A
 16%|█▌        | 15/93 [05:12<28:44, 22.11s/it][A
 17%|█▋        | 16/93 [05:37<29:25, 22.93s/it][A
 18%|█▊        | 17/93 [06:01<29:24, 23.22s/it][A
 19%|█▉        | 18/93 [06:24<29:02, 23.24s/it][A
 20%|██        | 19/93 [06:49<29:16, 23.73s/it][A
 22%|██▏       | 20/93 [07:11<28:22, 23.32s/it][A
 23%|██▎       | 21/93 [07:35<28:07, 23.43s/it][A
 24%|██▎       | 22/93 [07:59<27:57, 23.63s/it][A
 25%|██▍       | 23/93 [08:22<27:19, 23.42s/it][A
 26%|██▌       | 24/93 [08:45<26:36, 23.14s/it][A
 27%|██▋       | 25/93 [09:06<25:36, 22.60s/it][A
 28%|██▊       | 26/93 [09:31<25:55, 23.22s/it][A
 29%|██▉       | 27/93 [09:55<25:58, 23.61s/it][A
 30%|███       | 28/93 [10:19<25:48, 23.82s/it][A
 31%|███       | 29/93 [10:43<25:10, 23.60s/it][A
 32%|███▏      | 30/93 [11:03<23:42, 22.58s/it][A
 33%|███▎      | 31/93 [11:24<23:01, 22.28s/it][A
 34%|███▍      | 32/93 [11:49<23:14, 22.86s/it][A
 35%|███▌      | 33/93 [12:12<23:04, 23.08s/it][A
 37%|███▋      | 34/93 [12:37<23:10, 23.57s/it][A
 38%|███▊      | 35/93 [12:59<22:23, 23.16s/it][A
 39%|███▊      | 36/93 [13:21<21:38, 22.79s/it][A
 40%|███▉      | 37/93 [13:44<21:27, 23.00s/it][A
 41%|████      | 38/93 [14:07<20:52, 22.77s/it][A
 42%|████▏     | 39/93 [14:31<21:00, 23.34s/it][A
 43%|████▎     | 40/93 [14:56<20:58, 23.75s/it][A
 44%|████▍     | 41/93 [15:19<20:27, 23.60s/it][A
 45%|████▌     | 42/93 [15:42<19:46, 23.26s/it][A
 46%|████▌     | 43/93 [16:07<19:45, 23.70s/it][A
 47%|████▋     | 44/93 [16:31<19:33, 23.94s/it][A
 48%|████▊     | 45/93 [16:55<19:13, 24.03s/it][A
 49%|████▉     | 46/93 [17:19<18:46, 23.96s/it][A
 51%|█████     | 47/93 [17:40<17:38, 23.01s/it][A
 52%|█████▏    | 48/93 [18:05<17:39, 23.53s/it][A
 53%|█████▎    | 49/93 [18:27<17:06, 23.33s/it][A
 54%|█████▍    | 50/93 [18:47<15:52, 22.16s/it][A
 55%|█████▍    | 51/93 [19:07<15:01, 21.47s/it][A
 56%|█████▌    | 52/93 [19:31<15:16, 22.36s/it][A
 57%|█████▋    | 53/93 [19:53<14:48, 22.21s/it][A
 58%|█████▊    | 54/93 [20:16<14:40, 22.56s/it][A
 59%|█████▉    | 55/93 [20:38<14:00, 22.12s/it][A
 60%|██████    | 56/93 [21:01<13:58, 22.66s/it][A
 61%|██████▏   | 57/93 [21:24<13:40, 22.78s/it][A
 62%|██████▏   | 58/93 [21:48<13:27, 23.06s/it][A
 63%|██████▎   | 59/93 [22:11<13:02, 23.01s/it][A
 65%|██████▍   | 60/93 [22:35<12:47, 23.26s/it][A
 66%|██████▌   | 61/93 [22:57<12:14, 22.96s/it][A
 67%|██████▋   | 62/93 [23:21<11:59, 23.21s/it][A
 68%|██████▊   | 63/93 [23:46<11:48, 23.61s/it][A
 69%|██████▉   | 64/93 [24:07<11:03, 22.88s/it][A
 70%|██████▉   | 65/93 [24:31<10:56, 23.44s/it][A
 71%|███████   | 66/93 [24:53<10:15, 22.81s/it][A
 72%|███████▏  | 67/93 [25:14<09:37, 22.20s/it][A
 73%|███████▎  | 68/93 [25:38<09:34, 22.96s/it][A
 74%|███████▍  | 69/93 [26:03<09:23, 23.49s/it][A
 75%|███████▌  | 70/93 [26:25<08:50, 23.05s/it][A
 76%|███████▋  | 71/93 [26:47<08:23, 22.86s/it][A
 77%|███████▋  | 72/93 [27:10<07:58, 22.80s/it][A
 78%|███████▊  | 73/93 [27:31<07:26, 22.30s/it][A
 80%|███████▉  | 74/93 [27:56<07:17, 23.04s/it][A
 81%|████████  | 75/93 [28:20<06:59, 23.29s/it][A
 82%|████████▏ | 76/93 [28:45<06:43, 23.73s/it][A
 83%|████████▎ | 77/93 [29:09<06:20, 23.77s/it][A
 84%|████████▍ | 78/93 [29:28<05:36, 22.42s/it][A
 85%|████████▍ | 79/93 [29:52<05:23, 23.11s/it][A
 86%|████████▌ | 80/93 [30:16<05:01, 23.19s/it][A
 87%|████████▋ | 81/93 [30:39<04:38, 23.19s/it][A
 88%|████████▊ | 82/93 [31:03<04:17, 23.38s/it][A
 89%|████████▉ | 83/93 [31:24<03:47, 22.79s/it][A
 90%|█████████ | 84/93 [31:48<03:27, 23.10s/it][A
 91%|█████████▏| 85/93 [32:05<02:50, 21.34s/it][A
 92%|█████████▏| 86/93 [32:27<02:30, 21.44s/it][A
 94%|█████████▎| 87/93 [32:52<02:14, 22.39s/it][A
 95%|█████████▍| 88/93 [33:13<01:50, 22.07s/it][A
 96%|█████████▌| 89/93 [33:32<01:24, 21.21s/it][A
 97%|█████████▋| 90/93 [33:56<01:05, 22.00s/it][A
 98%|█████████▊| 91/93 [34:17<00:43, 21.73s/it][A
 99%|█████████▉| 92/93 [34:42<00:22, 22.63s/it][A
100%|██████████| 93/93 [35:02<00:00, 21.74s/it][A                                                     
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 40.1785, 'eval_rouge2': 17.0364, 'eval_rougeL': 27.8337, 'eval_rougeLsum': 37.5134, 'eval_gen_len': 71.42103494623656, 'eval_runtime': 2140.2252, 'eval_samples_per_second': 1.402, 'eval_steps_per_second': 0.044, 'eval_block_avg': 15.211847789497304, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:47:33<03:16,  2.19s/it]
100%|██████████| 93/93 [35:18<00:00, 21.74s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 07:31:18,030 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-1000
[INFO|configuration_utils.py:457] 2024-05-24 07:31:18,031 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/config.json
[INFO|configuration_utils.py:362] 2024-05-24 07:31:18,031 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 07:31:20,207 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 07:31:20,208 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 07:31:20,208 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 07:31:20,236 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-1000/spiece.model
 92%|█████████▏| 1001/1090 [1:47:37<15:56:38, 644.93s/it] 92%|█████████▏| 1002/1090 [1:47:40<11:03:05, 452.11s/it] 92%|█████████▏| 1003/1090 [1:47:42<7:39:55, 317.19s/it]  92%|█████████▏| 1004/1090 [1:47:44<5:19:13, 222.71s/it] 92%|█████████▏| 1005/1090 [1:47:46<3:41:48, 156.57s/it] 92%|█████████▏| 1006/1090 [1:47:49<2:34:24, 110.29s/it] 92%|█████████▏| 1007/1090 [1:47:51<1:47:39, 77.83s/it]  92%|█████████▏| 1008/1090 [1:47:53<1:15:18, 55.11s/it] 93%|█████████▎| 1009/1090 [1:47:55<52:56, 39.22s/it]   93%|█████████▎| 1010/1090 [1:47:57<37:26, 28.09s/it] 93%|█████████▎| 1011/1090 [1:47:59<26:42, 20.29s/it] 93%|█████████▎| 1012/1090 [1:48:01<19:16, 14.82s/it] 93%|█████████▎| 1013/1090 [1:48:03<14:08, 11.01s/it] 93%|█████████▎| 1014/1090 [1:48:06<10:37,  8.38s/it] 93%|█████████▎| 1015/1090 [1:48:08<08:09,  6.52s/it] 93%|█████████▎| 1016/1090 [1:48:10<06:22,  5.17s/it] 93%|█████████▎| 1017/1090 [1:48:12<05:09,  4.25s/it] 93%|█████████▎| 1018/1090 [1:48:14<04:21,  3.64s/it] 93%|█████████▎| 1019/1090 [1:48:16<03:46,  3.18s/it] 94%|█████████▎| 1020/1090 [1:48:18<03:21,  2.88s/it] 94%|█████████▎| 1021/1090 [1:48:21<03:02,  2.64s/it] 94%|█████████▍| 1022/1090 [1:48:23<02:50,  2.50s/it] 94%|█████████▍| 1023/1090 [1:48:25<02:41,  2.40s/it] 94%|█████████▍| 1024/1090 [1:48:27<02:35,  2.36s/it] 94%|█████████▍| 1025/1090 [1:48:30<02:34,  2.38s/it] 94%|█████████▍| 1026/1090 [1:48:32<02:30,  2.36s/it] 94%|█████████▍| 1027/1090 [1:48:34<02:25,  2.31s/it] 94%|█████████▍| 1028/1090 [1:48:36<02:22,  2.30s/it] 94%|█████████▍| 1029/1090 [1:48:38<02:14,  2.21s/it] 94%|█████████▍| 1030/1090 [1:48:40<02:10,  2.17s/it] 95%|█████████▍| 1031/1090 [1:48:43<02:07,  2.16s/it] 95%|█████████▍| 1032/1090 [1:48:45<02:06,  2.18s/it] 95%|█████████▍| 1033/1090 [1:48:47<02:03,  2.16s/it] 95%|█████████▍| 1034/1090 [1:48:49<02:02,  2.19s/it] 95%|█████████▍| 1035/1090 [1:48:51<01:59,  2.17s/it] 95%|█████████▌| 1036/1090 [1:48:54<01:57,  2.18s/it] 95%|█████████▌| 1037/1090 [1:48:56<01:55,  2.18s/it] 95%|█████████▌| 1038/1090 [1:48:58<01:50,  2.13s/it] 95%|█████████▌| 1039/1090 [1:49:00<01:50,  2.16s/it] 95%|█████████▌| 1040/1090 [1:49:02<01:50,  2.21s/it] 96%|█████████▌| 1041/1090 [1:49:04<01:47,  2.19s/it] 96%|█████████▌| 1042/1090 [1:49:07<01:44,  2.18s/it] 96%|█████████▌| 1043/1090 [1:49:09<01:42,  2.18s/it] 96%|█████████▌| 1044/1090 [1:49:11<01:39,  2.15s/it] 96%|█████████▌| 1045/1090 [1:49:13<01:35,  2.13s/it] 96%|█████████▌| 1046/1090 [1:49:15<01:33,  2.12s/it] 96%|█████████▌| 1047/1090 [1:49:17<01:32,  2.15s/it] 96%|█████████▌| 1048/1090 [1:49:19<01:30,  2.15s/it] 96%|█████████▌| 1049/1090 [1:49:22<01:28,  2.16s/it] 96%|█████████▋| 1050/1090 [1:49:24<01:24,  2.12s/it] 96%|█████████▋| 1051/1090 [1:49:26<01:23,  2.13s/it] 97%|█████████▋| 1052/1090 [1:49:28<01:21,  2.14s/it] 97%|█████████▋| 1053/1090 [1:49:30<01:19,  2.14s/it] 97%|█████████▋| 1054/1090 [1:49:32<01:15,  2.09s/it] 97%|█████████▋| 1055/1090 [1:49:34<01:13,  2.11s/it] 97%|█████████▋| 1056/1090 [1:49:36<01:11,  2.10s/it] 97%|█████████▋| 1057/1090 [1:49:39<01:11,  2.16s/it] 97%|█████████▋| 1058/1090 [1:49:41<01:08,  2.15s/it] 97%|█████████▋| 1059/1090 [1:49:43<01:09,  2.23s/it] 97%|█████████▋| 1060/1090 [1:49:45<01:06,  2.23s/it] 97%|█████████▋| 1061/1090 [1:49:48<01:04,  2.22s/it] 97%|█████████▋| 1062/1090 [1:49:50<01:01,  2.19s/it] 98%|█████████▊| 1063/1090 [1:49:52<00:58,  2.17s/it] 98%|█████████▊| 1064/1090 [1:49:54<00:56,  2.15s/it] 98%|█████████▊| 1065/1090 [1:49:56<00:53,  2.15s/it] 98%|█████████▊| 1066/1090 [1:49:58<00:52,  2.18s/it] 98%|█████████▊| 1067/1090 [1:50:00<00:49,  2.15s/it] 98%|█████████▊| 1068/1090 [1:50:03<00:47,  2.16s/it] 98%|█████████▊| 1069/1090 [1:50:05<00:45,  2.17s/it] 98%|█████████▊| 1070/1090 [1:50:07<00:44,  2.23s/it] 98%|█████████▊| 1071/1090 [1:50:09<00:41,  2.16s/it] 98%|█████████▊| 1072/1090 [1:50:11<00:38,  2.14s/it] 98%|█████████▊| 1073/1090 [1:50:13<00:36,  2.14s/it] 99%|█████████▊| 1074/1090 [1:50:15<00:33,  2.12s/it] 99%|█████████▊| 1075/1090 [1:50:17<00:31,  2.10s/it] 99%|█████████▊| 1076/1090 [1:50:20<00:29,  2.11s/it] 99%|█████████▉| 1077/1090 [1:50:22<00:27,  2.12s/it] 99%|█████████▉| 1078/1090 [1:50:24<00:25,  2.12s/it] 99%|█████████▉| 1079/1090 [1:50:26<00:24,  2.20s/it] 99%|█████████▉| 1080/1090 [1:50:28<00:21,  2.17s/it] 99%|█████████▉| 1081/1090 [1:50:30<00:19,  2.15s/it] 99%|█████████▉| 1082/1090 [1:50:33<00:17,  2.15s/it] 99%|█████████▉| 1083/1090 [1:50:35<00:14,  2.14s/it] 99%|█████████▉| 1084/1090 [1:50:37<00:12,  2.11s/it]100%|█████████▉| 1085/1090 [1:50:39<00:10,  2.15s/it]100%|█████████▉| 1086/1090 [1:50:41<00:08,  2.17s/it]100%|█████████▉| 1087/1090 [1:50:43<00:06,  2.17s/it]100%|█████████▉| 1088/1090 [1:50:46<00:04,  2.16s/it]100%|█████████▉| 1089/1090 [1:50:48<00:02,  2.14s/it]100%|██████████| 1090/1090 [1:50:50<00:00,  2.12s/it][INFO|trainer.py:2039] 2024-05-24 07:34:34,843 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2172] 2024-05-24 07:34:34,843 >> Loading best model from src/save/cnndm_t5_large/checkpoint-500 (score: 37.7674).
                                                     {'train_runtime': 6651.1153, 'train_samples_per_second': 5.262, 'train_steps_per_second': 0.164, 'train_loss': 0.4498339696761665, 'epoch': 5.0}
100%|██████████| 1090/1090 [1:50:51<00:00,  2.12s/it][INFO|trainer.py:2073] 2024-05-24 07:34:35,734 >> Deleting older checkpoint [src/save/cnndm_t5_large/checkpoint-1000] due to args.save_total_limit
100%|██████████| 1090/1090 [1:50:51<00:00,  6.10s/it]
[INFO|trainer.py:2868] 2024-05-24 07:34:35,942 >> Saving model checkpoint to src/save/cnndm_t5_large/
[INFO|configuration_utils.py:457] 2024-05-24 07:34:35,943 >> Configuration saved in src/save/cnndm_t5_large/config.json
[INFO|configuration_utils.py:362] 2024-05-24 07:34:35,944 >> Configuration saved in src/save/cnndm_t5_large/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 07:34:38,104 >> Model weights saved in src/save/cnndm_t5_large/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 07:34:38,105 >> tokenizer config file saved in src/save/cnndm_t5_large/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 07:34:38,105 >> Special tokens file saved in src/save/cnndm_t5_large/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 07:34:38,133 >> Copy vocab file to src/save/cnndm_t5_large/spiece.model
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4498
  train_runtime            = 1:50:51.11
  train_samples            =       7000
  train_samples_per_second =      5.262
  train_steps_per_second   =      0.164
05/24/2024 07:34:38 - INFO - __main__ - *** Evaluate ***
  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:22<17:25, 11.49s/it]  3%|▎         | 3/93 [00:47<25:28, 16.99s/it]  4%|▍         | 4/93 [01:11<29:04, 19.60s/it]  5%|▌         | 5/93 [01:36<31:22, 21.39s/it]  6%|▋         | 6/93 [01:58<31:27, 21.70s/it]  8%|▊         | 7/93 [02:19<30:41, 21.41s/it]  9%|▊         | 8/93 [02:39<29:38, 20.93s/it] 10%|▉         | 9/93 [02:59<29:08, 20.82s/it] 11%|█         | 10/93 [03:23<29:49, 21.56s/it] 12%|█▏        | 11/93 [03:47<30:46, 22.52s/it] 13%|█▎        | 12/93 [04:11<30:46, 22.80s/it] 14%|█▍        | 13/93 [04:36<31:09, 23.36s/it] 15%|█▌        | 14/93 [04:55<29:04, 22.08s/it] 16%|█▌        | 15/93 [05:18<29:11, 22.45s/it] 17%|█▋        | 16/93 [05:41<28:57, 22.57s/it] 18%|█▊        | 17/93 [06:03<28:17, 22.33s/it] 19%|█▉        | 18/93 [06:26<28:27, 22.77s/it] 20%|██        | 19/93 [06:51<28:48, 23.35s/it] 22%|██▏       | 20/93 [07:12<27:36, 22.69s/it] 23%|██▎       | 21/93 [07:33<26:25, 22.01s/it] 24%|██▎       | 22/93 [07:56<26:35, 22.47s/it] 25%|██▍       | 23/93 [08:20<26:40, 22.87s/it] 26%|██▌       | 24/93 [08:44<26:36, 23.14s/it] 27%|██▋       | 25/93 [09:08<26:27, 23.34s/it] 28%|██▊       | 26/93 [09:30<25:53, 23.19s/it] 29%|██▉       | 27/93 [09:55<26:00, 23.64s/it] 30%|███       | 28/93 [10:19<25:39, 23.68s/it] 31%|███       | 29/93 [10:42<24:57, 23.39s/it] 32%|███▏      | 30/93 [11:05<24:41, 23.52s/it] 33%|███▎      | 31/93 [11:29<24:11, 23.41s/it] 34%|███▍      | 32/93 [11:53<24:14, 23.84s/it] 35%|███▌      | 33/93 [12:18<24:07, 24.13s/it] 37%|███▋      | 34/93 [12:43<23:54, 24.31s/it] 38%|███▊      | 35/93 [13:04<22:31, 23.30s/it] 39%|███▊      | 36/93 [13:26<21:43, 22.87s/it] 40%|███▉      | 37/93 [13:50<21:39, 23.21s/it] 41%|████      | 38/93 [14:14<21:40, 23.64s/it] 42%|████▏     | 39/93 [14:36<20:49, 23.14s/it] 43%|████▎     | 40/93 [14:58<20:00, 22.65s/it] 44%|████▍     | 41/93 [15:22<19:54, 22.98s/it] 45%|████▌     | 42/93 [15:43<19:04, 22.45s/it] 46%|████▌     | 43/93 [16:06<18:48, 22.58s/it] 47%|████▋     | 44/93 [16:26<17:56, 21.97s/it] 48%|████▊     | 45/93 [16:48<17:35, 21.99s/it] 49%|████▉     | 46/93 [17:13<17:52, 22.82s/it] 51%|█████     | 47/93 [17:34<17:07, 22.33s/it] 52%|█████▏    | 48/93 [17:57<16:49, 22.44s/it] 53%|█████▎    | 49/93 [18:22<16:57, 23.11s/it] 54%|█████▍    | 50/93 [18:41<15:41, 21.89s/it] 55%|█████▍    | 51/93 [19:03<15:19, 21.89s/it] 56%|█████▌    | 52/93 [19:26<15:14, 22.30s/it] 57%|█████▋    | 53/93 [19:49<15:01, 22.54s/it] 58%|█████▊    | 54/93 [20:10<14:26, 22.21s/it] 59%|█████▉    | 55/93 [20:33<14:12, 22.43s/it] 60%|██████    | 56/93 [20:56<13:52, 22.50s/it] 61%|██████▏   | 57/93 [21:20<13:44, 22.91s/it] 62%|██████▏   | 58/93 [21:43<13:27, 23.07s/it] 63%|██████▎   | 59/93 [22:06<13:05, 23.11s/it] 65%|██████▍   | 60/93 [22:31<12:58, 23.59s/it] 66%|██████▌   | 61/93 [22:54<12:25, 23.28s/it] 67%|██████▋   | 62/93 [23:18<12:14, 23.70s/it] 68%|██████▊   | 63/93 [23:41<11:41, 23.37s/it] 69%|██████▉   | 64/93 [24:05<11:26, 23.66s/it] 70%|██████▉   | 65/93 [24:29<10:59, 23.57s/it] 71%|███████   | 66/93 [24:52<10:36, 23.58s/it] 72%|███████▏  | 67/93 [25:14<10:01, 23.13s/it] 73%|███████▎  | 68/93 [25:35<09:16, 22.27s/it] 74%|███████▍  | 69/93 [25:58<09:02, 22.60s/it] 75%|███████▌  | 70/93 [26:22<08:49, 23.01s/it] 76%|███████▋  | 71/93 [26:47<08:37, 23.53s/it] 77%|███████▋  | 72/93 [27:11<08:16, 23.62s/it] 78%|███████▊  | 73/93 [27:35<07:58, 23.94s/it] 80%|███████▉  | 74/93 [27:56<07:19, 23.12s/it] 81%|████████  | 75/93 [28:20<06:59, 23.32s/it] 82%|████████▏ | 76/93 [28:44<06:37, 23.41s/it] 83%|████████▎ | 77/93 [29:06<06:06, 22.93s/it] 84%|████████▍ | 78/93 [29:28<05:39, 22.62s/it] 85%|████████▍ | 79/93 [29:52<05:25, 23.23s/it] 86%|████████▌ | 80/93 [30:15<05:02, 23.24s/it] 87%|████████▋ | 81/93 [30:38<04:37, 23.16s/it] 88%|████████▊ | 82/93 [31:02<04:15, 23.27s/it] 89%|████████▉ | 83/93 [31:27<03:57, 23.72s/it] 90%|█████████ | 84/93 [31:51<03:35, 23.95s/it] 91%|█████████▏| 85/93 [32:09<02:56, 22.03s/it] 92%|█████████▏| 86/93 [32:33<02:38, 22.65s/it] 94%|█████████▎| 87/93 [32:55<02:14, 22.49s/it] 95%|█████████▍| 88/93 [33:16<01:50, 22.09s/it] 96%|█████████▌| 89/93 [33:40<01:31, 22.75s/it] 97%|█████████▋| 90/93 [34:05<01:10, 23.34s/it] 98%|█████████▊| 91/93 [34:27<00:45, 22.96s/it] 99%|█████████▉| 92/93 [34:48<00:22, 22.16s/it]100%|██████████| 93/93 [35:09<00:00, 21.89s/it]100%|██████████| 93/93 [35:25<00:00, 22.86s/it]
***** eval metrics *****
  epoch                   =        5.0
  eval_block_avg          =    15.1918
  eval_gen_len            =     71.544
  eval_loss               =     1.4048
  eval_rouge1             =    40.4773
  eval_rouge2             =    17.4589
  eval_rougeL             =    28.2757
  eval_rougeLsum          =    37.7674
  eval_runtime            = 0:35:46.39
  eval_samples            =       3000
  eval_samples_per_second =      1.398
  eval_steps_per_second   =      0.044
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 08:10:35 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 08:10:35 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_08-10-35_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 08:10:41 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 08:10:41 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 08:10:41 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 08:10:41 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 08:10:41,510 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 08:10:41,511 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 08:10:41,638 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 08:10:41,761 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 08:10:41,762 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 08:10:41,995 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 08:10:41,996 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 08:10:41,996 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 08:10:41,996 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 08:10:41,996 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 08:10:41,996 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 08:10:41,997 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 08:10:42,045 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 08:10:43,323 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 08:11:09,585 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[WARNING|modeling_utils.py:3192] 2024-05-24 08:11:09,585 >> Some weights of EffT5ForConditionalGeneration were not initialized from the model checkpoint at checkpoints/CNNDM and are newly initialized: ['cm_head.0.weight', 'cm_head.2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:2839] 2024-05-24 08:11:09,593 >> Generation config file not found, using a generation config created from the model config.
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
05/24/2024 08:11:09 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 08:11:09 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Running tokenizer on validation dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 08:11:10 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
Running tokenizer on validation dataset:  33%|███▎      | 1000/3000 [00:00<00:01, 1223.25 examples/s]Running tokenizer on validation dataset:  67%|██████▋   | 2000/3000 [00:01<00:00, 1239.52 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1243.13 examples/s]Running tokenizer on validation dataset: 100%|██████████| 3000/3000 [00:02<00:00, 1235.77 examples/s]
[INFO|trainer.py:1769] 2024-05-24 08:11:13,911 >> ***** Running training *****
[INFO|trainer.py:1770] 2024-05-24 08:11:13,911 >>   Num examples = 7,000
[INFO|trainer.py:1771] 2024-05-24 08:11:13,911 >>   Num Epochs = 5
[INFO|trainer.py:1772] 2024-05-24 08:11:13,911 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1773] 2024-05-24 08:11:13,911 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1774] 2024-05-24 08:11:13,911 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1775] 2024-05-24 08:11:13,911 >>   Total optimization steps = 1,090
[INFO|trainer.py:1776] 2024-05-24 08:11:13,913 >>   Number of trainable parameters = 1,050,624
  0%|          | 0/1090 [00:00<?, ?it/s][WARNING|logging.py:280] 2024-05-24 08:11:13,930 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1090 [00:02<50:20,  2.77s/it]  0%|          | 2/1090 [00:04<43:58,  2.43s/it]  0%|          | 3/1090 [00:07<43:51,  2.42s/it]  0%|          | 4/1090 [00:09<43:55,  2.43s/it]  0%|          | 5/1090 [00:11<41:12,  2.28s/it]  1%|          | 6/1090 [00:14<41:07,  2.28s/it]  1%|          | 7/1090 [00:16<40:45,  2.26s/it]  1%|          | 8/1090 [00:18<40:31,  2.25s/it]  1%|          | 9/1090 [00:20<40:16,  2.24s/it]  1%|          | 10/1090 [00:22<40:18,  2.24s/it]  1%|          | 11/1090 [00:25<39:51,  2.22s/it]  1%|          | 12/1090 [00:27<40:06,  2.23s/it]  1%|          | 13/1090 [00:29<39:24,  2.20s/it]  1%|▏         | 14/1090 [00:31<39:19,  2.19s/it]  1%|▏         | 15/1090 [00:33<39:22,  2.20s/it]  1%|▏         | 16/1090 [00:36<39:40,  2.22s/it]  2%|▏         | 17/1090 [00:38<39:46,  2.22s/it]  2%|▏         | 18/1090 [00:40<39:52,  2.23s/it]  2%|▏         | 19/1090 [00:42<39:10,  2.19s/it]  2%|▏         | 20/1090 [00:45<39:18,  2.20s/it]  2%|▏         | 21/1090 [00:47<39:16,  2.20s/it]  2%|▏         | 22/1090 [00:49<39:41,  2.23s/it]  2%|▏         | 23/1090 [00:51<39:49,  2.24s/it]  2%|▏         | 24/1090 [00:54<40:59,  2.31s/it]  2%|▏         | 25/1090 [00:56<40:35,  2.29s/it]  2%|▏         | 26/1090 [00:58<40:28,  2.28s/it]  2%|▏         | 27/1090 [01:00<39:36,  2.24s/it]  3%|▎         | 28/1090 [01:03<39:15,  2.22s/it]  3%|▎         | 29/1090 [01:05<39:53,  2.26s/it]  3%|▎         | 30/1090 [01:07<39:33,  2.24s/it]  3%|▎         | 31/1090 [01:09<39:05,  2.21s/it]  3%|▎         | 32/1090 [01:12<39:35,  2.24s/it]  3%|▎         | 33/1090 [01:14<39:19,  2.23s/it]  3%|▎         | 34/1090 [01:16<38:59,  2.22s/it]  3%|▎         | 35/1090 [01:18<39:00,  2.22s/it]  3%|▎         | 36/1090 [01:20<39:08,  2.23s/it]  3%|▎         | 37/1090 [01:23<39:15,  2.24s/it]  3%|▎         | 38/1090 [01:25<38:01,  2.17s/it]  4%|▎         | 39/1090 [01:27<38:45,  2.21s/it]  4%|▎         | 40/1090 [01:29<37:52,  2.16s/it]  4%|▍         | 41/1090 [01:31<38:12,  2.19s/it]  4%|▍         | 42/1090 [01:33<37:55,  2.17s/it]  4%|▍         | 43/1090 [01:36<37:50,  2.17s/it]  4%|▍         | 44/1090 [01:38<37:24,  2.15s/it]  4%|▍         | 45/1090 [01:40<37:40,  2.16s/it]  4%|▍         | 46/1090 [01:42<37:44,  2.17s/it]  4%|▍         | 47/1090 [01:44<38:05,  2.19s/it]  4%|▍         | 48/1090 [01:47<38:55,  2.24s/it]  4%|▍         | 49/1090 [01:49<39:24,  2.27s/it]  5%|▍         | 50/1090 [01:51<38:12,  2.20s/it]  5%|▍         | 51/1090 [01:53<37:59,  2.19s/it]  5%|▍         | 52/1090 [01:55<37:40,  2.18s/it]  5%|▍         | 53/1090 [01:58<37:45,  2.18s/it]  5%|▍         | 54/1090 [02:00<37:31,  2.17s/it]  5%|▌         | 55/1090 [02:02<37:51,  2.19s/it]  5%|▌         | 56/1090 [02:04<37:49,  2.20s/it]  5%|▌         | 57/1090 [02:07<40:04,  2.33s/it]  5%|▌         | 58/1090 [02:09<39:24,  2.29s/it]  5%|▌         | 59/1090 [02:11<39:23,  2.29s/it]  6%|▌         | 60/1090 [02:13<38:04,  2.22s/it]  6%|▌         | 61/1090 [02:16<37:48,  2.20s/it]  6%|▌         | 62/1090 [02:18<38:27,  2.24s/it]  6%|▌         | 63/1090 [02:20<37:56,  2.22s/it]  6%|▌         | 64/1090 [02:22<37:44,  2.21s/it]  6%|▌         | 65/1090 [02:25<38:40,  2.26s/it]  6%|▌         | 66/1090 [02:27<37:28,  2.20s/it]  6%|▌         | 67/1090 [02:29<37:12,  2.18s/it]  6%|▌         | 68/1090 [02:31<36:45,  2.16s/it]  6%|▋         | 69/1090 [02:33<36:26,  2.14s/it]  6%|▋         | 70/1090 [02:35<37:09,  2.19s/it]  7%|▋         | 71/1090 [02:37<37:06,  2.19s/it]  7%|▋         | 72/1090 [02:40<37:31,  2.21s/it]  7%|▋         | 73/1090 [02:42<37:29,  2.21s/it]  7%|▋         | 74/1090 [02:44<37:50,  2.23s/it]  7%|▋         | 75/1090 [02:46<37:24,  2.21s/it]  7%|▋         | 76/1090 [02:49<36:57,  2.19s/it]  7%|▋         | 77/1090 [02:51<37:19,  2.21s/it]  7%|▋         | 78/1090 [02:53<37:17,  2.21s/it]  7%|▋         | 79/1090 [02:55<37:40,  2.24s/it]  7%|▋         | 80/1090 [02:58<38:17,  2.27s/it]  7%|▋         | 81/1090 [03:00<38:05,  2.27s/it]  8%|▊         | 82/1090 [03:02<37:43,  2.25s/it]  8%|▊         | 83/1090 [03:04<37:15,  2.22s/it]  8%|▊         | 84/1090 [03:07<37:32,  2.24s/it]  8%|▊         | 85/1090 [03:09<37:15,  2.22s/it]  8%|▊         | 86/1090 [03:11<37:14,  2.23s/it]  8%|▊         | 87/1090 [03:13<37:11,  2.22s/it]  8%|▊         | 88/1090 [03:15<37:05,  2.22s/it]  8%|▊         | 89/1090 [03:18<36:55,  2.21s/it]  8%|▊         | 90/1090 [03:20<37:32,  2.25s/it]  8%|▊         | 91/1090 [03:22<36:50,  2.21s/it]  8%|▊         | 92/1090 [03:24<36:52,  2.22s/it]  9%|▊         | 93/1090 [03:26<36:32,  2.20s/it]  9%|▊         | 94/1090 [03:29<38:15,  2.30s/it]  9%|▊         | 95/1090 [03:31<37:41,  2.27s/it]  9%|▉         | 96/1090 [03:33<36:57,  2.23s/it]  9%|▉         | 97/1090 [03:36<37:24,  2.26s/it]  9%|▉         | 98/1090 [03:38<37:37,  2.28s/it]  9%|▉         | 99/1090 [03:40<37:22,  2.26s/it]  9%|▉         | 100/1090 [03:42<36:54,  2.24s/it]  9%|▉         | 101/1090 [03:45<36:41,  2.23s/it]  9%|▉         | 102/1090 [03:47<36:52,  2.24s/it]  9%|▉         | 103/1090 [03:49<36:11,  2.20s/it] 10%|▉         | 104/1090 [03:51<36:32,  2.22s/it] 10%|▉         | 105/1090 [03:54<36:48,  2.24s/it] 10%|▉         | 106/1090 [03:56<36:42,  2.24s/it] 10%|▉         | 107/1090 [03:58<36:31,  2.23s/it] 10%|▉         | 108/1090 [04:00<36:29,  2.23s/it] 10%|█         | 109/1090 [04:03<36:56,  2.26s/it] 10%|█         | 110/1090 [04:05<36:47,  2.25s/it] 10%|█         | 111/1090 [04:07<37:10,  2.28s/it] 10%|█         | 112/1090 [04:09<37:31,  2.30s/it] 10%|█         | 113/1090 [04:12<37:35,  2.31s/it] 10%|█         | 114/1090 [04:14<37:12,  2.29s/it] 11%|█         | 115/1090 [04:16<36:59,  2.28s/it] 11%|█         | 116/1090 [04:18<36:26,  2.25s/it] 11%|█         | 117/1090 [04:21<36:07,  2.23s/it] 11%|█         | 118/1090 [04:23<35:16,  2.18s/it] 11%|█         | 119/1090 [04:25<35:27,  2.19s/it] 11%|█         | 120/1090 [04:27<36:18,  2.25s/it] 11%|█         | 121/1090 [04:29<35:37,  2.21s/it] 11%|█         | 122/1090 [04:32<36:09,  2.24s/it] 11%|█▏        | 123/1090 [04:34<35:16,  2.19s/it] 11%|█▏        | 124/1090 [04:36<37:46,  2.35s/it] 11%|█▏        | 125/1090 [04:39<37:23,  2.33s/it] 12%|█▏        | 126/1090 [04:41<37:08,  2.31s/it] 12%|█▏        | 127/1090 [04:43<37:12,  2.32s/it] 12%|█▏        | 128/1090 [04:46<36:16,  2.26s/it] 12%|█▏        | 129/1090 [04:48<37:00,  2.31s/it] 12%|█▏        | 130/1090 [04:50<36:28,  2.28s/it] 12%|█▏        | 131/1090 [04:52<36:29,  2.28s/it] 12%|█▏        | 132/1090 [04:55<35:50,  2.24s/it] 12%|█▏        | 133/1090 [04:57<35:36,  2.23s/it] 12%|█▏        | 134/1090 [05:00<38:08,  2.39s/it] 12%|█▏        | 135/1090 [05:02<37:49,  2.38s/it] 12%|█▏        | 136/1090 [05:04<37:14,  2.34s/it] 13%|█▎        | 137/1090 [05:06<36:42,  2.31s/it] 13%|█▎        | 138/1090 [05:09<35:40,  2.25s/it] 13%|█▎        | 139/1090 [05:11<35:12,  2.22s/it] 13%|█▎        | 140/1090 [05:13<34:50,  2.20s/it] 13%|█▎        | 141/1090 [05:15<35:29,  2.24s/it] 13%|█▎        | 142/1090 [05:17<34:29,  2.18s/it] 13%|█▎        | 143/1090 [05:19<34:12,  2.17s/it] 13%|█▎        | 144/1090 [05:22<35:37,  2.26s/it] 13%|█▎        | 145/1090 [05:24<36:17,  2.30s/it] 13%|█▎        | 146/1090 [05:26<35:09,  2.23s/it] 13%|█▎        | 147/1090 [05:29<35:25,  2.25s/it] 14%|█▎        | 148/1090 [05:31<34:54,  2.22s/it] 14%|█▎        | 149/1090 [05:33<35:37,  2.27s/it] 14%|█▍        | 150/1090 [05:35<35:58,  2.30s/it] 14%|█▍        | 151/1090 [05:38<36:40,  2.34s/it] 14%|█▍        | 152/1090 [05:40<36:05,  2.31s/it] 14%|█▍        | 153/1090 [05:42<35:57,  2.30s/it] 14%|█▍        | 154/1090 [05:45<35:05,  2.25s/it] 14%|█▍        | 155/1090 [05:47<34:42,  2.23s/it] 14%|█▍        | 156/1090 [05:49<35:37,  2.29s/it] 14%|█▍        | 157/1090 [05:51<35:28,  2.28s/it] 14%|█▍        | 158/1090 [05:54<36:11,  2.33s/it] 15%|█▍        | 159/1090 [05:56<36:02,  2.32s/it] 15%|█▍        | 160/1090 [05:59<36:39,  2.37s/it] 15%|█▍        | 161/1090 [06:01<36:07,  2.33s/it] 15%|█▍        | 162/1090 [06:03<35:30,  2.30s/it] 15%|█▍        | 163/1090 [06:05<34:32,  2.24s/it] 15%|█▌        | 164/1090 [06:07<33:59,  2.20s/it] 15%|█▌        | 165/1090 [06:10<35:02,  2.27s/it] 15%|█▌        | 166/1090 [06:12<34:36,  2.25s/it] 15%|█▌        | 167/1090 [06:14<34:16,  2.23s/it] 15%|█▌        | 168/1090 [06:17<34:48,  2.27s/it] 16%|█▌        | 169/1090 [06:19<34:03,  2.22s/it] 16%|█▌        | 170/1090 [06:21<34:50,  2.27s/it] 16%|█▌        | 171/1090 [06:23<35:10,  2.30s/it] 16%|█▌        | 172/1090 [06:25<34:20,  2.24s/it] 16%|█▌        | 173/1090 [06:28<33:54,  2.22s/it] 16%|█▌        | 174/1090 [06:30<33:20,  2.18s/it] 16%|█▌        | 175/1090 [06:32<33:20,  2.19s/it] 16%|█▌        | 176/1090 [06:34<33:09,  2.18s/it] 16%|█▌        | 177/1090 [06:36<34:04,  2.24s/it] 16%|█▋        | 178/1090 [06:39<33:45,  2.22s/it] 16%|█▋        | 179/1090 [06:41<34:29,  2.27s/it] 17%|█▋        | 180/1090 [06:43<34:27,  2.27s/it] 17%|█▋        | 181/1090 [06:45<33:14,  2.19s/it] 17%|█▋        | 182/1090 [06:47<33:02,  2.18s/it] 17%|█▋        | 183/1090 [06:50<33:31,  2.22s/it] 17%|█▋        | 184/1090 [06:52<33:17,  2.20s/it] 17%|█▋        | 185/1090 [06:54<34:20,  2.28s/it] 17%|█▋        | 186/1090 [06:56<33:06,  2.20s/it] 17%|█▋        | 187/1090 [06:59<33:51,  2.25s/it] 17%|█▋        | 188/1090 [07:01<33:25,  2.22s/it] 17%|█▋        | 189/1090 [07:03<33:37,  2.24s/it] 17%|█▋        | 190/1090 [07:06<34:12,  2.28s/it] 18%|█▊        | 191/1090 [07:08<33:02,  2.21s/it] 18%|█▊        | 192/1090 [07:10<33:06,  2.21s/it] 18%|█▊        | 193/1090 [07:12<33:03,  2.21s/it] 18%|█▊        | 194/1090 [07:14<33:01,  2.21s/it] 18%|█▊        | 195/1090 [07:17<33:27,  2.24s/it] 18%|█▊        | 196/1090 [07:19<33:03,  2.22s/it] 18%|█▊        | 197/1090 [07:21<33:38,  2.26s/it] 18%|█▊        | 198/1090 [07:23<34:01,  2.29s/it] 18%|█▊        | 199/1090 [07:26<33:02,  2.22s/it] 18%|█▊        | 200/1090 [07:28<32:50,  2.21s/it] 18%|█▊        | 201/1090 [07:30<34:02,  2.30s/it] 19%|█▊        | 202/1090 [07:33<34:04,  2.30s/it] 19%|█▊        | 203/1090 [07:35<33:02,  2.24s/it] 19%|█▊        | 204/1090 [07:37<32:44,  2.22s/it] 19%|█▉        | 205/1090 [07:39<32:41,  2.22s/it] 19%|█▉        | 206/1090 [07:41<32:34,  2.21s/it] 19%|█▉        | 207/1090 [07:43<32:09,  2.18s/it] 19%|█▉        | 208/1090 [07:46<32:30,  2.21s/it] 19%|█▉        | 209/1090 [07:48<31:40,  2.16s/it] 19%|█▉        | 210/1090 [07:50<32:35,  2.22s/it] 19%|█▉        | 211/1090 [07:52<32:37,  2.23s/it] 19%|█▉        | 212/1090 [07:54<32:25,  2.22s/it] 20%|█▉        | 213/1090 [07:57<32:09,  2.20s/it] 20%|█▉        | 214/1090 [07:59<32:32,  2.23s/it] 20%|█▉        | 215/1090 [08:01<32:15,  2.21s/it] 20%|█▉        | 216/1090 [08:04<35:09,  2.41s/it] 20%|█▉        | 217/1090 [08:06<34:09,  2.35s/it] 20%|██        | 218/1090 [08:09<34:22,  2.37s/it] 20%|██        | 219/1090 [08:11<34:02,  2.34s/it] 20%|██        | 220/1090 [08:13<32:49,  2.26s/it] 20%|██        | 221/1090 [08:15<32:55,  2.27s/it] 20%|██        | 222/1090 [08:17<32:13,  2.23s/it] 20%|██        | 223/1090 [08:20<33:11,  2.30s/it] 21%|██        | 224/1090 [08:22<33:24,  2.31s/it] 21%|██        | 225/1090 [08:25<34:14,  2.38s/it] 21%|██        | 226/1090 [08:27<33:29,  2.33s/it] 21%|██        | 227/1090 [08:29<32:20,  2.25s/it] 21%|██        | 228/1090 [08:31<31:51,  2.22s/it] 21%|██        | 229/1090 [08:34<33:02,  2.30s/it] 21%|██        | 230/1090 [08:36<31:54,  2.23s/it] 21%|██        | 231/1090 [08:38<32:36,  2.28s/it] 21%|██▏       | 232/1090 [08:40<31:53,  2.23s/it] 21%|██▏       | 233/1090 [08:42<31:22,  2.20s/it] 21%|██▏       | 234/1090 [08:45<31:27,  2.20s/it] 22%|██▏       | 235/1090 [08:47<31:22,  2.20s/it] 22%|██▏       | 236/1090 [08:49<32:17,  2.27s/it] 22%|██▏       | 237/1090 [08:51<31:45,  2.23s/it] 22%|██▏       | 238/1090 [08:53<31:15,  2.20s/it] 22%|██▏       | 239/1090 [08:56<31:14,  2.20s/it] 22%|██▏       | 240/1090 [08:58<32:00,  2.26s/it] 22%|██▏       | 241/1090 [09:00<31:42,  2.24s/it] 22%|██▏       | 242/1090 [09:02<31:11,  2.21s/it] 22%|██▏       | 243/1090 [09:05<32:00,  2.27s/it] 22%|██▏       | 244/1090 [09:07<32:00,  2.27s/it] 22%|██▏       | 245/1090 [09:10<33:41,  2.39s/it] 23%|██▎       | 246/1090 [09:12<33:06,  2.35s/it] 23%|██▎       | 247/1090 [09:14<32:21,  2.30s/it] 23%|██▎       | 248/1090 [09:16<32:07,  2.29s/it] 23%|██▎       | 249/1090 [09:19<32:10,  2.30s/it] 23%|██▎       | 250/1090 [09:21<32:23,  2.31s/it] 23%|██▎       | 251/1090 [09:23<32:10,  2.30s/it] 23%|██▎       | 252/1090 [09:26<32:31,  2.33s/it] 23%|██▎       | 253/1090 [09:28<31:55,  2.29s/it] 23%|██▎       | 254/1090 [09:30<31:50,  2.28s/it] 23%|██▎       | 255/1090 [09:33<31:57,  2.30s/it] 23%|██▎       | 256/1090 [09:35<31:38,  2.28s/it] 24%|██▎       | 257/1090 [09:37<31:16,  2.25s/it] 24%|██▎       | 258/1090 [09:39<31:29,  2.27s/it] 24%|██▍       | 259/1090 [09:41<31:08,  2.25s/it] 24%|██▍       | 260/1090 [09:44<31:10,  2.25s/it] 24%|██▍       | 261/1090 [09:46<31:02,  2.25s/it] 24%|██▍       | 262/1090 [09:48<30:56,  2.24s/it] 24%|██▍       | 263/1090 [09:50<30:54,  2.24s/it] 24%|██▍       | 264/1090 [09:53<30:53,  2.24s/it] 24%|██▍       | 265/1090 [09:55<30:47,  2.24s/it] 24%|██▍       | 266/1090 [09:57<30:50,  2.25s/it] 24%|██▍       | 267/1090 [09:59<31:00,  2.26s/it] 25%|██▍       | 268/1090 [10:02<31:07,  2.27s/it] 25%|██▍       | 269/1090 [10:04<30:57,  2.26s/it] 25%|██▍       | 270/1090 [10:06<30:42,  2.25s/it] 25%|██▍       | 271/1090 [10:08<30:30,  2.24s/it] 25%|██▍       | 272/1090 [10:11<30:24,  2.23s/it] 25%|██▌       | 273/1090 [10:13<30:11,  2.22s/it] 25%|██▌       | 274/1090 [10:15<30:07,  2.21s/it] 25%|██▌       | 275/1090 [10:17<29:58,  2.21s/it] 25%|██▌       | 276/1090 [10:19<29:46,  2.19s/it] 25%|██▌       | 277/1090 [10:22<29:37,  2.19s/it] 26%|██▌       | 278/1090 [10:24<29:52,  2.21s/it] 26%|██▌       | 279/1090 [10:26<30:07,  2.23s/it] 26%|██▌       | 280/1090 [10:28<29:40,  2.20s/it] 26%|██▌       | 281/1090 [10:30<29:45,  2.21s/it] 26%|██▌       | 282/1090 [10:33<29:26,  2.19s/it] 26%|██▌       | 283/1090 [10:35<29:52,  2.22s/it] 26%|██▌       | 284/1090 [10:37<30:19,  2.26s/it] 26%|██▌       | 285/1090 [10:39<30:07,  2.24s/it] 26%|██▌       | 286/1090 [10:42<30:22,  2.27s/it] 26%|██▋       | 287/1090 [10:44<30:57,  2.31s/it] 26%|██▋       | 288/1090 [10:46<30:16,  2.27s/it] 27%|██▋       | 289/1090 [10:49<30:13,  2.26s/it] 27%|██▋       | 290/1090 [10:51<30:21,  2.28s/it] 27%|██▋       | 291/1090 [10:53<30:39,  2.30s/it] 27%|██▋       | 292/1090 [10:55<29:50,  2.24s/it] 27%|██▋       | 293/1090 [10:58<29:28,  2.22s/it] 27%|██▋       | 294/1090 [11:00<28:57,  2.18s/it] 27%|██▋       | 295/1090 [11:02<28:45,  2.17s/it] 27%|██▋       | 296/1090 [11:04<28:50,  2.18s/it] 27%|██▋       | 297/1090 [11:06<29:01,  2.20s/it] 27%|██▋       | 298/1090 [11:08<28:54,  2.19s/it] 27%|██▋       | 299/1090 [11:11<30:07,  2.28s/it] 28%|██▊       | 300/1090 [11:13<29:22,  2.23s/it] 28%|██▊       | 301/1090 [11:16<30:55,  2.35s/it] 28%|██▊       | 302/1090 [11:18<30:05,  2.29s/it] 28%|██▊       | 303/1090 [11:20<29:07,  2.22s/it] 28%|██▊       | 304/1090 [11:22<28:47,  2.20s/it] 28%|██▊       | 305/1090 [11:24<28:22,  2.17s/it] 28%|██▊       | 306/1090 [11:26<28:10,  2.16s/it] 28%|██▊       | 307/1090 [11:28<28:24,  2.18s/it] 28%|██▊       | 308/1090 [11:31<28:04,  2.15s/it] 28%|██▊       | 309/1090 [11:33<27:54,  2.14s/it] 28%|██▊       | 310/1090 [11:35<28:01,  2.16s/it] 29%|██▊       | 311/1090 [11:37<28:08,  2.17s/it] 29%|██▊       | 312/1090 [11:39<29:05,  2.24s/it] 29%|██▊       | 313/1090 [11:42<29:07,  2.25s/it] 29%|██▉       | 314/1090 [11:44<28:28,  2.20s/it] 29%|██▉       | 315/1090 [11:46<28:15,  2.19s/it] 29%|██▉       | 316/1090 [11:48<28:52,  2.24s/it] 29%|██▉       | 317/1090 [11:51<29:29,  2.29s/it] 29%|██▉       | 318/1090 [11:53<29:37,  2.30s/it] 29%|██▉       | 319/1090 [11:55<29:32,  2.30s/it] 29%|██▉       | 320/1090 [11:58<28:57,  2.26s/it] 29%|██▉       | 321/1090 [12:00<29:46,  2.32s/it] 30%|██▉       | 322/1090 [12:02<29:40,  2.32s/it] 30%|██▉       | 323/1090 [12:04<28:35,  2.24s/it] 30%|██▉       | 324/1090 [12:07<29:30,  2.31s/it] 30%|██▉       | 325/1090 [12:09<29:28,  2.31s/it] 30%|██▉       | 326/1090 [12:11<28:51,  2.27s/it] 30%|███       | 327/1090 [12:13<28:28,  2.24s/it] 30%|███       | 328/1090 [12:16<28:56,  2.28s/it] 30%|███       | 329/1090 [12:18<28:23,  2.24s/it] 30%|███       | 330/1090 [12:21<29:29,  2.33s/it] 30%|███       | 331/1090 [12:23<29:14,  2.31s/it] 30%|███       | 332/1090 [12:25<28:39,  2.27s/it] 31%|███       | 333/1090 [12:27<27:44,  2.20s/it] 31%|███       | 334/1090 [12:29<28:05,  2.23s/it] 31%|███       | 335/1090 [12:31<27:14,  2.17s/it] 31%|███       | 336/1090 [12:34<27:33,  2.19s/it] 31%|███       | 337/1090 [12:36<27:34,  2.20s/it] 31%|███       | 338/1090 [12:38<26:54,  2.15s/it] 31%|███       | 339/1090 [12:40<26:41,  2.13s/it] 31%|███       | 340/1090 [12:42<26:59,  2.16s/it] 31%|███▏      | 341/1090 [12:44<27:00,  2.16s/it] 31%|███▏      | 342/1090 [12:47<27:11,  2.18s/it] 31%|███▏      | 343/1090 [12:49<27:07,  2.18s/it] 32%|███▏      | 344/1090 [12:51<26:50,  2.16s/it] 32%|███▏      | 345/1090 [12:53<27:09,  2.19s/it] 32%|███▏      | 346/1090 [12:55<27:31,  2.22s/it] 32%|███▏      | 347/1090 [12:58<27:21,  2.21s/it] 32%|███▏      | 348/1090 [13:00<27:43,  2.24s/it] 32%|███▏      | 349/1090 [13:02<27:29,  2.23s/it] 32%|███▏      | 350/1090 [13:04<27:19,  2.22s/it] 32%|███▏      | 351/1090 [13:07<27:25,  2.23s/it] 32%|███▏      | 352/1090 [13:09<27:21,  2.22s/it] 32%|███▏      | 353/1090 [13:11<27:03,  2.20s/it] 32%|███▏      | 354/1090 [13:13<27:37,  2.25s/it] 33%|███▎      | 355/1090 [13:15<27:13,  2.22s/it] 33%|███▎      | 356/1090 [13:18<27:44,  2.27s/it] 33%|███▎      | 357/1090 [13:20<27:08,  2.22s/it] 33%|███▎      | 358/1090 [13:22<27:11,  2.23s/it] 33%|███▎      | 359/1090 [13:24<26:51,  2.20s/it] 33%|███▎      | 360/1090 [13:26<26:15,  2.16s/it] 33%|███▎      | 361/1090 [13:29<26:28,  2.18s/it] 33%|███▎      | 362/1090 [13:31<27:23,  2.26s/it] 33%|███▎      | 363/1090 [13:33<26:41,  2.20s/it] 33%|███▎      | 364/1090 [13:35<26:24,  2.18s/it] 33%|███▎      | 365/1090 [13:37<26:19,  2.18s/it] 34%|███▎      | 366/1090 [13:40<26:14,  2.17s/it] 34%|███▎      | 367/1090 [13:42<26:13,  2.18s/it] 34%|███▍      | 368/1090 [13:44<26:15,  2.18s/it] 34%|███▍      | 369/1090 [13:46<26:50,  2.23s/it] 34%|███▍      | 370/1090 [13:48<26:21,  2.20s/it] 34%|███▍      | 371/1090 [13:51<26:13,  2.19s/it] 34%|███▍      | 372/1090 [13:53<26:24,  2.21s/it] 34%|███▍      | 373/1090 [13:55<26:17,  2.20s/it] 34%|███▍      | 374/1090 [13:57<26:07,  2.19s/it] 34%|███▍      | 375/1090 [13:59<26:12,  2.20s/it] 34%|███▍      | 376/1090 [14:02<26:09,  2.20s/it] 35%|███▍      | 377/1090 [14:04<26:12,  2.21s/it] 35%|███▍      | 378/1090 [14:06<26:35,  2.24s/it] 35%|███▍      | 379/1090 [14:08<26:41,  2.25s/it] 35%|███▍      | 380/1090 [14:11<26:12,  2.22s/it] 35%|███▍      | 381/1090 [14:13<26:21,  2.23s/it] 35%|███▌      | 382/1090 [14:15<26:39,  2.26s/it] 35%|███▌      | 383/1090 [14:17<26:22,  2.24s/it] 35%|███▌      | 384/1090 [14:20<26:16,  2.23s/it] 35%|███▌      | 385/1090 [14:22<26:31,  2.26s/it] 35%|███▌      | 386/1090 [14:24<26:19,  2.24s/it] 36%|███▌      | 387/1090 [14:26<26:35,  2.27s/it] 36%|███▌      | 388/1090 [14:29<26:41,  2.28s/it] 36%|███▌      | 389/1090 [14:31<26:40,  2.28s/it] 36%|███▌      | 390/1090 [14:33<26:11,  2.25s/it] 36%|███▌      | 391/1090 [14:35<25:57,  2.23s/it] 36%|███▌      | 392/1090 [14:38<26:27,  2.27s/it] 36%|███▌      | 393/1090 [14:40<25:45,  2.22s/it] 36%|███▌      | 394/1090 [14:42<25:19,  2.18s/it] 36%|███▌      | 395/1090 [14:44<25:26,  2.20s/it] 36%|███▋      | 396/1090 [14:47<26:05,  2.26s/it] 36%|███▋      | 397/1090 [14:48<24:58,  2.16s/it] 37%|███▋      | 398/1090 [14:51<24:48,  2.15s/it] 37%|███▋      | 399/1090 [14:53<24:33,  2.13s/it] 37%|███▋      | 400/1090 [14:55<24:42,  2.15s/it] 37%|███▋      | 401/1090 [14:57<24:33,  2.14s/it] 37%|███▋      | 402/1090 [14:59<24:57,  2.18s/it] 37%|███▋      | 403/1090 [15:01<24:55,  2.18s/it] 37%|███▋      | 404/1090 [15:04<24:58,  2.18s/it] 37%|███▋      | 405/1090 [15:06<25:00,  2.19s/it] 37%|███▋      | 406/1090 [15:08<25:10,  2.21s/it] 37%|███▋      | 407/1090 [15:10<25:22,  2.23s/it] 37%|███▋      | 408/1090 [15:13<25:32,  2.25s/it] 38%|███▊      | 409/1090 [15:15<26:02,  2.29s/it] 38%|███▊      | 410/1090 [15:17<25:22,  2.24s/it] 38%|███▊      | 411/1090 [15:19<24:52,  2.20s/it] 38%|███▊      | 412/1090 [15:21<24:49,  2.20s/it] 38%|███▊      | 413/1090 [15:24<25:18,  2.24s/it] 38%|███▊      | 414/1090 [15:26<25:24,  2.25s/it] 38%|███▊      | 415/1090 [15:28<25:44,  2.29s/it] 38%|███▊      | 416/1090 [15:31<25:03,  2.23s/it] 38%|███▊      | 417/1090 [15:33<24:44,  2.21s/it] 38%|███▊      | 418/1090 [15:35<24:29,  2.19s/it] 38%|███▊      | 419/1090 [15:37<25:12,  2.25s/it] 39%|███▊      | 420/1090 [15:40<25:56,  2.32s/it] 39%|███▊      | 421/1090 [15:42<25:34,  2.29s/it] 39%|███▊      | 422/1090 [15:44<25:09,  2.26s/it] 39%|███▉      | 423/1090 [15:46<25:28,  2.29s/it] 39%|███▉      | 424/1090 [15:48<24:29,  2.21s/it] 39%|███▉      | 425/1090 [15:51<24:44,  2.23s/it] 39%|███▉      | 426/1090 [15:53<24:29,  2.21s/it] 39%|███▉      | 427/1090 [15:55<24:55,  2.26s/it] 39%|███▉      | 428/1090 [15:57<24:25,  2.21s/it] 39%|███▉      | 429/1090 [16:00<24:38,  2.24s/it] 39%|███▉      | 430/1090 [16:02<23:55,  2.17s/it] 40%|███▉      | 431/1090 [16:04<24:29,  2.23s/it] 40%|███▉      | 432/1090 [16:07<25:13,  2.30s/it] 40%|███▉      | 433/1090 [16:09<25:04,  2.29s/it] 40%|███▉      | 434/1090 [16:11<25:05,  2.29s/it] 40%|███▉      | 435/1090 [16:13<24:15,  2.22s/it] 40%|████      | 436/1090 [16:15<24:06,  2.21s/it] 40%|████      | 437/1090 [16:17<23:36,  2.17s/it] 40%|████      | 438/1090 [16:20<23:25,  2.16s/it] 40%|████      | 439/1090 [16:22<23:23,  2.16s/it] 40%|████      | 440/1090 [16:24<23:44,  2.19s/it] 40%|████      | 441/1090 [16:26<23:40,  2.19s/it] 41%|████      | 442/1090 [16:28<23:55,  2.22s/it] 41%|████      | 443/1090 [16:31<24:00,  2.23s/it] 41%|████      | 444/1090 [16:33<24:06,  2.24s/it] 41%|████      | 445/1090 [16:35<24:11,  2.25s/it] 41%|████      | 446/1090 [16:37<23:58,  2.23s/it] 41%|████      | 447/1090 [16:40<23:51,  2.23s/it] 41%|████      | 448/1090 [16:42<23:48,  2.23s/it] 41%|████      | 449/1090 [16:44<23:31,  2.20s/it] 41%|████▏     | 450/1090 [16:46<23:24,  2.19s/it] 41%|████▏     | 451/1090 [16:49<23:50,  2.24s/it] 41%|████▏     | 452/1090 [16:51<23:48,  2.24s/it] 42%|████▏     | 453/1090 [16:53<23:35,  2.22s/it] 42%|████▏     | 454/1090 [16:55<23:49,  2.25s/it] 42%|████▏     | 455/1090 [16:57<23:16,  2.20s/it] 42%|████▏     | 456/1090 [17:00<23:10,  2.19s/it] 42%|████▏     | 457/1090 [17:02<23:02,  2.18s/it] 42%|████▏     | 458/1090 [17:04<23:26,  2.23s/it] 42%|████▏     | 459/1090 [17:06<23:21,  2.22s/it] 42%|████▏     | 460/1090 [17:08<23:15,  2.21s/it] 42%|████▏     | 461/1090 [17:11<23:41,  2.26s/it] 42%|████▏     | 462/1090 [17:13<23:35,  2.25s/it] 42%|████▏     | 463/1090 [17:15<23:15,  2.23s/it] 43%|████▎     | 464/1090 [17:17<22:56,  2.20s/it] 43%|████▎     | 465/1090 [17:20<23:13,  2.23s/it] 43%|████▎     | 466/1090 [17:22<23:34,  2.27s/it] 43%|████▎     | 467/1090 [17:24<23:37,  2.28s/it] 43%|████▎     | 468/1090 [17:27<23:30,  2.27s/it] 43%|████▎     | 469/1090 [17:29<23:19,  2.25s/it] 43%|████▎     | 470/1090 [17:31<23:23,  2.26s/it] 43%|████▎     | 471/1090 [17:33<23:16,  2.26s/it] 43%|████▎     | 472/1090 [17:36<23:37,  2.29s/it] 43%|████▎     | 473/1090 [17:38<23:30,  2.29s/it] 43%|████▎     | 474/1090 [17:40<22:42,  2.21s/it] 44%|████▎     | 475/1090 [17:42<22:33,  2.20s/it] 44%|████▎     | 476/1090 [17:44<22:28,  2.20s/it] 44%|████▍     | 477/1090 [17:47<22:48,  2.23s/it] 44%|████▍     | 478/1090 [17:49<23:25,  2.30s/it] 44%|████▍     | 479/1090 [17:51<23:30,  2.31s/it] 44%|████▍     | 480/1090 [17:54<23:07,  2.28s/it] 44%|████▍     | 481/1090 [17:56<23:07,  2.28s/it] 44%|████▍     | 482/1090 [17:58<23:07,  2.28s/it] 44%|████▍     | 483/1090 [18:00<23:02,  2.28s/it] 44%|████▍     | 484/1090 [18:03<23:26,  2.32s/it] 44%|████▍     | 485/1090 [18:05<22:56,  2.27s/it] 45%|████▍     | 486/1090 [18:07<22:56,  2.28s/it] 45%|████▍     | 487/1090 [18:09<22:22,  2.23s/it] 45%|████▍     | 488/1090 [18:12<22:04,  2.20s/it] 45%|████▍     | 489/1090 [18:14<21:57,  2.19s/it] 45%|████▍     | 490/1090 [18:16<21:52,  2.19s/it] 45%|████▌     | 491/1090 [18:18<21:37,  2.17s/it] 45%|████▌     | 492/1090 [18:20<21:31,  2.16s/it] 45%|████▌     | 493/1090 [18:22<21:27,  2.16s/it] 45%|████▌     | 494/1090 [18:25<21:31,  2.17s/it] 45%|████▌     | 495/1090 [18:27<21:49,  2.20s/it] 46%|████▌     | 496/1090 [18:29<22:00,  2.22s/it] 46%|████▌     | 497/1090 [18:31<21:56,  2.22s/it] 46%|████▌     | 498/1090 [18:33<21:38,  2.19s/it] 46%|████▌     | 499/1090 [18:36<21:46,  2.21s/it] 46%|████▌     | 500/1090 [18:38<21:52,  2.22s/it]                                                  {'loss': 0.5102, 'learning_rate': 2.7064220183486238e-05, 'epoch': 2.29}
 46%|████▌     | 500/1090 [18:38<21:52,  2.22s/it][INFO|configuration_utils.py:575] 2024-05-24 08:29:52,417 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}


  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:19<14:32,  9.58s/it][A
  3%|▎         | 3/93 [00:38<20:29, 13.66s/it][A
  4%|▍         | 4/93 [00:58<23:49, 16.06s/it][A
  5%|▌         | 5/93 [01:18<25:19, 17.27s/it][A
  6%|▋         | 6/93 [01:37<25:56, 17.89s/it][A
  8%|▊         | 7/93 [01:54<25:19, 17.67s/it][A
  9%|▊         | 8/93 [02:11<24:46, 17.49s/it][A
 10%|▉         | 9/93 [02:31<25:23, 18.14s/it][A
 11%|█         | 10/93 [02:50<25:29, 18.43s/it][A
 12%|█▏        | 11/93 [03:09<25:26, 18.62s/it][A
 13%|█▎        | 12/93 [03:28<25:20, 18.77s/it][A
 14%|█▍        | 13/93 [03:47<25:16, 18.95s/it][A
 15%|█▌        | 14/93 [04:07<25:05, 19.05s/it][A
 16%|█▌        | 15/93 [04:25<24:41, 19.00s/it][A
 17%|█▋        | 16/93 [04:44<24:05, 18.77s/it][A
 18%|█▊        | 17/93 [05:03<24:04, 19.01s/it][A
 19%|█▉        | 18/93 [05:25<24:52, 19.91s/it][A
 20%|██        | 19/93 [05:43<23:54, 19.38s/it][A
 22%|██▏       | 20/93 [06:03<23:32, 19.34s/it][A
 23%|██▎       | 21/93 [06:22<23:07, 19.27s/it][A
 24%|██▎       | 22/93 [06:39<22:04, 18.65s/it][A
 25%|██▍       | 23/93 [06:57<21:27, 18.40s/it][A
 26%|██▌       | 24/93 [07:17<21:44, 18.90s/it][A
 27%|██▋       | 25/93 [07:36<21:29, 18.97s/it][A
 28%|██▊       | 26/93 [07:54<20:58, 18.78s/it][A
 29%|██▉       | 27/93 [08:12<20:26, 18.59s/it][A
 30%|███       | 28/93 [08:29<19:28, 17.98s/it][A
 31%|███       | 29/93 [08:47<19:16, 18.07s/it][A
 32%|███▏      | 30/93 [09:06<19:01, 18.11s/it][A
 33%|███▎      | 31/93 [09:25<18:59, 18.38s/it][A
 34%|███▍      | 32/93 [09:41<18:05, 17.79s/it][A
 35%|███▌      | 33/93 [10:00<18:11, 18.20s/it][A
 37%|███▋      | 34/93 [10:19<18:08, 18.45s/it][A
 38%|███▊      | 35/93 [10:39<18:16, 18.91s/it][A
 39%|███▊      | 36/93 [10:58<18:00, 18.96s/it][A
 40%|███▉      | 37/93 [11:17<17:43, 18.99s/it][A
 41%|████      | 38/93 [11:36<17:25, 19.00s/it][A
 42%|████▏     | 39/93 [11:57<17:27, 19.39s/it][A
 43%|████▎     | 40/93 [12:16<17:01, 19.28s/it][A
 44%|████▍     | 41/93 [12:35<16:39, 19.21s/it][A
 45%|████▌     | 42/93 [12:54<16:23, 19.28s/it][A
 46%|████▌     | 43/93 [13:13<16:04, 19.30s/it][A
 47%|████▋     | 44/93 [13:32<15:41, 19.22s/it][A
 48%|████▊     | 45/93 [13:52<15:19, 19.17s/it][A
 49%|████▉     | 46/93 [14:10<14:49, 18.93s/it][A
 51%|█████     | 47/93 [14:29<14:32, 18.96s/it][A
 52%|█████▏    | 48/93 [14:47<14:02, 18.73s/it][A
 53%|█████▎    | 49/93 [15:06<13:48, 18.83s/it][A
 54%|█████▍    | 50/93 [15:25<13:33, 18.93s/it][A
 55%|█████▍    | 51/93 [15:44<13:07, 18.76s/it][A
 56%|█████▌    | 52/93 [16:02<12:43, 18.62s/it][A
 57%|█████▋    | 53/93 [16:21<12:32, 18.81s/it][A
 58%|█████▊    | 54/93 [16:41<12:22, 19.03s/it][A
 59%|█████▉    | 55/93 [16:57<11:33, 18.24s/it][A
 60%|██████    | 56/93 [17:17<11:36, 18.83s/it][A
 61%|██████▏   | 57/93 [17:35<10:59, 18.32s/it][A
 62%|██████▏   | 58/93 [17:54<10:50, 18.58s/it][A
 63%|██████▎   | 59/93 [18:13<10:40, 18.84s/it][A
 65%|██████▍   | 60/93 [18:33<10:27, 19.00s/it][A
 66%|██████▌   | 61/93 [18:52<10:08, 19.02s/it][A
 67%|██████▋   | 62/93 [19:12<09:59, 19.34s/it][A
 68%|██████▊   | 63/93 [19:27<09:05, 18.17s/it][A
 69%|██████▉   | 64/93 [19:46<08:54, 18.43s/it][A
 70%|██████▉   | 65/93 [20:05<08:36, 18.43s/it][A
 71%|███████   | 66/93 [20:21<08:03, 17.92s/it][A
 72%|███████▏  | 67/93 [20:40<07:48, 18.02s/it][A
 73%|███████▎  | 68/93 [20:59<07:40, 18.40s/it][A
 74%|███████▍  | 69/93 [21:17<07:21, 18.39s/it][A
 75%|███████▌  | 70/93 [21:37<07:09, 18.68s/it][A
 76%|███████▋  | 71/93 [21:57<06:59, 19.06s/it][A
 77%|███████▋  | 72/93 [22:16<06:40, 19.05s/it][A
 78%|███████▊  | 73/93 [22:35<06:22, 19.15s/it][A
 80%|███████▉  | 74/93 [22:53<05:58, 18.85s/it][A
 81%|████████  | 75/93 [23:13<05:45, 19.19s/it][A
 82%|████████▏ | 76/93 [23:28<05:03, 17.85s/it][A
 83%|████████▎ | 77/93 [23:45<04:43, 17.70s/it][A
 84%|████████▍ | 78/93 [24:04<04:31, 18.09s/it][A
 85%|████████▍ | 79/93 [24:21<04:10, 17.87s/it][A
 86%|████████▌ | 80/93 [24:42<04:01, 18.54s/it][A
 87%|████████▋ | 81/93 [25:01<03:43, 18.66s/it][A
 88%|████████▊ | 82/93 [25:18<03:20, 18.22s/it][A
 89%|████████▉ | 83/93 [25:36<03:02, 18.20s/it][A
 90%|█████████ | 84/93 [25:55<02:46, 18.48s/it][A
 91%|█████████▏| 85/93 [26:14<02:29, 18.65s/it][A
 92%|█████████▏| 86/93 [26:33<02:11, 18.83s/it][A
 94%|█████████▎| 87/93 [26:53<01:53, 18.93s/it][A
 95%|█████████▍| 88/93 [27:13<01:36, 19.31s/it][A
 96%|█████████▌| 89/93 [27:32<01:16, 19.23s/it][A
 97%|█████████▋| 90/93 [27:51<00:57, 19.20s/it][A
 98%|█████████▊| 91/93 [28:10<00:38, 19.18s/it][A
 99%|█████████▉| 92/93 [28:27<00:18, 18.66s/it][A
100%|██████████| 93/93 [28:48<00:00, 19.14s/it][A                                                  
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 28.5158, 'eval_rouge2': 11.4073, 'eval_rougeL': 20.815, 'eval_rougeLsum': 26.8295, 'eval_gen_len': 80.80443548387096, 'eval_runtime': 1759.7979, 'eval_samples_per_second': 1.705, 'eval_steps_per_second': 0.053, 'eval_block_avg': 9.977830518161033, 'epoch': 2.29}
 46%|████▌     | 500/1090 [47:58<21:52,  2.22s/it]
100%|██████████| 93/93 [29:04<00:00, 19.14s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 08:59:12,194 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-500
[INFO|configuration_utils.py:457] 2024-05-24 08:59:12,195 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/config.json
[INFO|configuration_utils.py:362] 2024-05-24 08:59:12,196 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 08:59:15,166 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 08:59:15,167 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 08:59:15,168 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 08:59:15,203 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-500/spiece.model
 46%|████▌     | 501/1090 [48:03<86:53:38, 531.10s/it] 46%|████▌     | 502/1090 [48:05<60:50:02, 372.45s/it] 46%|████▌     | 503/1090 [48:08<42:36:58, 261.36s/it] 46%|████▌     | 504/1090 [48:10<29:53:23, 183.62s/it] 46%|████▋     | 505/1090 [48:12<21:00:08, 129.24s/it] 46%|████▋     | 506/1090 [48:14<14:47:07, 91.14s/it]  47%|████▋     | 507/1090 [48:16<10:26:01, 64.43s/it] 47%|████▋     | 508/1090 [48:19<7:24:07, 45.79s/it]  47%|████▋     | 509/1090 [48:21<5:17:03, 32.74s/it] 47%|████▋     | 510/1090 [48:23<3:47:57, 23.58s/it] 47%|████▋     | 511/1090 [48:26<2:45:54, 17.19s/it] 47%|████▋     | 512/1090 [48:28<2:02:10, 12.68s/it] 47%|████▋     | 513/1090 [48:30<1:31:56,  9.56s/it] 47%|████▋     | 514/1090 [48:32<1:10:50,  7.38s/it] 47%|████▋     | 515/1090 [48:34<55:51,  5.83s/it]   47%|████▋     | 516/1090 [48:37<45:42,  4.78s/it] 47%|████▋     | 517/1090 [48:39<38:03,  3.98s/it] 48%|████▊     | 518/1090 [48:41<33:11,  3.48s/it] 48%|████▊     | 519/1090 [48:43<29:29,  3.10s/it] 48%|████▊     | 520/1090 [48:46<26:58,  2.84s/it] 48%|████▊     | 521/1090 [48:48<26:08,  2.76s/it] 48%|████▊     | 522/1090 [48:50<24:21,  2.57s/it] 48%|████▊     | 523/1090 [48:53<23:25,  2.48s/it] 48%|████▊     | 524/1090 [48:55<22:33,  2.39s/it] 48%|████▊     | 525/1090 [48:57<22:01,  2.34s/it] 48%|████▊     | 526/1090 [48:59<21:35,  2.30s/it] 48%|████▊     | 527/1090 [49:02<21:30,  2.29s/it] 48%|████▊     | 528/1090 [49:04<21:12,  2.26s/it] 49%|████▊     | 529/1090 [49:06<20:44,  2.22s/it] 49%|████▊     | 530/1090 [49:08<20:45,  2.22s/it] 49%|████▊     | 531/1090 [49:10<20:43,  2.22s/it] 49%|████▉     | 532/1090 [49:13<20:39,  2.22s/it] 49%|████▉     | 533/1090 [49:15<20:54,  2.25s/it] 49%|████▉     | 534/1090 [49:17<20:35,  2.22s/it] 49%|████▉     | 535/1090 [49:19<20:23,  2.20s/it] 49%|████▉     | 536/1090 [49:22<20:44,  2.25s/it] 49%|████▉     | 537/1090 [49:24<20:30,  2.23s/it] 49%|████▉     | 538/1090 [49:26<20:39,  2.25s/it] 49%|████▉     | 539/1090 [49:28<20:37,  2.25s/it] 50%|████▉     | 540/1090 [49:30<20:27,  2.23s/it] 50%|████▉     | 541/1090 [49:33<20:06,  2.20s/it] 50%|████▉     | 542/1090 [49:35<19:56,  2.18s/it] 50%|████▉     | 543/1090 [49:37<19:57,  2.19s/it] 50%|████▉     | 544/1090 [49:39<19:48,  2.18s/it] 50%|█████     | 545/1090 [49:41<19:58,  2.20s/it] 50%|█████     | 546/1090 [49:44<19:58,  2.20s/it] 50%|█████     | 547/1090 [49:46<19:52,  2.20s/it] 50%|█████     | 548/1090 [49:48<20:21,  2.25s/it] 50%|█████     | 549/1090 [49:50<20:14,  2.25s/it] 50%|█████     | 550/1090 [49:52<19:57,  2.22s/it] 51%|█████     | 551/1090 [49:55<20:00,  2.23s/it] 51%|█████     | 552/1090 [49:57<20:02,  2.24s/it] 51%|█████     | 553/1090 [49:59<20:05,  2.24s/it] 51%|█████     | 554/1090 [50:01<19:53,  2.23s/it] 51%|█████     | 555/1090 [50:04<19:56,  2.24s/it] 51%|█████     | 556/1090 [50:06<19:55,  2.24s/it] 51%|█████     | 557/1090 [50:08<19:44,  2.22s/it] 51%|█████     | 558/1090 [50:10<19:38,  2.22s/it] 51%|█████▏    | 559/1090 [50:13<19:39,  2.22s/it] 51%|█████▏    | 560/1090 [50:15<19:26,  2.20s/it] 51%|█████▏    | 561/1090 [50:17<19:18,  2.19s/it] 52%|█████▏    | 562/1090 [50:19<19:31,  2.22s/it] 52%|█████▏    | 563/1090 [50:21<19:20,  2.20s/it] 52%|█████▏    | 564/1090 [50:23<19:10,  2.19s/it] 52%|█████▏    | 565/1090 [50:26<19:21,  2.21s/it] 52%|█████▏    | 566/1090 [50:28<19:55,  2.28s/it] 52%|█████▏    | 567/1090 [50:30<19:38,  2.25s/it] 52%|█████▏    | 568/1090 [50:32<19:05,  2.19s/it] 52%|█████▏    | 569/1090 [50:34<18:40,  2.15s/it] 52%|█████▏    | 570/1090 [50:37<18:50,  2.17s/it] 52%|█████▏    | 571/1090 [50:39<18:33,  2.15s/it] 52%|█████▏    | 572/1090 [50:41<18:25,  2.13s/it] 53%|█████▎    | 573/1090 [50:43<18:27,  2.14s/it] 53%|█████▎    | 574/1090 [50:45<18:27,  2.15s/it] 53%|█████▎    | 575/1090 [50:47<18:23,  2.14s/it] 53%|█████▎    | 576/1090 [50:50<18:49,  2.20s/it] 53%|█████▎    | 577/1090 [50:52<19:04,  2.23s/it] 53%|█████▎    | 578/1090 [50:54<19:04,  2.24s/it] 53%|█████▎    | 579/1090 [50:56<18:43,  2.20s/it] 53%|█████▎    | 580/1090 [50:59<19:18,  2.27s/it] 53%|█████▎    | 581/1090 [51:01<19:09,  2.26s/it] 53%|█████▎    | 582/1090 [51:03<19:09,  2.26s/it] 53%|█████▎    | 583/1090 [51:06<19:14,  2.28s/it] 54%|█████▎    | 584/1090 [51:08<19:00,  2.25s/it] 54%|█████▎    | 585/1090 [51:10<18:51,  2.24s/it] 54%|█████▍    | 586/1090 [51:12<18:46,  2.24s/it] 54%|█████▍    | 587/1090 [51:14<18:38,  2.22s/it] 54%|█████▍    | 588/1090 [51:17<18:57,  2.27s/it] 54%|█████▍    | 589/1090 [51:19<18:51,  2.26s/it] 54%|█████▍    | 590/1090 [51:21<19:14,  2.31s/it] 54%|█████▍    | 591/1090 [51:24<19:00,  2.29s/it] 54%|█████▍    | 592/1090 [51:26<18:54,  2.28s/it] 54%|█████▍    | 593/1090 [51:28<18:36,  2.25s/it] 54%|█████▍    | 594/1090 [51:30<18:53,  2.29s/it] 55%|█████▍    | 595/1090 [51:33<18:19,  2.22s/it] 55%|█████▍    | 596/1090 [51:35<18:05,  2.20s/it] 55%|█████▍    | 597/1090 [51:37<18:02,  2.20s/it] 55%|█████▍    | 598/1090 [51:39<18:06,  2.21s/it] 55%|█████▍    | 599/1090 [51:41<18:21,  2.24s/it] 55%|█████▌    | 600/1090 [51:44<18:12,  2.23s/it] 55%|█████▌    | 601/1090 [51:46<18:13,  2.24s/it] 55%|█████▌    | 602/1090 [51:48<18:05,  2.22s/it] 55%|█████▌    | 603/1090 [51:50<18:18,  2.26s/it] 55%|█████▌    | 604/1090 [51:53<18:00,  2.22s/it] 56%|█████▌    | 605/1090 [51:55<18:00,  2.23s/it] 56%|█████▌    | 606/1090 [51:57<18:01,  2.23s/it] 56%|█████▌    | 607/1090 [51:59<17:56,  2.23s/it] 56%|█████▌    | 608/1090 [52:01<17:52,  2.22s/it] 56%|█████▌    | 609/1090 [52:04<18:05,  2.26s/it] 56%|█████▌    | 610/1090 [52:06<18:05,  2.26s/it] 56%|█████▌    | 611/1090 [52:08<18:10,  2.28s/it] 56%|█████▌    | 612/1090 [52:11<17:55,  2.25s/it] 56%|█████▌    | 613/1090 [52:13<18:09,  2.29s/it] 56%|█████▋    | 614/1090 [52:15<18:14,  2.30s/it] 56%|█████▋    | 615/1090 [52:18<17:59,  2.27s/it] 57%|█████▋    | 616/1090 [52:20<17:50,  2.26s/it] 57%|█████▋    | 617/1090 [52:22<17:46,  2.25s/it] 57%|█████▋    | 618/1090 [52:24<17:25,  2.22s/it] 57%|█████▋    | 619/1090 [52:26<17:45,  2.26s/it] 57%|█████▋    | 620/1090 [52:29<17:47,  2.27s/it] 57%|█████▋    | 621/1090 [52:31<17:52,  2.29s/it] 57%|█████▋    | 622/1090 [52:33<17:41,  2.27s/it] 57%|█████▋    | 623/1090 [52:36<17:32,  2.25s/it] 57%|█████▋    | 624/1090 [52:38<17:30,  2.25s/it] 57%|█████▋    | 625/1090 [52:40<17:35,  2.27s/it] 57%|█████▋    | 626/1090 [52:42<17:27,  2.26s/it] 58%|█████▊    | 627/1090 [52:45<17:24,  2.26s/it] 58%|█████▊    | 628/1090 [52:47<17:07,  2.22s/it] 58%|█████▊    | 629/1090 [52:49<16:59,  2.21s/it] 58%|█████▊    | 630/1090 [52:51<17:10,  2.24s/it] 58%|█████▊    | 631/1090 [52:54<17:25,  2.28s/it] 58%|█████▊    | 632/1090 [52:56<17:14,  2.26s/it] 58%|█████▊    | 633/1090 [52:58<17:14,  2.26s/it] 58%|█████▊    | 634/1090 [53:00<17:01,  2.24s/it] 58%|█████▊    | 635/1090 [53:03<17:02,  2.25s/it] 58%|█████▊    | 636/1090 [53:05<17:12,  2.27s/it] 58%|█████▊    | 637/1090 [53:07<17:00,  2.25s/it] 59%|█████▊    | 638/1090 [53:09<17:13,  2.29s/it] 59%|█████▊    | 639/1090 [53:12<17:06,  2.28s/it] 59%|█████▊    | 640/1090 [53:14<17:00,  2.27s/it] 59%|█████▉    | 641/1090 [53:16<17:18,  2.31s/it] 59%|█████▉    | 642/1090 [53:19<17:08,  2.30s/it] 59%|█████▉    | 643/1090 [53:21<17:09,  2.30s/it] 59%|█████▉    | 644/1090 [53:23<16:46,  2.26s/it] 59%|█████▉    | 645/1090 [53:25<16:34,  2.24s/it] 59%|█████▉    | 646/1090 [53:27<16:21,  2.21s/it] 59%|█████▉    | 647/1090 [53:30<16:12,  2.19s/it] 59%|█████▉    | 648/1090 [53:32<16:19,  2.22s/it] 60%|█████▉    | 649/1090 [53:34<16:22,  2.23s/it] 60%|█████▉    | 650/1090 [53:36<16:24,  2.24s/it] 60%|█████▉    | 651/1090 [53:39<16:25,  2.25s/it] 60%|█████▉    | 652/1090 [53:41<16:06,  2.21s/it] 60%|█████▉    | 653/1090 [53:43<16:18,  2.24s/it] 60%|██████    | 654/1090 [53:45<16:32,  2.28s/it] 60%|██████    | 655/1090 [53:48<16:23,  2.26s/it] 60%|██████    | 656/1090 [53:50<16:19,  2.26s/it] 60%|██████    | 657/1090 [53:52<16:18,  2.26s/it] 60%|██████    | 658/1090 [53:54<16:09,  2.24s/it] 60%|██████    | 659/1090 [53:57<16:04,  2.24s/it] 61%|██████    | 660/1090 [53:59<16:13,  2.26s/it] 61%|██████    | 661/1090 [54:01<15:55,  2.23s/it] 61%|██████    | 662/1090 [54:03<15:57,  2.24s/it] 61%|██████    | 663/1090 [54:06<15:59,  2.25s/it] 61%|██████    | 664/1090 [54:08<15:42,  2.21s/it] 61%|██████    | 665/1090 [54:10<16:03,  2.27s/it] 61%|██████    | 666/1090 [54:12<15:43,  2.22s/it] 61%|██████    | 667/1090 [54:15<15:49,  2.25s/it] 61%|██████▏   | 668/1090 [54:17<15:43,  2.24s/it] 61%|██████▏   | 669/1090 [54:19<15:29,  2.21s/it] 61%|██████▏   | 670/1090 [54:21<15:36,  2.23s/it] 62%|██████▏   | 671/1090 [54:23<15:46,  2.26s/it] 62%|██████▏   | 672/1090 [54:26<16:00,  2.30s/it] 62%|██████▏   | 673/1090 [54:28<15:53,  2.29s/it] 62%|██████▏   | 674/1090 [54:30<15:52,  2.29s/it] 62%|██████▏   | 675/1090 [54:33<15:51,  2.29s/it] 62%|██████▏   | 676/1090 [54:35<15:25,  2.24s/it] 62%|██████▏   | 677/1090 [54:37<15:19,  2.23s/it] 62%|██████▏   | 678/1090 [54:39<15:40,  2.28s/it] 62%|██████▏   | 679/1090 [54:42<15:37,  2.28s/it] 62%|██████▏   | 680/1090 [54:44<15:24,  2.26s/it] 62%|██████▏   | 681/1090 [54:46<15:36,  2.29s/it] 63%|██████▎   | 682/1090 [54:49<15:37,  2.30s/it] 63%|██████▎   | 683/1090 [54:51<15:21,  2.26s/it] 63%|██████▎   | 684/1090 [54:53<15:01,  2.22s/it] 63%|██████▎   | 685/1090 [54:55<14:54,  2.21s/it] 63%|██████▎   | 686/1090 [54:57<15:01,  2.23s/it] 63%|██████▎   | 687/1090 [55:00<14:59,  2.23s/it] 63%|██████▎   | 688/1090 [55:02<14:49,  2.21s/it] 63%|██████▎   | 689/1090 [55:04<15:22,  2.30s/it] 63%|██████▎   | 690/1090 [55:07<15:29,  2.32s/it] 63%|██████▎   | 691/1090 [55:09<15:10,  2.28s/it] 63%|██████▎   | 692/1090 [55:11<14:58,  2.26s/it] 64%|██████▎   | 693/1090 [55:13<14:52,  2.25s/it] 64%|██████▎   | 694/1090 [55:16<14:53,  2.26s/it] 64%|██████▍   | 695/1090 [55:18<14:48,  2.25s/it] 64%|██████▍   | 696/1090 [55:20<14:51,  2.26s/it] 64%|██████▍   | 697/1090 [55:22<14:48,  2.26s/it] 64%|██████▍   | 698/1090 [55:25<14:37,  2.24s/it] 64%|██████▍   | 699/1090 [55:27<14:33,  2.23s/it] 64%|██████▍   | 700/1090 [55:29<14:36,  2.25s/it] 64%|██████▍   | 701/1090 [55:31<14:26,  2.23s/it] 64%|██████▍   | 702/1090 [55:34<14:36,  2.26s/it] 64%|██████▍   | 703/1090 [55:36<14:34,  2.26s/it] 65%|██████▍   | 704/1090 [55:38<14:24,  2.24s/it] 65%|██████▍   | 705/1090 [55:40<14:21,  2.24s/it] 65%|██████▍   | 706/1090 [55:43<14:26,  2.26s/it] 65%|██████▍   | 707/1090 [55:45<14:14,  2.23s/it] 65%|██████▍   | 708/1090 [55:47<14:06,  2.21s/it] 65%|██████▌   | 709/1090 [55:49<14:10,  2.23s/it] 65%|██████▌   | 710/1090 [55:51<14:14,  2.25s/it] 65%|██████▌   | 711/1090 [55:54<14:20,  2.27s/it] 65%|██████▌   | 712/1090 [55:56<14:27,  2.30s/it] 65%|██████▌   | 713/1090 [55:58<14:19,  2.28s/it] 66%|██████▌   | 714/1090 [56:01<14:25,  2.30s/it] 66%|██████▌   | 715/1090 [56:03<14:25,  2.31s/it] 66%|██████▌   | 716/1090 [56:05<14:19,  2.30s/it] 66%|██████▌   | 717/1090 [56:07<13:59,  2.25s/it] 66%|██████▌   | 718/1090 [56:10<14:12,  2.29s/it] 66%|██████▌   | 719/1090 [56:12<13:59,  2.26s/it] 66%|██████▌   | 720/1090 [56:14<13:54,  2.25s/it] 66%|██████▌   | 721/1090 [56:17<13:52,  2.26s/it] 66%|██████▌   | 722/1090 [56:19<13:50,  2.26s/it] 66%|██████▋   | 723/1090 [56:21<13:30,  2.21s/it] 66%|██████▋   | 724/1090 [56:23<13:31,  2.22s/it] 67%|██████▋   | 725/1090 [56:25<13:37,  2.24s/it] 67%|██████▋   | 726/1090 [56:28<13:43,  2.26s/it] 67%|██████▋   | 727/1090 [56:30<13:32,  2.24s/it] 67%|██████▋   | 728/1090 [56:32<13:20,  2.21s/it] 67%|██████▋   | 729/1090 [56:34<13:18,  2.21s/it] 67%|██████▋   | 730/1090 [56:36<13:18,  2.22s/it] 67%|██████▋   | 731/1090 [56:39<13:14,  2.21s/it] 67%|██████▋   | 732/1090 [56:41<13:26,  2.25s/it] 67%|██████▋   | 733/1090 [56:43<13:06,  2.20s/it] 67%|██████▋   | 734/1090 [56:45<13:13,  2.23s/it] 67%|██████▋   | 735/1090 [56:48<12:56,  2.19s/it] 68%|██████▊   | 736/1090 [56:50<13:00,  2.21s/it] 68%|██████▊   | 737/1090 [56:52<12:46,  2.17s/it] 68%|██████▊   | 738/1090 [56:54<12:53,  2.20s/it] 68%|██████▊   | 739/1090 [56:56<13:03,  2.23s/it] 68%|██████▊   | 740/1090 [56:59<12:53,  2.21s/it] 68%|██████▊   | 741/1090 [57:01<12:51,  2.21s/it] 68%|██████▊   | 742/1090 [57:03<12:38,  2.18s/it] 68%|██████▊   | 743/1090 [57:05<12:37,  2.18s/it] 68%|██████▊   | 744/1090 [57:07<12:29,  2.17s/it] 68%|██████▊   | 745/1090 [57:09<12:30,  2.18s/it] 68%|██████▊   | 746/1090 [57:12<12:58,  2.26s/it] 69%|██████▊   | 747/1090 [57:14<12:42,  2.22s/it] 69%|██████▊   | 748/1090 [57:16<12:50,  2.25s/it] 69%|██████▊   | 749/1090 [57:19<12:52,  2.26s/it] 69%|██████▉   | 750/1090 [57:21<12:26,  2.19s/it] 69%|██████▉   | 751/1090 [57:23<12:14,  2.17s/it] 69%|██████▉   | 752/1090 [57:25<12:09,  2.16s/it] 69%|██████▉   | 753/1090 [57:27<12:12,  2.17s/it] 69%|██████▉   | 754/1090 [57:29<12:13,  2.18s/it] 69%|██████▉   | 755/1090 [57:31<12:09,  2.18s/it] 69%|██████▉   | 756/1090 [57:34<12:03,  2.17s/it] 69%|██████▉   | 757/1090 [57:36<12:34,  2.27s/it] 70%|██████▉   | 758/1090 [57:38<12:20,  2.23s/it] 70%|██████▉   | 759/1090 [57:40<12:08,  2.20s/it] 70%|██████▉   | 760/1090 [57:43<12:29,  2.27s/it] 70%|██████▉   | 761/1090 [57:45<12:27,  2.27s/it] 70%|██████▉   | 762/1090 [57:47<12:30,  2.29s/it] 70%|███████   | 763/1090 [57:50<12:27,  2.29s/it] 70%|███████   | 764/1090 [57:52<13:02,  2.40s/it] 70%|███████   | 765/1090 [57:55<12:48,  2.36s/it] 70%|███████   | 766/1090 [57:57<12:41,  2.35s/it] 70%|███████   | 767/1090 [57:59<12:28,  2.32s/it] 70%|███████   | 768/1090 [58:01<12:23,  2.31s/it] 71%|███████   | 769/1090 [58:04<12:23,  2.32s/it] 71%|███████   | 770/1090 [58:06<12:10,  2.28s/it] 71%|███████   | 771/1090 [58:08<11:44,  2.21s/it] 71%|███████   | 772/1090 [58:10<11:51,  2.24s/it] 71%|███████   | 773/1090 [58:13<11:45,  2.22s/it] 71%|███████   | 774/1090 [58:15<11:40,  2.22s/it] 71%|███████   | 775/1090 [58:17<11:57,  2.28s/it] 71%|███████   | 776/1090 [58:20<12:08,  2.32s/it] 71%|███████▏  | 777/1090 [58:22<11:38,  2.23s/it] 71%|███████▏  | 778/1090 [58:24<12:00,  2.31s/it] 71%|███████▏  | 779/1090 [58:26<11:42,  2.26s/it] 72%|███████▏  | 780/1090 [58:28<11:32,  2.23s/it] 72%|███████▏  | 781/1090 [58:31<11:20,  2.20s/it] 72%|███████▏  | 782/1090 [58:33<11:17,  2.20s/it] 72%|███████▏  | 783/1090 [58:35<11:14,  2.20s/it] 72%|███████▏  | 784/1090 [58:37<11:06,  2.18s/it] 72%|███████▏  | 785/1090 [58:39<10:58,  2.16s/it] 72%|███████▏  | 786/1090 [58:42<11:17,  2.23s/it] 72%|███████▏  | 787/1090 [58:44<11:13,  2.22s/it] 72%|███████▏  | 788/1090 [58:46<11:23,  2.26s/it] 72%|███████▏  | 789/1090 [58:48<11:05,  2.21s/it] 72%|███████▏  | 790/1090 [58:50<10:53,  2.18s/it] 73%|███████▎  | 791/1090 [58:53<10:51,  2.18s/it] 73%|███████▎  | 792/1090 [58:55<10:44,  2.16s/it] 73%|███████▎  | 793/1090 [58:57<10:43,  2.17s/it] 73%|███████▎  | 794/1090 [58:59<10:50,  2.20s/it] 73%|███████▎  | 795/1090 [59:01<10:42,  2.18s/it] 73%|███████▎  | 796/1090 [59:03<10:38,  2.17s/it] 73%|███████▎  | 797/1090 [59:06<10:30,  2.15s/it] 73%|███████▎  | 798/1090 [59:08<10:24,  2.14s/it] 73%|███████▎  | 799/1090 [59:10<10:26,  2.15s/it] 73%|███████▎  | 800/1090 [59:12<10:36,  2.19s/it] 73%|███████▎  | 801/1090 [59:14<10:38,  2.21s/it] 74%|███████▎  | 802/1090 [59:16<10:25,  2.17s/it] 74%|███████▎  | 803/1090 [59:19<10:24,  2.18s/it] 74%|███████▍  | 804/1090 [59:21<10:28,  2.20s/it] 74%|███████▍  | 805/1090 [59:23<10:16,  2.16s/it] 74%|███████▍  | 806/1090 [59:25<10:19,  2.18s/it] 74%|███████▍  | 807/1090 [59:27<10:13,  2.17s/it] 74%|███████▍  | 808/1090 [59:29<09:59,  2.13s/it] 74%|███████▍  | 809/1090 [59:31<10:00,  2.14s/it] 74%|███████▍  | 810/1090 [59:34<10:00,  2.15s/it] 74%|███████▍  | 811/1090 [59:36<09:58,  2.14s/it] 74%|███████▍  | 812/1090 [59:38<09:52,  2.13s/it] 75%|███████▍  | 813/1090 [59:40<09:48,  2.12s/it] 75%|███████▍  | 814/1090 [59:42<09:49,  2.14s/it] 75%|███████▍  | 815/1090 [59:44<09:44,  2.13s/it] 75%|███████▍  | 816/1090 [59:47<09:52,  2.16s/it] 75%|███████▍  | 817/1090 [59:49<09:55,  2.18s/it] 75%|███████▌  | 818/1090 [59:51<10:05,  2.23s/it] 75%|███████▌  | 819/1090 [59:53<09:56,  2.20s/it] 75%|███████▌  | 820/1090 [59:56<10:00,  2.23s/it] 75%|███████▌  | 821/1090 [59:58<10:04,  2.25s/it] 75%|███████▌  | 822/1090 [1:00:00<10:07,  2.27s/it] 76%|███████▌  | 823/1090 [1:00:02<10:10,  2.28s/it] 76%|███████▌  | 824/1090 [1:00:05<10:15,  2.31s/it] 76%|███████▌  | 825/1090 [1:00:07<10:11,  2.31s/it] 76%|███████▌  | 826/1090 [1:00:09<09:49,  2.23s/it] 76%|███████▌  | 827/1090 [1:00:11<09:50,  2.25s/it] 76%|███████▌  | 828/1090 [1:00:14<09:41,  2.22s/it] 76%|███████▌  | 829/1090 [1:00:16<09:37,  2.21s/it] 76%|███████▌  | 830/1090 [1:00:18<09:27,  2.18s/it] 76%|███████▌  | 831/1090 [1:00:20<09:22,  2.17s/it] 76%|███████▋  | 832/1090 [1:00:22<09:22,  2.18s/it] 76%|███████▋  | 833/1090 [1:00:24<09:13,  2.15s/it] 77%|███████▋  | 834/1090 [1:00:26<09:09,  2.15s/it] 77%|███████▋  | 835/1090 [1:00:29<09:16,  2.18s/it] 77%|███████▋  | 836/1090 [1:00:31<09:19,  2.20s/it] 77%|███████▋  | 837/1090 [1:00:33<09:13,  2.19s/it] 77%|███████▋  | 838/1090 [1:00:35<09:14,  2.20s/it] 77%|███████▋  | 839/1090 [1:00:38<09:17,  2.22s/it] 77%|███████▋  | 840/1090 [1:00:40<09:25,  2.26s/it] 77%|███████▋  | 841/1090 [1:00:42<09:15,  2.23s/it] 77%|███████▋  | 842/1090 [1:00:44<09:11,  2.22s/it] 77%|███████▋  | 843/1090 [1:00:47<09:08,  2.22s/it] 77%|███████▋  | 844/1090 [1:00:49<08:56,  2.18s/it] 78%|███████▊  | 845/1090 [1:00:51<09:03,  2.22s/it] 78%|███████▊  | 846/1090 [1:00:53<09:01,  2.22s/it] 78%|███████▊  | 847/1090 [1:00:56<09:06,  2.25s/it] 78%|███████▊  | 848/1090 [1:00:58<09:01,  2.24s/it] 78%|███████▊  | 849/1090 [1:01:00<09:12,  2.29s/it] 78%|███████▊  | 850/1090 [1:01:02<09:03,  2.27s/it] 78%|███████▊  | 851/1090 [1:01:05<09:03,  2.27s/it] 78%|███████▊  | 852/1090 [1:01:07<09:05,  2.29s/it] 78%|███████▊  | 853/1090 [1:01:09<08:50,  2.24s/it] 78%|███████▊  | 854/1090 [1:01:11<08:49,  2.24s/it] 78%|███████▊  | 855/1090 [1:01:14<08:48,  2.25s/it] 79%|███████▊  | 856/1090 [1:01:16<08:43,  2.24s/it] 79%|███████▊  | 857/1090 [1:01:18<08:46,  2.26s/it] 79%|███████▊  | 858/1090 [1:01:20<08:40,  2.24s/it] 79%|███████▉  | 859/1090 [1:01:23<08:36,  2.24s/it] 79%|███████▉  | 860/1090 [1:01:25<08:33,  2.23s/it] 79%|███████▉  | 861/1090 [1:01:27<08:32,  2.24s/it] 79%|███████▉  | 862/1090 [1:01:29<08:25,  2.22s/it] 79%|███████▉  | 863/1090 [1:01:31<08:26,  2.23s/it] 79%|███████▉  | 864/1090 [1:01:34<08:40,  2.30s/it] 79%|███████▉  | 865/1090 [1:01:36<08:32,  2.28s/it] 79%|███████▉  | 866/1090 [1:01:38<08:31,  2.28s/it] 80%|███████▉  | 867/1090 [1:01:41<08:27,  2.28s/it] 80%|███████▉  | 868/1090 [1:01:43<08:22,  2.26s/it] 80%|███████▉  | 869/1090 [1:01:45<08:14,  2.24s/it] 80%|███████▉  | 870/1090 [1:01:47<08:16,  2.26s/it] 80%|███████▉  | 871/1090 [1:01:50<08:08,  2.23s/it] 80%|████████  | 872/1090 [1:01:52<08:07,  2.23s/it] 80%|████████  | 873/1090 [1:01:54<08:19,  2.30s/it] 80%|████████  | 874/1090 [1:01:57<08:28,  2.36s/it] 80%|████████  | 875/1090 [1:01:59<08:19,  2.32s/it] 80%|████████  | 876/1090 [1:02:01<08:09,  2.29s/it] 80%|████████  | 877/1090 [1:02:04<08:07,  2.29s/it] 81%|████████  | 878/1090 [1:02:06<08:07,  2.30s/it] 81%|████████  | 879/1090 [1:02:08<08:05,  2.30s/it] 81%|████████  | 880/1090 [1:02:10<07:57,  2.27s/it] 81%|████████  | 881/1090 [1:02:13<07:54,  2.27s/it] 81%|████████  | 882/1090 [1:02:15<07:48,  2.25s/it] 81%|████████  | 883/1090 [1:02:17<07:53,  2.29s/it] 81%|████████  | 884/1090 [1:02:20<07:53,  2.30s/it] 81%|████████  | 885/1090 [1:02:22<07:46,  2.28s/it] 81%|████████▏ | 886/1090 [1:02:24<07:43,  2.27s/it] 81%|████████▏ | 887/1090 [1:02:26<07:43,  2.28s/it] 81%|████████▏ | 888/1090 [1:02:28<07:31,  2.24s/it] 82%|████████▏ | 889/1090 [1:02:31<07:34,  2.26s/it] 82%|████████▏ | 890/1090 [1:02:33<07:21,  2.21s/it] 82%|████████▏ | 891/1090 [1:02:35<07:17,  2.20s/it] 82%|████████▏ | 892/1090 [1:02:37<07:11,  2.18s/it] 82%|████████▏ | 893/1090 [1:02:39<07:11,  2.19s/it] 82%|████████▏ | 894/1090 [1:02:42<07:12,  2.21s/it] 82%|████████▏ | 895/1090 [1:02:44<07:03,  2.17s/it] 82%|████████▏ | 896/1090 [1:02:46<07:09,  2.21s/it] 82%|████████▏ | 897/1090 [1:02:48<07:08,  2.22s/it] 82%|████████▏ | 898/1090 [1:02:50<07:04,  2.21s/it] 82%|████████▏ | 899/1090 [1:02:53<07:02,  2.21s/it] 83%|████████▎ | 900/1090 [1:02:55<06:58,  2.20s/it] 83%|████████▎ | 901/1090 [1:02:57<06:52,  2.18s/it] 83%|████████▎ | 902/1090 [1:02:59<06:51,  2.19s/it] 83%|████████▎ | 903/1090 [1:03:01<06:56,  2.23s/it] 83%|████████▎ | 904/1090 [1:03:04<06:53,  2.22s/it] 83%|████████▎ | 905/1090 [1:03:06<06:49,  2.21s/it] 83%|████████▎ | 906/1090 [1:03:08<06:45,  2.20s/it] 83%|████████▎ | 907/1090 [1:03:10<06:45,  2.21s/it] 83%|████████▎ | 908/1090 [1:03:13<06:44,  2.22s/it] 83%|████████▎ | 909/1090 [1:03:15<06:36,  2.19s/it] 83%|████████▎ | 910/1090 [1:03:17<06:33,  2.19s/it] 84%|████████▎ | 911/1090 [1:03:19<06:26,  2.16s/it] 84%|████████▎ | 912/1090 [1:03:21<06:36,  2.23s/it] 84%|████████▍ | 913/1090 [1:03:23<06:29,  2.20s/it] 84%|████████▍ | 914/1090 [1:03:26<06:30,  2.22s/it] 84%|████████▍ | 915/1090 [1:03:28<06:34,  2.25s/it] 84%|████████▍ | 916/1090 [1:03:30<06:22,  2.20s/it] 84%|████████▍ | 917/1090 [1:03:33<06:32,  2.27s/it] 84%|████████▍ | 918/1090 [1:03:35<06:43,  2.35s/it] 84%|████████▍ | 919/1090 [1:03:37<06:43,  2.36s/it] 84%|████████▍ | 920/1090 [1:03:40<06:36,  2.33s/it] 84%|████████▍ | 921/1090 [1:03:42<06:29,  2.31s/it] 85%|████████▍ | 922/1090 [1:03:44<06:15,  2.23s/it] 85%|████████▍ | 923/1090 [1:03:46<06:11,  2.23s/it] 85%|████████▍ | 924/1090 [1:03:48<06:07,  2.21s/it] 85%|████████▍ | 925/1090 [1:03:51<06:11,  2.25s/it] 85%|████████▍ | 926/1090 [1:03:53<05:58,  2.19s/it] 85%|████████▌ | 927/1090 [1:03:55<05:58,  2.20s/it] 85%|████████▌ | 928/1090 [1:03:57<06:06,  2.26s/it] 85%|████████▌ | 929/1090 [1:04:00<05:54,  2.20s/it] 85%|████████▌ | 930/1090 [1:04:02<05:54,  2.22s/it] 85%|████████▌ | 931/1090 [1:04:04<06:04,  2.29s/it] 86%|████████▌ | 932/1090 [1:04:07<06:07,  2.32s/it] 86%|████████▌ | 933/1090 [1:04:09<05:59,  2.29s/it] 86%|████████▌ | 934/1090 [1:04:11<05:45,  2.22s/it] 86%|████████▌ | 935/1090 [1:04:13<05:40,  2.20s/it] 86%|████████▌ | 936/1090 [1:04:15<05:34,  2.17s/it] 86%|████████▌ | 937/1090 [1:04:17<05:29,  2.15s/it] 86%|████████▌ | 938/1090 [1:04:20<05:51,  2.31s/it] 86%|████████▌ | 939/1090 [1:04:22<05:49,  2.31s/it] 86%|████████▌ | 940/1090 [1:04:24<05:38,  2.25s/it] 86%|████████▋ | 941/1090 [1:04:27<05:34,  2.24s/it] 86%|████████▋ | 942/1090 [1:04:29<05:24,  2.20s/it] 87%|████████▋ | 943/1090 [1:04:31<05:24,  2.21s/it] 87%|████████▋ | 944/1090 [1:04:33<05:19,  2.19s/it] 87%|████████▋ | 945/1090 [1:04:35<05:26,  2.25s/it] 87%|████████▋ | 946/1090 [1:04:38<05:20,  2.23s/it] 87%|████████▋ | 947/1090 [1:04:40<05:12,  2.19s/it] 87%|████████▋ | 948/1090 [1:04:42<05:06,  2.16s/it] 87%|████████▋ | 949/1090 [1:04:44<05:01,  2.14s/it] 87%|████████▋ | 950/1090 [1:04:46<05:00,  2.14s/it] 87%|████████▋ | 951/1090 [1:04:48<05:00,  2.16s/it] 87%|████████▋ | 952/1090 [1:04:51<05:05,  2.21s/it] 87%|████████▋ | 953/1090 [1:04:53<05:02,  2.21s/it] 88%|████████▊ | 954/1090 [1:04:55<05:02,  2.23s/it] 88%|████████▊ | 955/1090 [1:04:57<04:56,  2.20s/it] 88%|████████▊ | 956/1090 [1:04:59<04:55,  2.20s/it] 88%|████████▊ | 957/1090 [1:05:02<04:55,  2.22s/it] 88%|████████▊ | 958/1090 [1:05:04<04:54,  2.23s/it] 88%|████████▊ | 959/1090 [1:05:06<04:49,  2.21s/it] 88%|████████▊ | 960/1090 [1:05:09<04:56,  2.28s/it] 88%|████████▊ | 961/1090 [1:05:11<04:44,  2.21s/it] 88%|████████▊ | 962/1090 [1:05:13<04:41,  2.20s/it] 88%|████████▊ | 963/1090 [1:05:15<04:39,  2.20s/it] 88%|████████▊ | 964/1090 [1:05:17<04:37,  2.20s/it] 89%|████████▊ | 965/1090 [1:05:19<04:33,  2.19s/it] 89%|████████▊ | 966/1090 [1:05:21<04:30,  2.18s/it] 89%|████████▊ | 967/1090 [1:05:24<04:31,  2.20s/it] 89%|████████▉ | 968/1090 [1:05:26<04:27,  2.20s/it] 89%|████████▉ | 969/1090 [1:05:28<04:28,  2.22s/it] 89%|████████▉ | 970/1090 [1:05:30<04:26,  2.22s/it] 89%|████████▉ | 971/1090 [1:05:33<04:24,  2.22s/it] 89%|████████▉ | 972/1090 [1:05:35<04:21,  2.22s/it] 89%|████████▉ | 973/1090 [1:05:37<04:24,  2.26s/it] 89%|████████▉ | 974/1090 [1:05:40<04:25,  2.29s/it] 89%|████████▉ | 975/1090 [1:05:42<04:23,  2.29s/it] 90%|████████▉ | 976/1090 [1:05:44<04:16,  2.25s/it] 90%|████████▉ | 977/1090 [1:05:46<04:11,  2.22s/it] 90%|████████▉ | 978/1090 [1:05:48<04:07,  2.21s/it] 90%|████████▉ | 979/1090 [1:05:51<04:13,  2.28s/it] 90%|████████▉ | 980/1090 [1:05:53<04:08,  2.26s/it] 90%|█████████ | 981/1090 [1:05:55<04:04,  2.24s/it] 90%|█████████ | 982/1090 [1:05:57<03:59,  2.22s/it] 90%|█████████ | 983/1090 [1:06:00<04:01,  2.26s/it] 90%|█████████ | 984/1090 [1:06:02<03:57,  2.24s/it] 90%|█████████ | 985/1090 [1:06:04<03:58,  2.27s/it] 90%|█████████ | 986/1090 [1:06:06<03:54,  2.25s/it] 91%|█████████ | 987/1090 [1:06:09<03:52,  2.25s/it] 91%|█████████ | 988/1090 [1:06:11<03:47,  2.24s/it] 91%|█████████ | 989/1090 [1:06:13<03:47,  2.25s/it] 91%|█████████ | 990/1090 [1:06:15<03:45,  2.25s/it] 91%|█████████ | 991/1090 [1:06:18<03:41,  2.23s/it] 91%|█████████ | 992/1090 [1:06:20<03:41,  2.26s/it] 91%|█████████ | 993/1090 [1:06:22<03:36,  2.23s/it] 91%|█████████ | 994/1090 [1:06:24<03:34,  2.24s/it] 91%|█████████▏| 995/1090 [1:06:27<03:29,  2.21s/it] 91%|█████████▏| 996/1090 [1:06:29<03:32,  2.26s/it] 91%|█████████▏| 997/1090 [1:06:31<03:28,  2.24s/it] 92%|█████████▏| 998/1090 [1:06:33<03:27,  2.25s/it] 92%|█████████▏| 999/1090 [1:06:36<03:24,  2.25s/it] 92%|█████████▏| 1000/1090 [1:06:38<03:24,  2.28s/it]                                                     {'loss': 0.4758, 'learning_rate': 4.128440366972477e-06, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:06:38<03:24,  2.28s/it]
  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:14<11:14,  7.41s/it][A
  3%|▎         | 3/93 [00:35<19:10, 12.79s/it][A
  4%|▍         | 4/93 [00:50<20:28, 13.80s/it][A
  5%|▌         | 5/93 [01:07<21:37, 14.74s/it][A
  6%|▋         | 6/93 [01:25<23:02, 15.89s/it][A
  8%|▊         | 7/93 [01:41<22:54, 15.99s/it][A
  9%|▊         | 8/93 [01:59<23:34, 16.64s/it][A
 10%|▉         | 9/93 [02:19<24:35, 17.57s/it][A
 11%|█         | 10/93 [02:37<24:37, 17.81s/it][A
 12%|█▏        | 11/93 [02:56<24:53, 18.22s/it][A
 13%|█▎        | 12/93 [03:16<25:21, 18.79s/it][A
 14%|█▍        | 13/93 [03:36<25:12, 18.91s/it][A
 15%|█▌        | 14/93 [03:57<25:44, 19.56s/it][A
 16%|█▌        | 15/93 [04:19<26:22, 20.29s/it][A
 17%|█▋        | 16/93 [04:38<25:36, 19.96s/it][A
 18%|█▊        | 17/93 [04:57<25:06, 19.82s/it][A
 19%|█▉        | 18/93 [05:17<24:54, 19.92s/it][A
 20%|██        | 19/93 [05:37<24:19, 19.72s/it][A
 22%|██▏       | 20/93 [05:54<22:59, 18.89s/it][A
 23%|██▎       | 21/93 [06:13<22:44, 18.96s/it][A
 24%|██▎       | 22/93 [06:28<21:09, 17.88s/it][A
 25%|██▍       | 23/93 [06:45<20:36, 17.67s/it][A
 26%|██▌       | 24/93 [07:05<20:51, 18.14s/it][A
 27%|██▋       | 25/93 [07:24<20:56, 18.48s/it][A
 28%|██▊       | 26/93 [07:43<20:53, 18.71s/it][A
 29%|██▉       | 27/93 [08:01<20:24, 18.56s/it][A
 30%|███       | 28/93 [08:21<20:34, 19.00s/it][A
 31%|███       | 29/93 [08:38<19:24, 18.20s/it][A
 32%|███▏      | 30/93 [08:57<19:22, 18.45s/it][A
 33%|███▎      | 31/93 [09:16<19:14, 18.62s/it][A
 34%|███▍      | 32/93 [09:33<18:34, 18.28s/it][A
 35%|███▌      | 33/93 [09:53<18:52, 18.88s/it][A
 37%|███▋      | 34/93 [10:12<18:23, 18.70s/it][A
 38%|███▊      | 35/93 [10:32<18:27, 19.09s/it][A
 39%|███▊      | 36/93 [10:50<17:50, 18.78s/it][A
 40%|███▉      | 37/93 [11:09<17:34, 18.83s/it][A
 41%|████      | 38/93 [11:26<16:50, 18.38s/it][A
 42%|████▏     | 39/93 [11:45<16:46, 18.63s/it][A
 43%|████▎     | 40/93 [12:04<16:32, 18.73s/it][A
 44%|████▍     | 41/93 [12:23<16:18, 18.82s/it][A
 45%|████▌     | 42/93 [12:43<16:21, 19.25s/it][A
 46%|████▌     | 43/93 [13:03<16:03, 19.28s/it][A
 47%|████▋     | 44/93 [13:22<15:41, 19.21s/it][A
 48%|████▊     | 45/93 [13:36<14:08, 17.69s/it][A
 49%|████▉     | 46/93 [13:54<13:57, 17.83s/it][A
 51%|█████     | 47/93 [14:12<13:42, 17.87s/it][A
 52%|█████▏    | 48/93 [14:31<13:43, 18.29s/it][A
 53%|█████▎    | 49/93 [14:51<13:47, 18.80s/it][A
 54%|█████▍    | 50/93 [15:11<13:33, 18.91s/it][A
 55%|█████▍    | 51/93 [15:30<13:17, 18.98s/it][A
 56%|█████▌    | 52/93 [15:49<12:58, 18.99s/it][A
 57%|█████▋    | 53/93 [16:09<12:57, 19.43s/it][A
 58%|█████▊    | 54/93 [16:29<12:38, 19.44s/it][A
 59%|█████▉    | 55/93 [16:44<11:32, 18.23s/it][A
 60%|██████    | 56/93 [17:03<11:24, 18.49s/it][A
 61%|██████▏   | 57/93 [17:21<11:00, 18.36s/it][A
 62%|██████▏   | 58/93 [17:40<10:50, 18.58s/it][A
 63%|██████▎   | 59/93 [17:56<09:59, 17.62s/it][A
 65%|██████▍   | 60/93 [18:15<09:58, 18.13s/it][A
 66%|██████▌   | 61/93 [18:33<09:40, 18.14s/it][A
 67%|██████▋   | 62/93 [18:52<09:31, 18.43s/it][A
 68%|██████▊   | 63/93 [19:10<09:10, 18.34s/it][A
 69%|██████▉   | 64/93 [19:28<08:49, 18.26s/it][A
 70%|██████▉   | 65/93 [19:46<08:20, 17.89s/it][A
 71%|███████   | 66/93 [20:05<08:13, 18.29s/it][A
 72%|███████▏  | 67/93 [20:25<08:09, 18.84s/it][A
 73%|███████▎  | 68/93 [20:46<08:07, 19.52s/it][A
 74%|███████▍  | 69/93 [21:05<07:48, 19.52s/it][A
 75%|███████▌  | 70/93 [21:24<07:24, 19.34s/it][A
 76%|███████▋  | 71/93 [21:44<07:09, 19.52s/it][A
 77%|███████▋  | 72/93 [22:03<06:46, 19.38s/it][A
 78%|███████▊  | 73/93 [22:22<06:25, 19.30s/it][A
 80%|███████▉  | 74/93 [22:42<06:06, 19.26s/it][A
 81%|████████  | 75/93 [23:02<05:50, 19.47s/it][A
 82%|████████▏ | 76/93 [23:21<05:30, 19.43s/it][A
 83%|████████▎ | 77/93 [23:40<05:08, 19.28s/it][A
 84%|████████▍ | 78/93 [23:59<04:47, 19.18s/it][A
 85%|████████▍ | 79/93 [24:18<04:28, 19.16s/it][A
 86%|████████▌ | 80/93 [24:37<04:09, 19.17s/it][A
 87%|████████▋ | 81/93 [24:55<03:45, 18.83s/it][A
 88%|████████▊ | 82/93 [25:14<03:27, 18.88s/it][A
 89%|████████▉ | 83/93 [25:33<03:09, 18.95s/it][A
 90%|█████████ | 84/93 [25:52<02:51, 19.01s/it][A
 91%|█████████▏| 85/93 [26:11<02:32, 19.02s/it][A
 92%|█████████▏| 86/93 [26:31<02:13, 19.12s/it][A
 94%|█████████▎| 87/93 [26:50<01:54, 19.10s/it][A
 95%|█████████▍| 88/93 [27:08<01:34, 18.80s/it][A
 96%|█████████▌| 89/93 [27:27<01:15, 18.84s/it][A
 97%|█████████▋| 90/93 [27:46<00:56, 18.91s/it][A
 98%|█████████▊| 91/93 [28:05<00:37, 19.00s/it][A
 99%|█████████▉| 92/93 [28:25<00:19, 19.16s/it][A
100%|██████████| 93/93 [28:45<00:00, 19.49s/it][A                                                     
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 23.693, 'eval_rouge2': 9.4112, 'eval_rougeL': 17.7896, 'eval_rougeLsum': 22.3333, 'eval_gen_len': 81.75235215053763, 'eval_runtime': 1760.3296, 'eval_samples_per_second': 1.704, 'eval_steps_per_second': 0.053, 'eval_block_avg': 9.564263451443567, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:35:58<03:24,  2.28s/it]
100%|██████████| 93/93 [29:02<00:00, 19.49s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 09:47:12,732 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-1000
[INFO|configuration_utils.py:457] 2024-05-24 09:47:12,733 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/config.json
[INFO|configuration_utils.py:362] 2024-05-24 09:47:12,734 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 09:47:14,948 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 09:47:14,949 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 09:47:14,949 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 09:47:14,978 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-1000/spiece.model
 92%|█████████▏| 1001/1090 [1:36:03<13:07:42, 531.04s/it] 92%|█████████▏| 1002/1090 [1:36:05<9:06:12, 372.41s/it]  92%|█████████▏| 1003/1090 [1:36:07<6:19:00, 261.38s/it] 92%|█████████▏| 1004/1090 [1:36:10<4:23:12, 183.64s/it] 92%|█████████▏| 1005/1090 [1:36:12<3:03:03, 129.21s/it] 92%|█████████▏| 1006/1090 [1:36:14<2:07:37, 91.16s/it]  92%|█████████▏| 1007/1090 [1:36:16<1:29:10, 64.46s/it] 92%|█████████▏| 1008/1090 [1:36:19<1:02:35, 45.80s/it] 93%|█████████▎| 1009/1090 [1:36:21<44:12, 32.75s/it]   93%|█████████▎| 1010/1090 [1:36:23<31:26, 23.58s/it] 93%|█████████▎| 1011/1090 [1:36:25<22:36, 17.18s/it] 93%|█████████▎| 1012/1090 [1:36:27<16:27, 12.66s/it] 93%|█████████▎| 1013/1090 [1:36:30<12:12,  9.52s/it] 93%|█████████▎| 1014/1090 [1:36:32<09:19,  7.36s/it] 93%|█████████▎| 1015/1090 [1:36:34<07:16,  5.82s/it] 93%|█████████▎| 1016/1090 [1:36:36<05:51,  4.74s/it] 93%|█████████▎| 1017/1090 [1:36:39<04:50,  3.99s/it] 93%|█████████▎| 1018/1090 [1:36:41<04:12,  3.51s/it] 93%|█████████▎| 1019/1090 [1:36:43<03:41,  3.12s/it] 94%|█████████▎| 1020/1090 [1:36:46<03:20,  2.86s/it] 94%|█████████▎| 1021/1090 [1:36:48<03:02,  2.65s/it] 94%|█████████▍| 1022/1090 [1:36:50<02:52,  2.53s/it] 94%|█████████▍| 1023/1090 [1:36:52<02:42,  2.42s/it] 94%|█████████▍| 1024/1090 [1:36:54<02:36,  2.37s/it] 94%|█████████▍| 1025/1090 [1:36:57<02:35,  2.39s/it] 94%|█████████▍| 1026/1090 [1:36:59<02:30,  2.35s/it] 94%|█████████▍| 1027/1090 [1:37:01<02:24,  2.30s/it] 94%|█████████▍| 1028/1090 [1:37:04<02:23,  2.31s/it] 94%|█████████▍| 1029/1090 [1:37:06<02:19,  2.28s/it] 94%|█████████▍| 1030/1090 [1:37:08<02:16,  2.27s/it] 95%|█████████▍| 1031/1090 [1:37:10<02:15,  2.29s/it] 95%|█████████▍| 1032/1090 [1:37:13<02:13,  2.30s/it] 95%|█████████▍| 1033/1090 [1:37:15<02:09,  2.27s/it] 95%|█████████▍| 1034/1090 [1:37:17<02:07,  2.28s/it] 95%|█████████▍| 1035/1090 [1:37:19<02:03,  2.25s/it] 95%|█████████▌| 1036/1090 [1:37:22<02:02,  2.27s/it] 95%|█████████▌| 1037/1090 [1:37:24<01:59,  2.25s/it] 95%|█████████▌| 1038/1090 [1:37:26<01:57,  2.25s/it] 95%|█████████▌| 1039/1090 [1:37:29<01:56,  2.29s/it] 95%|█████████▌| 1040/1090 [1:37:31<01:55,  2.31s/it] 96%|█████████▌| 1041/1090 [1:37:33<01:52,  2.29s/it] 96%|█████████▌| 1042/1090 [1:37:35<01:49,  2.27s/it] 96%|█████████▌| 1043/1090 [1:37:38<01:46,  2.27s/it] 96%|█████████▌| 1044/1090 [1:37:40<01:42,  2.23s/it] 96%|█████████▌| 1045/1090 [1:37:42<01:40,  2.23s/it] 96%|█████████▌| 1046/1090 [1:37:44<01:38,  2.23s/it] 96%|█████████▌| 1047/1090 [1:37:46<01:36,  2.24s/it] 96%|█████████▌| 1048/1090 [1:37:49<01:33,  2.24s/it] 96%|█████████▌| 1049/1090 [1:37:51<01:31,  2.23s/it] 96%|█████████▋| 1050/1090 [1:37:53<01:29,  2.24s/it] 96%|█████████▋| 1051/1090 [1:37:55<01:27,  2.25s/it] 97%|█████████▋| 1052/1090 [1:37:58<01:25,  2.25s/it] 97%|█████████▋| 1053/1090 [1:38:00<01:23,  2.25s/it] 97%|█████████▋| 1054/1090 [1:38:02<01:19,  2.21s/it] 97%|█████████▋| 1055/1090 [1:38:04<01:18,  2.23s/it] 97%|█████████▋| 1056/1090 [1:38:07<01:15,  2.21s/it] 97%|█████████▋| 1057/1090 [1:38:09<01:14,  2.26s/it] 97%|█████████▋| 1058/1090 [1:38:11<01:11,  2.23s/it] 97%|█████████▋| 1059/1090 [1:38:13<01:10,  2.27s/it] 97%|█████████▋| 1060/1090 [1:38:16<01:07,  2.25s/it] 97%|█████████▋| 1061/1090 [1:38:18<01:05,  2.25s/it] 97%|█████████▋| 1062/1090 [1:38:20<01:03,  2.27s/it] 98%|█████████▊| 1063/1090 [1:38:22<01:01,  2.27s/it] 98%|█████████▊| 1064/1090 [1:38:25<00:58,  2.24s/it] 98%|█████████▊| 1065/1090 [1:38:27<00:56,  2.25s/it] 98%|█████████▊| 1066/1090 [1:38:29<00:54,  2.27s/it] 98%|█████████▊| 1067/1090 [1:38:31<00:51,  2.23s/it] 98%|█████████▊| 1068/1090 [1:38:34<00:49,  2.23s/it] 98%|█████████▊| 1069/1090 [1:38:36<00:46,  2.22s/it] 98%|█████████▊| 1070/1090 [1:38:38<00:45,  2.26s/it] 98%|█████████▊| 1071/1090 [1:38:40<00:42,  2.23s/it] 98%|█████████▊| 1072/1090 [1:38:43<00:40,  2.23s/it] 98%|█████████▊| 1073/1090 [1:38:45<00:38,  2.25s/it] 99%|█████████▊| 1074/1090 [1:38:47<00:35,  2.22s/it] 99%|█████████▊| 1075/1090 [1:38:49<00:33,  2.22s/it] 99%|█████████▊| 1076/1090 [1:38:51<00:31,  2.23s/it] 99%|█████████▉| 1077/1090 [1:38:54<00:28,  2.21s/it] 99%|█████████▉| 1078/1090 [1:38:56<00:26,  2.20s/it] 99%|█████████▉| 1079/1090 [1:38:58<00:24,  2.26s/it] 99%|█████████▉| 1080/1090 [1:39:01<00:22,  2.29s/it] 99%|█████████▉| 1081/1090 [1:39:03<00:20,  2.28s/it] 99%|█████████▉| 1082/1090 [1:39:05<00:18,  2.29s/it] 99%|█████████▉| 1083/1090 [1:39:07<00:15,  2.28s/it] 99%|█████████▉| 1084/1090 [1:39:10<00:13,  2.25s/it]100%|█████████▉| 1085/1090 [1:39:12<00:11,  2.26s/it]100%|█████████▉| 1086/1090 [1:39:14<00:08,  2.24s/it]100%|█████████▉| 1087/1090 [1:39:16<00:06,  2.23s/it]100%|█████████▉| 1088/1090 [1:39:18<00:04,  2.22s/it]100%|█████████▉| 1089/1090 [1:39:21<00:02,  2.24s/it]100%|██████████| 1090/1090 [1:39:23<00:00,  2.24s/it][INFO|trainer.py:2039] 2024-05-24 09:50:37,357 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2172] 2024-05-24 09:50:37,358 >> Loading best model from src/save/cnndm_t5_large/checkpoint-500 (score: 26.8295).
                                                     {'train_runtime': 5964.3248, 'train_samples_per_second': 5.868, 'train_steps_per_second': 0.183, 'train_loss': 0.4913987920918596, 'epoch': 5.0}
100%|██████████| 1090/1090 [1:39:24<00:00,  2.24s/it][INFO|trainer.py:2073] 2024-05-24 09:50:38,239 >> Deleting older checkpoint [src/save/cnndm_t5_large/checkpoint-1000] due to args.save_total_limit
100%|██████████| 1090/1090 [1:39:24<00:00,  5.47s/it]
[INFO|trainer.py:2868] 2024-05-24 09:50:38,446 >> Saving model checkpoint to src/save/cnndm_t5_large/
[INFO|configuration_utils.py:457] 2024-05-24 09:50:38,447 >> Configuration saved in src/save/cnndm_t5_large/config.json
[INFO|configuration_utils.py:362] 2024-05-24 09:50:38,447 >> Configuration saved in src/save/cnndm_t5_large/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 09:50:41,494 >> Model weights saved in src/save/cnndm_t5_large/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 09:50:41,495 >> tokenizer config file saved in src/save/cnndm_t5_large/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 09:50:41,495 >> Special tokens file saved in src/save/cnndm_t5_large/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 09:50:41,530 >> Copy vocab file to src/save/cnndm_t5_large/spiece.model
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4914
  train_runtime            = 1:39:24.32
  train_samples            =       7000
  train_samples_per_second =      5.868
  train_steps_per_second   =      0.183
05/24/2024 09:50:41 - INFO - __main__ - *** Evaluate ***
  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:19<14:32,  9.58s/it]  3%|▎         | 3/93 [00:38<20:24, 13.61s/it]  4%|▍         | 4/93 [00:58<23:49, 16.06s/it]  5%|▌         | 5/93 [01:18<25:15, 17.23s/it]  6%|▋         | 6/93 [01:37<25:54, 17.87s/it]  8%|▊         | 7/93 [01:54<25:18, 17.66s/it]  9%|▊         | 8/93 [02:11<24:45, 17.48s/it] 10%|▉         | 9/93 [02:30<25:18, 18.08s/it] 11%|█         | 10/93 [02:49<25:24, 18.37s/it] 12%|█▏        | 11/93 [03:08<25:23, 18.58s/it] 13%|█▎        | 12/93 [03:28<25:18, 18.75s/it] 14%|█▍        | 13/93 [03:47<25:14, 18.93s/it] 15%|█▌        | 14/93 [04:06<25:03, 19.04s/it] 16%|█▌        | 15/93 [04:25<24:40, 18.98s/it] 17%|█▋        | 16/93 [04:44<24:08, 18.82s/it] 18%|█▊        | 17/93 [05:03<24:09, 19.07s/it] 19%|█▉        | 18/93 [05:25<24:57, 19.97s/it] 20%|██        | 19/93 [05:43<23:59, 19.45s/it] 22%|██▏       | 20/93 [06:03<23:34, 19.38s/it] 23%|██▎       | 21/93 [06:22<23:08, 19.29s/it] 24%|██▎       | 22/93 [06:39<22:06, 18.68s/it] 25%|██▍       | 23/93 [06:57<21:28, 18.40s/it] 26%|██▌       | 24/93 [07:17<21:45, 18.92s/it] 27%|██▋       | 25/93 [07:36<21:30, 18.97s/it] 28%|██▊       | 26/93 [07:54<20:57, 18.78s/it] 29%|██▉       | 27/93 [08:12<20:25, 18.57s/it] 30%|███       | 28/93 [08:29<19:28, 17.98s/it] 31%|███       | 29/93 [08:47<19:15, 18.05s/it] 32%|███▏      | 30/93 [09:05<18:58, 18.07s/it] 33%|███▎      | 31/93 [09:24<18:57, 18.35s/it] 34%|███▍      | 32/93 [09:41<18:04, 17.78s/it] 35%|███▌      | 33/93 [10:00<18:10, 18.18s/it] 37%|███▋      | 34/93 [10:19<18:08, 18.45s/it] 38%|███▊      | 35/93 [10:39<18:17, 18.92s/it] 39%|███▊      | 36/93 [10:58<17:53, 18.84s/it] 40%|███▉      | 37/93 [11:17<17:37, 18.88s/it] 41%|████      | 38/93 [11:36<17:20, 18.92s/it] 42%|████▏     | 39/93 [11:56<17:24, 19.34s/it] 43%|████▎     | 40/93 [12:15<16:59, 19.23s/it] 44%|████▍     | 41/93 [12:34<16:36, 19.17s/it] 45%|████▌     | 42/93 [12:53<16:21, 19.25s/it] 46%|████▌     | 43/93 [13:13<16:04, 19.28s/it] 47%|████▋     | 44/93 [13:32<15:40, 19.20s/it] 48%|████▊     | 45/93 [13:51<15:18, 19.14s/it] 49%|████▉     | 46/93 [14:09<14:48, 18.89s/it] 51%|█████     | 47/93 [14:28<14:30, 18.91s/it] 52%|█████▏    | 48/93 [14:46<13:59, 18.66s/it] 53%|█████▎    | 49/93 [15:05<13:46, 18.78s/it] 54%|█████▍    | 50/93 [15:24<13:32, 18.90s/it] 55%|█████▍    | 51/93 [15:43<13:07, 18.74s/it] 56%|█████▌    | 52/93 [16:01<12:43, 18.61s/it] 57%|█████▋    | 53/93 [16:20<12:32, 18.81s/it] 58%|█████▊    | 54/93 [16:40<12:22, 19.03s/it] 59%|█████▉    | 55/93 [16:56<11:32, 18.21s/it] 60%|██████    | 56/93 [17:16<11:35, 18.79s/it] 61%|██████▏   | 57/93 [17:33<10:57, 18.28s/it] 62%|██████▏   | 58/93 [17:53<10:48, 18.53s/it] 63%|██████▎   | 59/93 [18:12<10:39, 18.82s/it] 65%|██████▍   | 60/93 [18:31<10:26, 18.98s/it] 66%|██████▌   | 61/93 [18:50<10:08, 19.02s/it] 67%|██████▋   | 62/93 [19:11<09:59, 19.33s/it] 68%|██████▊   | 63/93 [19:26<09:05, 18.18s/it] 69%|██████▉   | 64/93 [19:45<08:54, 18.43s/it] 70%|██████▉   | 65/93 [20:03<08:36, 18.43s/it] 71%|███████   | 66/93 [20:20<08:04, 17.95s/it] 72%|███████▏  | 67/93 [20:39<07:49, 18.06s/it] 73%|███████▎  | 68/93 [20:58<07:41, 18.45s/it] 74%|███████▍  | 69/93 [21:16<07:22, 18.42s/it] 75%|███████▌  | 70/93 [21:36<07:10, 18.71s/it] 76%|███████▋  | 71/93 [21:56<07:00, 19.10s/it] 77%|███████▋  | 72/93 [22:15<06:40, 19.06s/it] 78%|███████▊  | 73/93 [22:34<06:23, 19.17s/it] 80%|███████▉  | 74/93 [22:52<05:58, 18.89s/it] 81%|████████  | 75/93 [23:12<05:45, 19.19s/it] 82%|████████▏ | 76/93 [23:27<05:03, 17.85s/it] 83%|████████▎ | 77/93 [23:44<04:43, 17.71s/it] 84%|████████▍ | 78/93 [24:03<04:31, 18.08s/it] 85%|████████▍ | 79/93 [24:21<04:10, 17.88s/it] 86%|████████▌ | 80/93 [24:41<04:01, 18.57s/it] 87%|████████▋ | 81/93 [25:00<03:44, 18.69s/it] 88%|████████▊ | 82/93 [25:17<03:20, 18.27s/it] 89%|████████▉ | 83/93 [25:35<03:02, 18.24s/it] 90%|█████████ | 84/93 [25:55<02:46, 18.52s/it] 91%|█████████▏| 85/93 [26:14<02:29, 18.68s/it] 92%|█████████▏| 86/93 [26:33<02:12, 18.87s/it] 94%|█████████▎| 87/93 [26:52<01:53, 18.96s/it] 95%|█████████▍| 88/93 [27:12<01:36, 19.34s/it] 96%|█████████▌| 89/93 [27:31<01:17, 19.26s/it] 97%|█████████▋| 90/93 [27:51<00:57, 19.23s/it] 98%|█████████▊| 91/93 [28:10<00:38, 19.19s/it] 99%|█████████▉| 92/93 [28:27<00:18, 18.69s/it]100%|██████████| 93/93 [28:47<00:00, 19.19s/it]100%|██████████| 93/93 [29:04<00:00, 18.75s/it]
***** eval metrics *****
  epoch                   =        5.0
  eval_block_avg          =     9.7021
  eval_gen_len            =    80.8044
  eval_loss               =     1.4048
  eval_rouge1             =    28.5158
  eval_rouge2             =    11.4073
  eval_rougeL             =     20.815
  eval_rougeLsum          =    26.8295
  eval_runtime            = 0:29:19.53
  eval_samples            =       3000
  eval_samples_per_second =      1.705
  eval_steps_per_second   =      0.053
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 10:20:09 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 10:20:09 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_10-20-09_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 10:20:15 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 10:20:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 10:20:15 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 10:20:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 10:20:15,477 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 10:20:15,478 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 10:20:15,598 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 10:20:15,717 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 10:20:15,719 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 10:20:15,951 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 10:20:15,951 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 10:20:15,951 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 10:20:15,951 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 10:20:15,951 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 10:20:15,952 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 10:20:15,953 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 10:20:16,002 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 10:20:17,287 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 10:20:44,312 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[WARNING|modeling_utils.py:3192] 2024-05-24 10:20:44,312 >> Some weights of EffT5ForConditionalGeneration were not initialized from the model checkpoint at checkpoints/CNNDM and are newly initialized: ['cm_head.linear.bias', 'cm_head.linear.weight', 'cm_head.lstm.weight_ih_l0', 'cm_head.lstm.weight_hh_l0', 'cm_head.lstm.bias_hh_l0', 'cm_head.lstm.bias_ih_l0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:2839] 2024-05-24 10:20:44,323 >> Generation config file not found, using a generation config created from the model config.
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
05/24/2024 10:20:44 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-500f9c3b8c9b943d.arrow
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 10:20:44 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 10:20:44 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
[INFO|trainer.py:1769] 2024-05-24 10:20:46,176 >> ***** Running training *****
[INFO|trainer.py:1770] 2024-05-24 10:20:46,177 >>   Num examples = 7,000
[INFO|trainer.py:1771] 2024-05-24 10:20:46,177 >>   Num Epochs = 5
[INFO|trainer.py:1772] 2024-05-24 10:20:46,177 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1773] 2024-05-24 10:20:46,177 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1774] 2024-05-24 10:20:46,177 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1775] 2024-05-24 10:20:46,177 >>   Total optimization steps = 1,090
[INFO|trainer.py:1776] 2024-05-24 10:20:46,179 >>   Number of trainable parameters = 1,276,502
  0%|          | 0/1090 [00:00<?, ?it/s][WARNING|logging.py:280] 2024-05-24 10:20:46,196 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1090 [00:03<55:03,  3.03s/it]  0%|          | 2/1090 [00:05<50:07,  2.76s/it]  0%|          | 3/1090 [00:08<49:15,  2.72s/it]  0%|          | 4/1090 [00:10<49:01,  2.71s/it]  0%|          | 5/1090 [00:13<47:03,  2.60s/it]  1%|          | 6/1090 [00:15<46:57,  2.60s/it]  1%|          | 7/1090 [00:18<46:23,  2.57s/it]  1%|          | 8/1090 [00:21<46:03,  2.55s/it]  1%|          | 9/1090 [00:23<45:45,  2.54s/it]  1%|          | 10/1090 [00:26<46:16,  2.57s/it]  1%|          | 11/1090 [00:28<46:09,  2.57s/it]  1%|          | 12/1090 [00:31<46:34,  2.59s/it]  1%|          | 13/1090 [00:33<45:18,  2.52s/it]  1%|▏         | 14/1090 [00:36<45:26,  2.53s/it]  1%|▏         | 15/1090 [00:38<45:17,  2.53s/it]  1%|▏         | 16/1090 [00:41<45:19,  2.53s/it]  2%|▏         | 17/1090 [00:44<46:13,  2.59s/it]  2%|▏         | 18/1090 [00:46<45:21,  2.54s/it]  2%|▏         | 19/1090 [00:48<44:36,  2.50s/it]  2%|▏         | 20/1090 [00:51<44:45,  2.51s/it]  2%|▏         | 21/1090 [00:53<45:03,  2.53s/it]  2%|▏         | 22/1090 [00:56<45:35,  2.56s/it]  2%|▏         | 23/1090 [00:59<45:39,  2.57s/it]  2%|▏         | 24/1090 [01:02<46:55,  2.64s/it]  2%|▏         | 25/1090 [01:04<45:44,  2.58s/it]  2%|▏         | 26/1090 [01:07<46:27,  2.62s/it]  2%|▏         | 27/1090 [01:09<45:04,  2.54s/it]  3%|▎         | 28/1090 [01:12<44:42,  2.53s/it]  3%|▎         | 29/1090 [01:14<45:28,  2.57s/it]  3%|▎         | 30/1090 [01:17<45:10,  2.56s/it]  3%|▎         | 31/1090 [01:19<44:49,  2.54s/it]  3%|▎         | 32/1090 [01:22<45:21,  2.57s/it]  3%|▎         | 33/1090 [01:24<44:50,  2.55s/it]  3%|▎         | 34/1090 [01:27<44:28,  2.53s/it]  3%|▎         | 35/1090 [01:29<44:31,  2.53s/it]  3%|▎         | 36/1090 [01:32<44:36,  2.54s/it]  3%|▎         | 37/1090 [01:35<44:55,  2.56s/it]  3%|▎         | 38/1090 [01:37<44:28,  2.54s/it]  4%|▎         | 39/1090 [01:40<44:48,  2.56s/it]  4%|▎         | 40/1090 [01:42<44:37,  2.55s/it]  4%|▍         | 41/1090 [01:45<45:09,  2.58s/it]  4%|▍         | 42/1090 [01:47<44:58,  2.58s/it]  4%|▍         | 43/1090 [01:50<44:51,  2.57s/it]  4%|▍         | 44/1090 [01:52<44:28,  2.55s/it]  4%|▍         | 45/1090 [01:55<44:42,  2.57s/it]  4%|▍         | 46/1090 [01:58<44:47,  2.57s/it]  4%|▍         | 47/1090 [02:00<45:08,  2.60s/it]  4%|▍         | 48/1090 [02:03<45:33,  2.62s/it]  4%|▍         | 49/1090 [02:06<45:56,  2.65s/it]  5%|▍         | 50/1090 [02:08<45:09,  2.61s/it]  5%|▍         | 51/1090 [02:11<44:49,  2.59s/it]  5%|▍         | 52/1090 [02:13<44:28,  2.57s/it]  5%|▍         | 53/1090 [02:16<44:38,  2.58s/it]  5%|▍         | 54/1090 [02:18<44:21,  2.57s/it]  5%|▌         | 55/1090 [02:21<44:52,  2.60s/it]  5%|▌         | 56/1090 [02:24<45:25,  2.64s/it]  5%|▌         | 57/1090 [02:27<46:18,  2.69s/it]  5%|▌         | 58/1090 [02:29<46:17,  2.69s/it]  5%|▌         | 59/1090 [02:32<45:52,  2.67s/it]  6%|▌         | 60/1090 [02:34<45:05,  2.63s/it]  6%|▌         | 61/1090 [02:37<44:48,  2.61s/it]  6%|▌         | 62/1090 [02:40<44:46,  2.61s/it]  6%|▌         | 63/1090 [02:42<43:59,  2.57s/it]  6%|▌         | 64/1090 [02:45<44:07,  2.58s/it]  6%|▌         | 65/1090 [02:48<45:20,  2.65s/it]  6%|▌         | 66/1090 [02:50<43:45,  2.56s/it]  6%|▌         | 67/1090 [02:53<43:49,  2.57s/it]  6%|▌         | 68/1090 [02:55<43:09,  2.53s/it]  6%|▋         | 69/1090 [02:57<42:58,  2.53s/it]  6%|▋         | 70/1090 [03:00<43:24,  2.55s/it]  7%|▋         | 71/1090 [03:03<43:31,  2.56s/it]  7%|▋         | 72/1090 [03:05<43:46,  2.58s/it]  7%|▋         | 73/1090 [03:08<43:48,  2.58s/it]  7%|▋         | 74/1090 [03:11<44:15,  2.61s/it]  7%|▋         | 75/1090 [03:13<42:47,  2.53s/it]  7%|▋         | 76/1090 [03:15<42:20,  2.51s/it]  7%|▋         | 77/1090 [03:18<42:47,  2.53s/it]  7%|▋         | 78/1090 [03:20<42:50,  2.54s/it]  7%|▋         | 79/1090 [03:23<43:09,  2.56s/it]  7%|▋         | 80/1090 [03:26<43:33,  2.59s/it]  7%|▋         | 81/1090 [03:28<43:19,  2.58s/it]  8%|▊         | 82/1090 [03:31<43:18,  2.58s/it]  8%|▊         | 83/1090 [03:33<42:34,  2.54s/it]  8%|▊         | 84/1090 [03:36<42:50,  2.55s/it]  8%|▊         | 85/1090 [03:38<42:35,  2.54s/it]  8%|▊         | 86/1090 [03:41<42:35,  2.55s/it]  8%|▊         | 87/1090 [03:43<42:21,  2.53s/it]  8%|▊         | 88/1090 [03:46<42:06,  2.52s/it]  8%|▊         | 89/1090 [03:49<42:24,  2.54s/it]  8%|▊         | 90/1090 [03:51<42:52,  2.57s/it]  8%|▊         | 91/1090 [03:54<42:41,  2.56s/it]  8%|▊         | 92/1090 [03:56<42:24,  2.55s/it]  9%|▊         | 93/1090 [03:59<42:02,  2.53s/it]  9%|▊         | 94/1090 [04:02<43:12,  2.60s/it]  9%|▊         | 95/1090 [04:04<42:47,  2.58s/it]  9%|▉         | 96/1090 [04:06<41:59,  2.53s/it]  9%|▉         | 97/1090 [04:09<43:04,  2.60s/it]  9%|▉         | 98/1090 [04:12<43:30,  2.63s/it]  9%|▉         | 99/1090 [04:14<43:00,  2.60s/it]  9%|▉         | 100/1090 [04:17<42:50,  2.60s/it]  9%|▉         | 101/1090 [04:20<42:22,  2.57s/it]  9%|▉         | 102/1090 [04:22<42:30,  2.58s/it]  9%|▉         | 103/1090 [04:25<42:00,  2.55s/it] 10%|▉         | 104/1090 [04:27<42:12,  2.57s/it] 10%|▉         | 105/1090 [04:30<42:15,  2.57s/it] 10%|▉         | 106/1090 [04:32<42:03,  2.56s/it] 10%|▉         | 107/1090 [04:35<41:33,  2.54s/it] 10%|▉         | 108/1090 [04:37<41:34,  2.54s/it] 10%|█         | 109/1090 [04:40<42:10,  2.58s/it] 10%|█         | 110/1090 [04:43<42:40,  2.61s/it] 10%|█         | 111/1090 [04:45<42:55,  2.63s/it] 10%|█         | 112/1090 [04:48<42:57,  2.64s/it] 10%|█         | 113/1090 [04:51<43:07,  2.65s/it] 10%|█         | 114/1090 [04:53<42:32,  2.62s/it] 11%|█         | 115/1090 [04:56<42:14,  2.60s/it] 11%|█         | 116/1090 [04:58<41:33,  2.56s/it] 11%|█         | 117/1090 [05:01<41:04,  2.53s/it] 11%|█         | 118/1090 [05:03<41:11,  2.54s/it] 11%|█         | 119/1090 [05:06<41:47,  2.58s/it] 11%|█         | 120/1090 [05:09<41:59,  2.60s/it] 11%|█         | 121/1090 [05:11<42:01,  2.60s/it] 11%|█         | 122/1090 [05:14<42:10,  2.61s/it] 11%|█▏        | 123/1090 [05:16<41:39,  2.59s/it] 11%|█▏        | 124/1090 [05:19<42:56,  2.67s/it] 11%|█▏        | 125/1090 [05:22<42:37,  2.65s/it] 12%|█▏        | 126/1090 [05:25<42:14,  2.63s/it] 12%|█▏        | 127/1090 [05:27<42:21,  2.64s/it] 12%|█▏        | 128/1090 [05:30<42:00,  2.62s/it] 12%|█▏        | 129/1090 [05:32<42:20,  2.64s/it] 12%|█▏        | 130/1090 [05:35<41:35,  2.60s/it] 12%|█▏        | 131/1090 [05:38<41:29,  2.60s/it] 12%|█▏        | 132/1090 [05:40<41:29,  2.60s/it] 12%|█▏        | 133/1090 [05:43<41:24,  2.60s/it] 12%|█▏        | 134/1090 [05:46<42:56,  2.70s/it] 12%|█▏        | 135/1090 [05:48<42:32,  2.67s/it] 12%|█▏        | 136/1090 [05:51<42:02,  2.64s/it] 13%|█▎        | 137/1090 [05:53<41:35,  2.62s/it] 13%|█▎        | 138/1090 [05:56<41:20,  2.61s/it] 13%|█▎        | 139/1090 [05:59<41:15,  2.60s/it] 13%|█▎        | 140/1090 [06:01<40:52,  2.58s/it] 13%|█▎        | 141/1090 [06:04<40:58,  2.59s/it] 13%|█▎        | 142/1090 [06:06<40:25,  2.56s/it] 13%|█▎        | 143/1090 [06:09<40:20,  2.56s/it] 13%|█▎        | 144/1090 [06:12<41:15,  2.62s/it] 13%|█▎        | 145/1090 [06:14<41:43,  2.65s/it] 13%|█▎        | 146/1090 [06:17<40:56,  2.60s/it] 13%|█▎        | 147/1090 [06:20<41:39,  2.65s/it] 14%|█▎        | 148/1090 [06:22<41:17,  2.63s/it] 14%|█▎        | 149/1090 [06:25<41:33,  2.65s/it] 14%|█▍        | 150/1090 [06:27<41:32,  2.65s/it] 14%|█▍        | 151/1090 [06:30<42:02,  2.69s/it] 14%|█▍        | 152/1090 [06:33<41:26,  2.65s/it] 14%|█▍        | 153/1090 [06:35<41:07,  2.63s/it] 14%|█▍        | 154/1090 [06:38<40:46,  2.61s/it] 14%|█▍        | 155/1090 [06:41<40:37,  2.61s/it] 14%|█▍        | 156/1090 [06:43<40:56,  2.63s/it] 14%|█▍        | 157/1090 [06:46<40:53,  2.63s/it] 14%|█▍        | 158/1090 [06:49<41:23,  2.67s/it] 15%|█▍        | 159/1090 [06:51<41:26,  2.67s/it] 15%|█▍        | 160/1090 [06:54<42:06,  2.72s/it] 15%|█▍        | 161/1090 [06:57<41:41,  2.69s/it] 15%|█▍        | 162/1090 [06:59<40:56,  2.65s/it] 15%|█▍        | 163/1090 [07:02<40:21,  2.61s/it] 15%|█▌        | 164/1090 [07:04<39:43,  2.57s/it] 15%|█▌        | 165/1090 [07:07<40:27,  2.62s/it] 15%|█▌        | 166/1090 [07:10<40:35,  2.64s/it] 15%|█▌        | 167/1090 [07:12<40:25,  2.63s/it] 15%|█▌        | 168/1090 [07:15<40:32,  2.64s/it] 16%|█▌        | 169/1090 [07:18<40:00,  2.61s/it] 16%|█▌        | 170/1090 [07:20<40:16,  2.63s/it] 16%|█▌        | 171/1090 [07:23<40:24,  2.64s/it] 16%|█▌        | 172/1090 [07:25<40:09,  2.62s/it] 16%|█▌        | 173/1090 [07:28<39:55,  2.61s/it] 16%|█▌        | 174/1090 [07:31<39:27,  2.58s/it] 16%|█▌        | 175/1090 [07:33<39:34,  2.60s/it] 16%|█▌        | 176/1090 [07:36<39:15,  2.58s/it] 16%|█▌        | 177/1090 [07:38<39:49,  2.62s/it] 16%|█▋        | 178/1090 [07:41<40:02,  2.63s/it] 16%|█▋        | 179/1090 [07:44<40:06,  2.64s/it] 17%|█▋        | 180/1090 [07:46<39:55,  2.63s/it] 17%|█▋        | 181/1090 [07:49<39:13,  2.59s/it] 17%|█▋        | 182/1090 [07:51<39:08,  2.59s/it] 17%|█▋        | 183/1090 [07:54<39:06,  2.59s/it] 17%|█▋        | 184/1090 [07:57<39:24,  2.61s/it] 17%|█▋        | 185/1090 [07:59<39:52,  2.64s/it] 17%|█▋        | 186/1090 [08:02<39:02,  2.59s/it] 17%|█▋        | 187/1090 [08:04<38:57,  2.59s/it] 17%|█▋        | 188/1090 [08:07<38:57,  2.59s/it] 17%|█▋        | 189/1090 [08:10<38:43,  2.58s/it] 17%|█▋        | 190/1090 [08:12<39:30,  2.63s/it] 18%|█▊        | 191/1090 [08:15<38:44,  2.59s/it] 18%|█▊        | 192/1090 [08:17<39:00,  2.61s/it] 18%|█▊        | 193/1090 [08:20<38:48,  2.60s/it] 18%|█▊        | 194/1090 [08:23<38:44,  2.59s/it] 18%|█▊        | 195/1090 [08:25<39:18,  2.63s/it] 18%|█▊        | 196/1090 [08:28<38:48,  2.60s/it] 18%|█▊        | 197/1090 [08:31<38:57,  2.62s/it] 18%|█▊        | 198/1090 [08:33<39:02,  2.63s/it] 18%|█▊        | 199/1090 [08:36<38:29,  2.59s/it] 18%|█▊        | 200/1090 [08:38<38:41,  2.61s/it] 18%|█▊        | 201/1090 [08:41<39:20,  2.65s/it] 19%|█▊        | 202/1090 [08:44<39:08,  2.65s/it] 19%|█▊        | 203/1090 [08:46<38:42,  2.62s/it] 19%|█▊        | 204/1090 [08:49<37:53,  2.57s/it] 19%|█▉        | 205/1090 [08:51<38:09,  2.59s/it] 19%|█▉        | 206/1090 [08:54<38:11,  2.59s/it] 19%|█▉        | 207/1090 [08:56<37:44,  2.56s/it] 19%|█▉        | 208/1090 [08:59<38:27,  2.62s/it] 19%|█▉        | 209/1090 [09:02<37:25,  2.55s/it] 19%|█▉        | 210/1090 [09:04<38:36,  2.63s/it] 19%|█▉        | 211/1090 [09:07<38:41,  2.64s/it] 19%|█▉        | 212/1090 [09:10<38:39,  2.64s/it] 20%|█▉        | 213/1090 [09:12<38:22,  2.63s/it] 20%|█▉        | 214/1090 [09:15<38:48,  2.66s/it] 20%|█▉        | 215/1090 [09:18<38:16,  2.62s/it] 20%|█▉        | 216/1090 [09:21<40:18,  2.77s/it] 20%|█▉        | 217/1090 [09:23<39:22,  2.71s/it] 20%|██        | 218/1090 [09:26<39:39,  2.73s/it] 20%|██        | 219/1090 [09:29<39:07,  2.70s/it] 20%|██        | 220/1090 [09:31<38:19,  2.64s/it] 20%|██        | 221/1090 [09:34<39:17,  2.71s/it] 20%|██        | 222/1090 [09:36<37:36,  2.60s/it] 20%|██        | 223/1090 [09:39<38:46,  2.68s/it] 21%|██        | 224/1090 [09:42<38:48,  2.69s/it] 21%|██        | 225/1090 [09:45<39:34,  2.74s/it] 21%|██        | 226/1090 [09:47<38:27,  2.67s/it] 21%|██        | 227/1090 [09:50<37:40,  2.62s/it] 21%|██        | 228/1090 [09:52<37:10,  2.59s/it] 21%|██        | 229/1090 [09:55<38:10,  2.66s/it] 21%|██        | 230/1090 [09:58<36:48,  2.57s/it] 21%|██        | 231/1090 [10:00<37:42,  2.63s/it] 21%|██▏       | 232/1090 [10:03<37:27,  2.62s/it] 21%|██▏       | 233/1090 [10:05<36:33,  2.56s/it] 21%|██▏       | 234/1090 [10:08<36:48,  2.58s/it] 22%|██▏       | 235/1090 [10:11<36:40,  2.57s/it] 22%|██▏       | 236/1090 [10:13<37:07,  2.61s/it] 22%|██▏       | 237/1090 [10:16<37:14,  2.62s/it] 22%|██▏       | 238/1090 [10:18<36:38,  2.58s/it] 22%|██▏       | 239/1090 [10:21<36:38,  2.58s/it] 22%|██▏       | 240/1090 [10:24<37:32,  2.65s/it] 22%|██▏       | 241/1090 [10:26<36:19,  2.57s/it] 22%|██▏       | 242/1090 [10:29<36:17,  2.57s/it] 22%|██▏       | 243/1090 [10:31<36:56,  2.62s/it] 22%|██▏       | 244/1090 [10:34<36:50,  2.61s/it] 22%|██▏       | 245/1090 [10:37<39:14,  2.79s/it] 23%|██▎       | 246/1090 [10:40<38:29,  2.74s/it] 23%|██▎       | 247/1090 [10:42<37:21,  2.66s/it] 23%|██▎       | 248/1090 [10:45<37:06,  2.64s/it] 23%|██▎       | 249/1090 [10:48<37:06,  2.65s/it] 23%|██▎       | 250/1090 [10:50<37:21,  2.67s/it] 23%|██▎       | 251/1090 [10:53<37:10,  2.66s/it] 23%|██▎       | 252/1090 [10:56<37:06,  2.66s/it] 23%|██▎       | 253/1090 [10:58<35:53,  2.57s/it] 23%|██▎       | 254/1090 [11:01<35:54,  2.58s/it] 23%|██▎       | 255/1090 [11:03<36:46,  2.64s/it] 23%|██▎       | 256/1090 [11:06<36:21,  2.62s/it] 24%|██▎       | 257/1090 [11:08<35:50,  2.58s/it] 24%|██▎       | 258/1090 [11:11<36:45,  2.65s/it] 24%|██▍       | 259/1090 [11:14<36:00,  2.60s/it] 24%|██▍       | 260/1090 [11:16<36:38,  2.65s/it] 24%|██▍       | 261/1090 [11:19<36:24,  2.63s/it] 24%|██▍       | 262/1090 [11:22<35:53,  2.60s/it] 24%|██▍       | 263/1090 [11:24<36:13,  2.63s/it] 24%|██▍       | 264/1090 [11:27<35:53,  2.61s/it] 24%|██▍       | 265/1090 [11:30<36:10,  2.63s/it] 24%|██▍       | 266/1090 [11:32<35:56,  2.62s/it] 24%|██▍       | 267/1090 [11:35<36:18,  2.65s/it] 25%|██▍       | 268/1090 [11:38<36:28,  2.66s/it] 25%|██▍       | 269/1090 [11:40<36:19,  2.65s/it] 25%|██▍       | 270/1090 [11:43<35:15,  2.58s/it] 25%|██▍       | 271/1090 [11:45<34:56,  2.56s/it] 25%|██▍       | 272/1090 [11:48<34:51,  2.56s/it] 25%|██▌       | 273/1090 [11:50<34:52,  2.56s/it] 25%|██▌       | 274/1090 [11:53<35:38,  2.62s/it] 25%|██▌       | 275/1090 [11:55<34:31,  2.54s/it] 25%|██▌       | 276/1090 [11:58<34:22,  2.53s/it] 25%|██▌       | 277/1090 [12:00<34:13,  2.53s/it] 26%|██▌       | 278/1090 [12:03<34:25,  2.54s/it] 26%|██▌       | 279/1090 [12:06<34:42,  2.57s/it] 26%|██▌       | 280/1090 [12:08<34:08,  2.53s/it] 26%|██▌       | 281/1090 [12:11<34:14,  2.54s/it] 26%|██▌       | 282/1090 [12:13<33:58,  2.52s/it] 26%|██▌       | 283/1090 [12:16<34:23,  2.56s/it] 26%|██▌       | 284/1090 [12:18<34:40,  2.58s/it] 26%|██▌       | 285/1090 [12:21<34:31,  2.57s/it] 26%|██▌       | 286/1090 [12:23<34:34,  2.58s/it] 26%|██▋       | 287/1090 [12:26<35:18,  2.64s/it] 26%|██▋       | 288/1090 [12:29<35:07,  2.63s/it] 27%|██▋       | 289/1090 [12:31<35:10,  2.63s/it] 27%|██▋       | 290/1090 [12:34<34:52,  2.62s/it] 27%|██▋       | 291/1090 [12:37<34:37,  2.60s/it] 27%|██▋       | 292/1090 [12:39<34:33,  2.60s/it] 27%|██▋       | 293/1090 [12:42<34:25,  2.59s/it] 27%|██▋       | 294/1090 [12:44<33:57,  2.56s/it] 27%|██▋       | 295/1090 [12:47<33:39,  2.54s/it] 27%|██▋       | 296/1090 [12:49<33:52,  2.56s/it] 27%|██▋       | 297/1090 [12:52<34:24,  2.60s/it] 27%|██▋       | 298/1090 [12:55<34:15,  2.59s/it] 27%|██▋       | 299/1090 [12:58<35:12,  2.67s/it] 28%|██▊       | 300/1090 [13:00<34:58,  2.66s/it] 28%|██▊       | 301/1090 [13:03<35:30,  2.70s/it] 28%|██▊       | 302/1090 [13:05<34:46,  2.65s/it] 28%|██▊       | 303/1090 [13:08<33:57,  2.59s/it] 28%|██▊       | 304/1090 [13:11<33:56,  2.59s/it] 28%|██▊       | 305/1090 [13:13<33:46,  2.58s/it] 28%|██▊       | 306/1090 [13:16<33:27,  2.56s/it] 28%|██▊       | 307/1090 [13:18<33:52,  2.60s/it] 28%|██▊       | 308/1090 [13:21<33:26,  2.57s/it] 28%|██▊       | 309/1090 [13:23<33:12,  2.55s/it] 28%|██▊       | 310/1090 [13:26<32:29,  2.50s/it] 29%|██▊       | 311/1090 [13:28<33:24,  2.57s/it] 29%|██▊       | 312/1090 [13:31<34:03,  2.63s/it] 29%|██▊       | 313/1090 [13:34<33:50,  2.61s/it] 29%|██▉       | 314/1090 [13:36<32:57,  2.55s/it] 29%|██▉       | 315/1090 [13:39<32:58,  2.55s/it] 29%|██▉       | 316/1090 [13:41<33:27,  2.59s/it] 29%|██▉       | 317/1090 [13:44<34:27,  2.68s/it] 29%|██▉       | 318/1090 [13:47<34:20,  2.67s/it] 29%|██▉       | 319/1090 [13:50<34:16,  2.67s/it] 29%|██▉       | 320/1090 [13:52<34:07,  2.66s/it] 29%|██▉       | 321/1090 [13:55<34:36,  2.70s/it] 30%|██▉       | 322/1090 [13:58<34:28,  2.69s/it] 30%|██▉       | 323/1090 [14:00<33:05,  2.59s/it] 30%|██▉       | 324/1090 [14:03<34:19,  2.69s/it] 30%|██▉       | 325/1090 [14:06<34:14,  2.69s/it] 30%|██▉       | 326/1090 [14:08<34:00,  2.67s/it] 30%|███       | 327/1090 [14:11<33:04,  2.60s/it] 30%|███       | 328/1090 [14:13<33:09,  2.61s/it] 30%|███       | 329/1090 [14:16<33:38,  2.65s/it] 30%|███       | 330/1090 [14:19<34:29,  2.72s/it] 30%|███       | 331/1090 [14:22<33:52,  2.68s/it] 30%|███       | 332/1090 [14:24<33:02,  2.62s/it] 31%|███       | 333/1090 [14:26<31:50,  2.52s/it] 31%|███       | 334/1090 [14:29<32:01,  2.54s/it] 31%|███       | 335/1090 [14:31<31:34,  2.51s/it] 31%|███       | 336/1090 [14:34<32:35,  2.59s/it] 31%|███       | 337/1090 [14:37<32:38,  2.60s/it] 31%|███       | 338/1090 [14:39<31:24,  2.51s/it] 31%|███       | 339/1090 [14:42<31:22,  2.51s/it] 31%|███       | 340/1090 [14:44<32:21,  2.59s/it] 31%|███▏      | 341/1090 [14:47<31:50,  2.55s/it] 31%|███▏      | 342/1090 [14:49<32:14,  2.59s/it] 31%|███▏      | 343/1090 [14:52<31:57,  2.57s/it] 32%|███▏      | 344/1090 [14:54<31:39,  2.55s/it] 32%|███▏      | 345/1090 [14:57<32:04,  2.58s/it] 32%|███▏      | 346/1090 [15:00<33:02,  2.67s/it] 32%|███▏      | 347/1090 [15:03<32:58,  2.66s/it] 32%|███▏      | 348/1090 [15:05<33:15,  2.69s/it] 32%|███▏      | 349/1090 [15:08<33:02,  2.68s/it] 32%|███▏      | 350/1090 [15:11<32:42,  2.65s/it] 32%|███▏      | 351/1090 [15:13<32:40,  2.65s/it] 32%|███▏      | 352/1090 [15:16<32:35,  2.65s/it] 32%|███▏      | 353/1090 [15:18<31:32,  2.57s/it] 32%|███▏      | 354/1090 [15:21<31:52,  2.60s/it] 33%|███▎      | 355/1090 [15:24<32:16,  2.63s/it] 33%|███▎      | 356/1090 [15:26<32:25,  2.65s/it] 33%|███▎      | 357/1090 [15:29<32:15,  2.64s/it] 33%|███▎      | 358/1090 [15:32<32:10,  2.64s/it] 33%|███▎      | 359/1090 [15:34<31:20,  2.57s/it] 33%|███▎      | 360/1090 [15:36<30:44,  2.53s/it] 33%|███▎      | 361/1090 [15:39<30:57,  2.55s/it] 33%|███▎      | 362/1090 [15:42<31:26,  2.59s/it] 33%|███▎      | 363/1090 [15:44<31:12,  2.58s/it] 33%|███▎      | 364/1090 [15:47<31:06,  2.57s/it] 33%|███▎      | 365/1090 [15:49<30:55,  2.56s/it] 34%|███▎      | 366/1090 [15:52<31:03,  2.57s/it] 34%|███▎      | 367/1090 [15:55<31:10,  2.59s/it] 34%|███▍      | 368/1090 [15:57<31:18,  2.60s/it] 34%|███▍      | 369/1090 [16:00<32:10,  2.68s/it] 34%|███▍      | 370/1090 [16:03<31:43,  2.64s/it] 34%|███▍      | 371/1090 [16:05<30:50,  2.57s/it] 34%|███▍      | 372/1090 [16:08<31:15,  2.61s/it] 34%|███▍      | 373/1090 [16:11<31:50,  2.66s/it] 34%|███▍      | 374/1090 [16:13<30:48,  2.58s/it] 34%|███▍      | 375/1090 [16:16<30:33,  2.56s/it] 34%|███▍      | 376/1090 [16:18<30:10,  2.54s/it] 35%|███▍      | 377/1090 [16:20<30:04,  2.53s/it] 35%|███▍      | 378/1090 [16:23<30:53,  2.60s/it] 35%|███▍      | 379/1090 [16:26<31:33,  2.66s/it] 35%|███▍      | 380/1090 [16:28<30:14,  2.56s/it] 35%|███▍      | 381/1090 [16:31<30:16,  2.56s/it] 35%|███▌      | 382/1090 [16:34<31:03,  2.63s/it] 35%|███▌      | 383/1090 [16:36<30:33,  2.59s/it] 35%|███▌      | 384/1090 [16:39<29:50,  2.54s/it] 35%|███▌      | 385/1090 [16:41<30:06,  2.56s/it] 35%|███▌      | 386/1090 [16:44<29:54,  2.55s/it] 36%|███▌      | 387/1090 [16:46<30:20,  2.59s/it] 36%|███▌      | 388/1090 [16:49<30:18,  2.59s/it] 36%|███▌      | 389/1090 [16:52<30:10,  2.58s/it] 36%|███▌      | 390/1090 [16:54<29:48,  2.55s/it] 36%|███▌      | 391/1090 [16:57<30:40,  2.63s/it] 36%|███▌      | 392/1090 [17:00<30:41,  2.64s/it] 36%|███▌      | 393/1090 [17:02<29:46,  2.56s/it] 36%|███▌      | 394/1090 [17:04<29:25,  2.54s/it] 36%|███▌      | 395/1090 [17:07<29:41,  2.56s/it] 36%|███▋      | 396/1090 [17:10<30:29,  2.64s/it] 36%|███▋      | 397/1090 [17:12<29:05,  2.52s/it] 37%|███▋      | 398/1090 [17:15<29:04,  2.52s/it] 37%|███▋      | 399/1090 [17:17<28:56,  2.51s/it] 37%|███▋      | 400/1090 [17:20<29:08,  2.53s/it] 37%|███▋      | 401/1090 [17:22<28:36,  2.49s/it] 37%|███▋      | 402/1090 [17:25<28:56,  2.52s/it] 37%|███▋      | 403/1090 [17:27<28:52,  2.52s/it] 37%|███▋      | 404/1090 [17:30<28:58,  2.53s/it] 37%|███▋      | 405/1090 [17:32<28:48,  2.52s/it] 37%|███▋      | 406/1090 [17:35<29:05,  2.55s/it] 37%|███▋      | 407/1090 [17:38<29:22,  2.58s/it] 37%|███▋      | 408/1090 [17:40<29:12,  2.57s/it] 38%|███▊      | 409/1090 [17:43<29:44,  2.62s/it] 38%|███▊      | 410/1090 [17:45<29:08,  2.57s/it] 38%|███▊      | 411/1090 [17:48<29:14,  2.58s/it] 38%|███▊      | 412/1090 [17:51<29:23,  2.60s/it] 38%|███▊      | 413/1090 [17:53<29:31,  2.62s/it] 38%|███▊      | 414/1090 [17:56<29:26,  2.61s/it] 38%|███▊      | 415/1090 [17:58<29:37,  2.63s/it] 38%|███▊      | 416/1090 [18:01<29:28,  2.62s/it] 38%|███▊      | 417/1090 [18:04<29:22,  2.62s/it] 38%|███▊      | 418/1090 [18:06<29:14,  2.61s/it] 38%|███▊      | 419/1090 [18:09<29:33,  2.64s/it] 39%|███▊      | 420/1090 [18:12<30:04,  2.69s/it] 39%|███▊      | 421/1090 [18:14<29:37,  2.66s/it] 39%|███▊      | 422/1090 [18:17<29:40,  2.67s/it] 39%|███▉      | 423/1090 [18:20<29:31,  2.66s/it] 39%|███▉      | 424/1090 [18:22<28:46,  2.59s/it] 39%|███▉      | 425/1090 [18:25<29:07,  2.63s/it] 39%|███▉      | 426/1090 [18:27<28:47,  2.60s/it] 39%|███▉      | 427/1090 [18:30<28:58,  2.62s/it] 39%|███▉      | 428/1090 [18:33<28:41,  2.60s/it] 39%|███▉      | 429/1090 [18:35<28:33,  2.59s/it] 39%|███▉      | 430/1090 [18:38<28:06,  2.55s/it] 40%|███▉      | 431/1090 [18:40<28:21,  2.58s/it] 40%|███▉      | 432/1090 [18:43<28:56,  2.64s/it] 40%|███▉      | 433/1090 [18:46<28:41,  2.62s/it] 40%|███▉      | 434/1090 [18:48<28:33,  2.61s/it] 40%|███▉      | 435/1090 [18:51<28:04,  2.57s/it] 40%|████      | 436/1090 [18:53<28:07,  2.58s/it] 40%|████      | 437/1090 [18:56<27:43,  2.55s/it] 40%|████      | 438/1090 [18:58<27:23,  2.52s/it] 40%|████      | 439/1090 [19:01<27:22,  2.52s/it] 40%|████      | 440/1090 [19:03<27:44,  2.56s/it] 40%|████      | 441/1090 [19:06<27:54,  2.58s/it] 41%|████      | 442/1090 [19:09<27:53,  2.58s/it] 41%|████      | 443/1090 [19:11<27:43,  2.57s/it] 41%|████      | 444/1090 [19:14<27:39,  2.57s/it] 41%|████      | 445/1090 [19:16<27:42,  2.58s/it] 41%|████      | 446/1090 [19:19<27:19,  2.55s/it] 41%|████      | 447/1090 [19:21<27:29,  2.56s/it] 41%|████      | 448/1090 [19:24<27:33,  2.58s/it] 41%|████      | 449/1090 [19:27<27:17,  2.56s/it] 41%|████▏     | 450/1090 [19:29<27:04,  2.54s/it] 41%|████▏     | 451/1090 [19:32<27:25,  2.58s/it] 41%|████▏     | 452/1090 [19:34<27:31,  2.59s/it] 42%|████▏     | 453/1090 [19:37<27:13,  2.56s/it] 42%|████▏     | 454/1090 [19:39<27:19,  2.58s/it] 42%|████▏     | 455/1090 [19:42<27:11,  2.57s/it] 42%|████▏     | 456/1090 [19:45<27:08,  2.57s/it] 42%|████▏     | 457/1090 [19:47<26:59,  2.56s/it] 42%|████▏     | 458/1090 [19:50<27:30,  2.61s/it] 42%|████▏     | 459/1090 [19:52<27:27,  2.61s/it] 42%|████▏     | 460/1090 [19:55<27:23,  2.61s/it] 42%|████▏     | 461/1090 [19:58<27:29,  2.62s/it] 42%|████▏     | 462/1090 [20:00<27:23,  2.62s/it] 42%|████▏     | 463/1090 [20:03<27:28,  2.63s/it] 43%|████▎     | 464/1090 [20:05<26:40,  2.56s/it] 43%|████▎     | 465/1090 [20:08<27:09,  2.61s/it] 43%|████▎     | 466/1090 [20:11<26:46,  2.58s/it] 43%|████▎     | 467/1090 [20:13<27:16,  2.63s/it] 43%|████▎     | 468/1090 [20:16<26:42,  2.58s/it] 43%|████▎     | 469/1090 [20:19<27:17,  2.64s/it] 43%|████▎     | 470/1090 [20:21<27:15,  2.64s/it] 43%|████▎     | 471/1090 [20:24<26:54,  2.61s/it] 43%|████▎     | 472/1090 [20:27<27:25,  2.66s/it] 43%|████▎     | 473/1090 [20:29<26:46,  2.60s/it] 43%|████▎     | 474/1090 [20:31<26:22,  2.57s/it] 44%|████▎     | 475/1090 [20:34<26:31,  2.59s/it] 44%|████▎     | 476/1090 [20:37<26:35,  2.60s/it] 44%|████▍     | 477/1090 [20:39<26:58,  2.64s/it] 44%|████▍     | 478/1090 [20:42<27:29,  2.70s/it] 44%|████▍     | 479/1090 [20:45<27:32,  2.70s/it] 44%|████▍     | 480/1090 [20:48<26:58,  2.65s/it] 44%|████▍     | 481/1090 [20:50<26:43,  2.63s/it] 44%|████▍     | 482/1090 [20:53<26:09,  2.58s/it] 44%|████▍     | 483/1090 [20:55<26:05,  2.58s/it] 44%|████▍     | 484/1090 [20:58<26:54,  2.66s/it] 44%|████▍     | 485/1090 [21:00<25:56,  2.57s/it] 45%|████▍     | 486/1090 [21:03<26:31,  2.63s/it] 45%|████▍     | 487/1090 [21:06<25:46,  2.56s/it] 45%|████▍     | 488/1090 [21:08<25:38,  2.56s/it] 45%|████▍     | 489/1090 [21:11<25:43,  2.57s/it] 45%|████▍     | 490/1090 [21:13<25:47,  2.58s/it] 45%|████▌     | 491/1090 [21:16<25:37,  2.57s/it] 45%|████▌     | 492/1090 [21:18<25:29,  2.56s/it] 45%|████▌     | 493/1090 [21:21<25:21,  2.55s/it] 45%|████▌     | 494/1090 [21:24<25:31,  2.57s/it] 45%|████▌     | 495/1090 [21:26<26:16,  2.65s/it] 46%|████▌     | 496/1090 [21:29<26:06,  2.64s/it] 46%|████▌     | 497/1090 [21:32<25:59,  2.63s/it] 46%|████▌     | 498/1090 [21:34<25:46,  2.61s/it] 46%|████▌     | 499/1090 [21:37<25:06,  2.55s/it] 46%|████▌     | 500/1090 [21:39<25:03,  2.55s/it]                                                  {'loss': 0.5067, 'learning_rate': 2.7064220183486238e-05, 'epoch': 2.29}
 46%|████▌     | 500/1090 [21:39<25:03,  2.55s/it][INFO|configuration_utils.py:575] 2024-05-24 10:42:25,836 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}


  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:23<18:00, 11.87s/it][A
  3%|▎         | 3/93 [00:48<25:58, 17.32s/it][A
  4%|▍         | 4/93 [01:14<30:27, 20.54s/it][A
  5%|▌         | 5/93 [01:40<32:51, 22.40s/it][A
  6%|▋         | 6/93 [02:06<34:10, 23.57s/it][A
  8%|▊         | 7/93 [02:32<34:53, 24.34s/it][A
  9%|▊         | 8/93 [02:53<33:01, 23.31s/it][A
 10%|▉         | 9/93 [03:18<33:11, 23.70s/it][A
 11%|█         | 10/93 [03:43<33:33, 24.26s/it][A
 12%|█▏        | 11/93 [04:08<33:24, 24.45s/it][A
 13%|█▎        | 12/93 [04:31<32:25, 24.01s/it][A
 14%|█▍        | 13/93 [04:55<31:54, 23.93s/it][A
 15%|█▌        | 14/93 [05:14<29:49, 22.65s/it][A
 16%|█▌        | 15/93 [05:36<29:07, 22.41s/it][A
 17%|█▋        | 16/93 [05:57<28:05, 21.89s/it][A
 18%|█▊        | 17/93 [06:21<28:43, 22.68s/it][A
 19%|█▉        | 18/93 [06:47<29:24, 23.53s/it][A
 20%|██        | 19/93 [07:13<29:55, 24.26s/it][A
 22%|██▏       | 20/93 [07:36<29:11, 23.99s/it][A
 23%|██▎       | 21/93 [08:01<28:59, 24.16s/it][A
 24%|██▎       | 22/93 [08:25<28:29, 24.08s/it][A
 25%|██▍       | 23/93 [08:49<28:11, 24.16s/it][A
 26%|██▌       | 24/93 [09:12<27:26, 23.87s/it][A
 27%|██▋       | 25/93 [09:36<26:54, 23.74s/it][A
 28%|██▊       | 26/93 [09:59<26:18, 23.56s/it][A
 29%|██▉       | 27/93 [10:25<26:41, 24.26s/it][A
 30%|███       | 28/93 [10:49<26:12, 24.20s/it][A
 31%|███       | 29/93 [11:15<26:20, 24.70s/it][A
 32%|███▏      | 30/93 [11:37<25:16, 24.07s/it][A
 33%|███▎      | 31/93 [12:03<25:26, 24.61s/it][A
 34%|███▍      | 32/93 [12:29<25:20, 24.93s/it][A
 35%|███▌      | 33/93 [12:52<24:27, 24.47s/it][A
 37%|███▋      | 34/93 [13:18<24:28, 24.89s/it][A
 38%|███▊      | 35/93 [13:40<23:20, 24.15s/it][A
 39%|███▊      | 36/93 [14:06<23:27, 24.68s/it][A
 40%|███▉      | 37/93 [14:29<22:33, 24.17s/it][A
 41%|████      | 38/93 [14:55<22:37, 24.68s/it][A
 42%|████▏     | 39/93 [15:19<22:04, 24.52s/it][A
 43%|████▎     | 40/93 [15:45<22:00, 24.92s/it][A
 44%|████▍     | 41/93 [16:09<21:17, 24.57s/it][A
 45%|████▌     | 42/93 [16:35<21:14, 24.98s/it][A
 46%|████▌     | 43/93 [17:01<21:03, 25.26s/it][A
 47%|████▋     | 44/93 [17:27<20:47, 25.45s/it][A
 48%|████▊     | 45/93 [17:51<20:07, 25.16s/it][A
 49%|████▉     | 46/93 [18:15<19:19, 24.67s/it][A
 51%|█████     | 47/93 [18:40<18:59, 24.77s/it][A
 52%|█████▏    | 48/93 [19:04<18:26, 24.59s/it][A
 53%|█████▎    | 49/93 [19:30<18:19, 24.99s/it][A
 54%|█████▍    | 50/93 [19:51<17:04, 23.81s/it][A
 55%|█████▍    | 51/93 [20:17<17:06, 24.43s/it][A
 56%|█████▌    | 52/93 [20:43<16:59, 24.86s/it][A
 57%|█████▋    | 53/93 [21:09<16:46, 25.17s/it][A
 58%|█████▊    | 54/93 [21:34<16:30, 25.40s/it][A
 59%|█████▉    | 55/93 [21:58<15:45, 24.89s/it][A
 60%|██████    | 56/93 [22:22<15:08, 24.56s/it][A
 61%|██████▏   | 57/93 [22:47<14:49, 24.71s/it][A
 62%|██████▏   | 58/93 [23:10<14:11, 24.33s/it][A
 63%|██████▎   | 59/93 [23:31<13:06, 23.13s/it][A
 65%|██████▍   | 60/93 [23:55<12:56, 23.54s/it][A
 66%|██████▌   | 61/93 [24:20<12:40, 23.77s/it][A
 67%|██████▋   | 62/93 [24:45<12:32, 24.28s/it][A
 68%|██████▊   | 63/93 [25:07<11:42, 23.43s/it][A
 69%|██████▉   | 64/93 [25:32<11:41, 24.18s/it][A
 70%|██████▉   | 65/93 [25:53<10:49, 23.20s/it][A
 71%|███████   | 66/93 [26:14<10:08, 22.53s/it][A
 72%|███████▏  | 67/93 [26:40<10:10, 23.49s/it][A
 73%|███████▎  | 68/93 [27:02<09:34, 22.99s/it][A
 74%|███████▍  | 69/93 [27:27<09:28, 23.69s/it][A
 75%|███████▌  | 70/93 [27:52<09:09, 23.88s/it][A
 76%|███████▋  | 71/93 [28:12<08:25, 22.97s/it][A
 77%|███████▋  | 72/93 [28:38<08:20, 23.85s/it][A
 78%|███████▊  | 73/93 [29:04<08:08, 24.41s/it][A
 80%|███████▉  | 74/93 [29:29<07:49, 24.69s/it][A
 81%|████████  | 75/93 [29:55<07:30, 25.05s/it][A
 82%|████████▏ | 76/93 [30:16<06:42, 23.66s/it][A
 83%|████████▎ | 77/93 [30:42<06:29, 24.35s/it][A
 84%|████████▍ | 78/93 [31:07<06:10, 24.67s/it][A
 85%|████████▍ | 79/93 [31:33<05:50, 25.03s/it][A
 86%|████████▌ | 80/93 [31:52<05:03, 23.38s/it][A
 87%|████████▋ | 81/93 [32:16<04:42, 23.50s/it][A
 88%|████████▊ | 82/93 [32:41<04:21, 23.76s/it][A
 89%|████████▉ | 83/93 [33:01<03:46, 22.65s/it][A
 90%|█████████ | 84/93 [33:27<03:32, 23.61s/it][A
 91%|█████████▏| 85/93 [33:47<03:01, 22.67s/it][A
 92%|█████████▏| 86/93 [34:13<02:45, 23.62s/it][A
 94%|█████████▎| 87/93 [34:39<02:25, 24.33s/it][A
 95%|█████████▍| 88/93 [35:05<02:04, 24.80s/it][A
 96%|█████████▌| 89/93 [35:31<01:40, 25.13s/it][A
 97%|█████████▋| 90/93 [35:57<01:16, 25.35s/it][A
 98%|█████████▊| 91/93 [36:19<00:48, 24.41s/it][A
 99%|█████████▉| 92/93 [36:40<00:23, 23.47s/it][A
100%|██████████| 93/93 [37:00<00:00, 22.50s/it][A                                                  
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 42.5955, 'eval_rouge2': 20.3095, 'eval_rougeL': 30.8883, 'eval_rougeLsum': 40.0724, 'eval_gen_len': 65.83635752688173, 'eval_runtime': 2263.4245, 'eval_samples_per_second': 1.325, 'eval_steps_per_second': 0.042, 'eval_block_avg': 18.141948187943903, 'epoch': 2.29}
 46%|████▌     | 500/1090 [59:23<25:03,  2.55s/it]
100%|██████████| 93/93 [37:17<00:00, 22.50s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 11:20:09,243 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-500
[INFO|configuration_utils.py:457] 2024-05-24 11:20:09,244 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/config.json
[INFO|configuration_utils.py:362] 2024-05-24 11:20:09,245 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-500/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 11:20:12,183 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 11:20:12,184 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 11:20:12,184 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 11:20:12,231 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-500/spiece.model
 46%|████▌     | 501/1090 [59:28<111:40:08, 682.53s/it] 46%|████▌     | 502/1090 [59:31<78:10:03, 478.58s/it]  46%|████▌     | 503/1090 [59:33<54:44:52, 335.76s/it] 46%|████▌     | 504/1090 [59:36<38:22:54, 235.79s/it] 46%|████▋     | 505/1090 [59:39<26:57:25, 165.89s/it] 46%|████▋     | 506/1090 [59:41<18:57:45, 116.89s/it] 47%|████▋     | 507/1090 [59:44<13:21:50, 82.52s/it]  47%|████▋     | 508/1090 [59:46<9:27:51, 58.54s/it]  47%|████▋     | 509/1090 [59:49<6:44:47, 41.80s/it] 47%|████▋     | 510/1090 [59:52<4:50:31, 30.05s/it] 47%|████▋     | 511/1090 [59:54<3:30:31, 21.82s/it] 47%|████▋     | 512/1090 [59:57<2:33:52, 15.97s/it] 47%|████▋     | 513/1090 [59:59<1:55:24, 12.00s/it] 47%|████▋     | 514/1090 [1:00:02<1:28:07,  9.18s/it] 47%|████▋     | 515/1090 [1:00:05<1:09:34,  7.26s/it] 47%|████▋     | 516/1090 [1:00:07<56:28,  5.90s/it]   47%|████▋     | 517/1090 [1:00:10<46:36,  4.88s/it] 48%|████▊     | 518/1090 [1:00:12<39:47,  4.17s/it] 48%|████▊     | 519/1090 [1:00:15<35:32,  3.74s/it] 48%|████▊     | 520/1090 [1:00:18<31:35,  3.33s/it] 48%|████▊     | 521/1090 [1:00:21<31:10,  3.29s/it] 48%|████▊     | 522/1090 [1:00:23<28:58,  3.06s/it] 48%|████▊     | 523/1090 [1:00:26<27:56,  2.96s/it] 48%|████▊     | 524/1090 [1:00:29<26:58,  2.86s/it] 48%|████▊     | 525/1090 [1:00:31<26:16,  2.79s/it] 48%|████▊     | 526/1090 [1:00:34<25:42,  2.74s/it] 48%|████▊     | 527/1090 [1:00:37<25:35,  2.73s/it] 48%|████▊     | 528/1090 [1:00:39<25:08,  2.68s/it] 49%|████▊     | 529/1090 [1:00:42<24:32,  2.63s/it] 49%|████▊     | 530/1090 [1:00:44<24:19,  2.61s/it] 49%|████▊     | 531/1090 [1:00:47<24:14,  2.60s/it] 49%|████▉     | 532/1090 [1:00:49<23:57,  2.58s/it] 49%|████▉     | 533/1090 [1:00:52<24:13,  2.61s/it] 49%|████▉     | 534/1090 [1:00:55<23:58,  2.59s/it] 49%|████▉     | 535/1090 [1:00:57<23:45,  2.57s/it] 49%|████▉     | 536/1090 [1:01:00<24:02,  2.60s/it] 49%|████▉     | 537/1090 [1:01:02<23:54,  2.59s/it] 49%|████▉     | 538/1090 [1:01:05<24:14,  2.63s/it] 49%|████▉     | 539/1090 [1:01:08<24:12,  2.64s/it] 50%|████▉     | 540/1090 [1:01:10<24:02,  2.62s/it] 50%|████▉     | 541/1090 [1:01:13<23:38,  2.58s/it] 50%|████▉     | 542/1090 [1:01:15<23:04,  2.53s/it] 50%|████▉     | 543/1090 [1:01:18<22:59,  2.52s/it] 50%|████▉     | 544/1090 [1:01:20<22:56,  2.52s/it] 50%|█████     | 545/1090 [1:01:23<23:03,  2.54s/it] 50%|█████     | 546/1090 [1:01:26<23:30,  2.59s/it] 50%|█████     | 547/1090 [1:01:28<22:46,  2.52s/it] 50%|█████     | 548/1090 [1:01:31<23:56,  2.65s/it] 50%|█████     | 549/1090 [1:01:33<23:59,  2.66s/it] 50%|█████     | 550/1090 [1:01:36<23:14,  2.58s/it] 51%|█████     | 551/1090 [1:01:39<23:18,  2.60s/it] 51%|█████     | 552/1090 [1:01:41<23:15,  2.59s/it] 51%|█████     | 553/1090 [1:01:44<23:41,  2.65s/it] 51%|█████     | 554/1090 [1:01:46<22:49,  2.56s/it] 51%|█████     | 555/1090 [1:01:49<22:54,  2.57s/it] 51%|█████     | 556/1090 [1:01:52<23:30,  2.64s/it] 51%|█████     | 557/1090 [1:01:54<22:47,  2.57s/it] 51%|█████     | 558/1090 [1:01:57<22:43,  2.56s/it] 51%|█████▏    | 559/1090 [1:01:59<22:36,  2.56s/it] 51%|█████▏    | 560/1090 [1:02:02<22:35,  2.56s/it] 51%|█████▏    | 561/1090 [1:02:04<22:30,  2.55s/it] 52%|█████▏    | 562/1090 [1:02:07<22:41,  2.58s/it] 52%|█████▏    | 563/1090 [1:02:09<22:23,  2.55s/it] 52%|█████▏    | 564/1090 [1:02:12<22:13,  2.54s/it] 52%|█████▏    | 565/1090 [1:02:14<22:20,  2.55s/it] 52%|█████▏    | 566/1090 [1:02:17<23:15,  2.66s/it] 52%|█████▏    | 567/1090 [1:02:20<22:27,  2.58s/it] 52%|█████▏    | 568/1090 [1:02:22<22:20,  2.57s/it] 52%|█████▏    | 569/1090 [1:02:25<21:54,  2.52s/it] 52%|█████▏    | 570/1090 [1:02:27<22:18,  2.57s/it] 52%|█████▏    | 571/1090 [1:02:30<21:57,  2.54s/it] 52%|█████▏    | 572/1090 [1:02:32<21:50,  2.53s/it] 53%|█████▎    | 573/1090 [1:02:35<21:51,  2.54s/it] 53%|█████▎    | 574/1090 [1:02:38<22:01,  2.56s/it] 53%|█████▎    | 575/1090 [1:02:40<21:56,  2.56s/it] 53%|█████▎    | 576/1090 [1:02:43<22:30,  2.63s/it] 53%|█████▎    | 577/1090 [1:02:46<22:39,  2.65s/it] 53%|█████▎    | 578/1090 [1:02:48<22:33,  2.64s/it] 53%|█████▎    | 579/1090 [1:02:51<21:54,  2.57s/it] 53%|█████▎    | 580/1090 [1:02:53<22:21,  2.63s/it] 53%|█████▎    | 581/1090 [1:02:56<22:16,  2.63s/it] 53%|█████▎    | 582/1090 [1:02:59<22:08,  2.61s/it] 53%|█████▎    | 583/1090 [1:03:01<22:23,  2.65s/it] 54%|█████▎    | 584/1090 [1:03:04<22:17,  2.64s/it] 54%|█████▎    | 585/1090 [1:03:07<22:12,  2.64s/it] 54%|█████▍    | 586/1090 [1:03:09<21:53,  2.61s/it] 54%|█████▍    | 587/1090 [1:03:12<21:32,  2.57s/it] 54%|█████▍    | 588/1090 [1:03:14<21:45,  2.60s/it] 54%|█████▍    | 589/1090 [1:03:17<21:40,  2.60s/it] 54%|█████▍    | 590/1090 [1:03:20<22:15,  2.67s/it] 54%|█████▍    | 591/1090 [1:03:22<22:01,  2.65s/it] 54%|█████▍    | 592/1090 [1:03:25<21:57,  2.65s/it] 54%|█████▍    | 593/1090 [1:03:27<21:41,  2.62s/it] 54%|█████▍    | 594/1090 [1:03:30<22:14,  2.69s/it] 55%|█████▍    | 595/1090 [1:03:33<21:31,  2.61s/it] 55%|█████▍    | 596/1090 [1:03:35<21:20,  2.59s/it] 55%|█████▍    | 597/1090 [1:03:38<21:26,  2.61s/it] 55%|█████▍    | 598/1090 [1:03:41<21:28,  2.62s/it] 55%|█████▍    | 599/1090 [1:03:43<21:53,  2.68s/it] 55%|█████▌    | 600/1090 [1:03:46<21:38,  2.65s/it] 55%|█████▌    | 601/1090 [1:03:49<21:34,  2.65s/it] 55%|█████▌    | 602/1090 [1:03:51<21:26,  2.64s/it] 55%|█████▌    | 603/1090 [1:03:54<21:27,  2.64s/it] 55%|█████▌    | 604/1090 [1:03:56<21:08,  2.61s/it] 56%|█████▌    | 605/1090 [1:03:59<20:59,  2.60s/it] 56%|█████▌    | 606/1090 [1:04:02<20:51,  2.59s/it] 56%|█████▌    | 607/1090 [1:04:04<20:53,  2.60s/it] 56%|█████▌    | 608/1090 [1:04:07<20:42,  2.58s/it] 56%|█████▌    | 609/1090 [1:04:09<21:09,  2.64s/it] 56%|█████▌    | 610/1090 [1:04:12<20:57,  2.62s/it] 56%|█████▌    | 611/1090 [1:04:15<21:09,  2.65s/it] 56%|█████▌    | 612/1090 [1:04:17<20:47,  2.61s/it] 56%|█████▌    | 613/1090 [1:04:20<21:03,  2.65s/it] 56%|█████▋    | 614/1090 [1:04:23<21:10,  2.67s/it] 56%|█████▋    | 615/1090 [1:04:25<20:47,  2.63s/it] 57%|█████▋    | 616/1090 [1:04:28<20:27,  2.59s/it] 57%|█████▋    | 617/1090 [1:04:30<20:39,  2.62s/it] 57%|█████▋    | 618/1090 [1:04:33<20:10,  2.56s/it] 57%|█████▋    | 619/1090 [1:04:36<20:27,  2.61s/it] 57%|█████▋    | 620/1090 [1:04:38<20:29,  2.62s/it] 57%|█████▋    | 621/1090 [1:04:41<20:30,  2.62s/it] 57%|█████▋    | 622/1090 [1:04:43<20:14,  2.59s/it] 57%|█████▋    | 623/1090 [1:04:46<20:07,  2.59s/it] 57%|█████▋    | 624/1090 [1:04:49<20:06,  2.59s/it] 57%|█████▋    | 625/1090 [1:04:51<20:06,  2.59s/it] 57%|█████▋    | 626/1090 [1:04:54<19:51,  2.57s/it] 58%|█████▊    | 627/1090 [1:04:56<19:45,  2.56s/it] 58%|█████▊    | 628/1090 [1:04:59<19:33,  2.54s/it] 58%|█████▊    | 629/1090 [1:05:01<19:31,  2.54s/it] 58%|█████▊    | 630/1090 [1:05:04<19:41,  2.57s/it] 58%|█████▊    | 631/1090 [1:05:06<19:38,  2.57s/it] 58%|█████▊    | 632/1090 [1:05:09<19:32,  2.56s/it] 58%|█████▊    | 633/1090 [1:05:12<19:39,  2.58s/it] 58%|█████▊    | 634/1090 [1:05:14<19:32,  2.57s/it] 58%|█████▊    | 635/1090 [1:05:17<20:06,  2.65s/it] 58%|█████▊    | 636/1090 [1:05:20<20:02,  2.65s/it] 58%|█████▊    | 637/1090 [1:05:22<19:40,  2.61s/it] 59%|█████▊    | 638/1090 [1:05:25<19:24,  2.58s/it] 59%|█████▊    | 639/1090 [1:05:28<19:55,  2.65s/it] 59%|█████▊    | 640/1090 [1:05:30<19:55,  2.66s/it] 59%|█████▉    | 641/1090 [1:05:33<20:22,  2.72s/it] 59%|█████▉    | 642/1090 [1:05:36<20:09,  2.70s/it] 59%|█████▉    | 643/1090 [1:05:38<20:12,  2.71s/it] 59%|█████▉    | 644/1090 [1:05:41<19:43,  2.65s/it] 59%|█████▉    | 645/1090 [1:05:44<19:31,  2.63s/it] 59%|█████▉    | 646/1090 [1:05:46<19:15,  2.60s/it] 59%|█████▉    | 647/1090 [1:05:49<18:57,  2.57s/it] 59%|█████▉    | 648/1090 [1:05:51<18:57,  2.57s/it] 60%|█████▉    | 649/1090 [1:05:54<19:04,  2.60s/it] 60%|█████▉    | 650/1090 [1:05:57<19:19,  2.64s/it] 60%|█████▉    | 651/1090 [1:05:59<19:23,  2.65s/it] 60%|█████▉    | 652/1090 [1:06:02<19:07,  2.62s/it] 60%|█████▉    | 653/1090 [1:06:04<19:10,  2.63s/it] 60%|██████    | 654/1090 [1:06:07<19:29,  2.68s/it] 60%|██████    | 655/1090 [1:06:10<19:17,  2.66s/it] 60%|██████    | 656/1090 [1:06:13<19:15,  2.66s/it] 60%|██████    | 657/1090 [1:06:15<19:19,  2.68s/it] 60%|██████    | 658/1090 [1:06:18<19:12,  2.67s/it] 60%|██████    | 659/1090 [1:06:20<19:00,  2.65s/it] 61%|██████    | 660/1090 [1:06:23<18:56,  2.64s/it] 61%|██████    | 661/1090 [1:06:26<18:30,  2.59s/it] 61%|██████    | 662/1090 [1:06:28<18:30,  2.60s/it] 61%|██████    | 663/1090 [1:06:31<18:36,  2.61s/it] 61%|██████    | 664/1090 [1:06:33<18:27,  2.60s/it] 61%|██████    | 665/1090 [1:06:36<18:45,  2.65s/it] 61%|██████    | 666/1090 [1:06:39<18:18,  2.59s/it] 61%|██████    | 667/1090 [1:06:41<18:25,  2.61s/it] 61%|██████▏   | 668/1090 [1:06:44<18:20,  2.61s/it] 61%|██████▏   | 669/1090 [1:06:46<17:56,  2.56s/it] 61%|██████▏   | 670/1090 [1:06:49<18:06,  2.59s/it] 62%|██████▏   | 671/1090 [1:06:52<18:10,  2.60s/it] 62%|██████▏   | 672/1090 [1:06:54<18:37,  2.67s/it] 62%|██████▏   | 673/1090 [1:06:57<18:34,  2.67s/it] 62%|██████▏   | 674/1090 [1:07:00<18:41,  2.70s/it] 62%|██████▏   | 675/1090 [1:07:03<18:33,  2.68s/it] 62%|██████▏   | 676/1090 [1:07:05<18:12,  2.64s/it] 62%|██████▏   | 677/1090 [1:07:08<18:03,  2.62s/it] 62%|██████▏   | 678/1090 [1:07:11<18:44,  2.73s/it] 62%|██████▏   | 679/1090 [1:07:13<18:19,  2.68s/it] 62%|██████▏   | 680/1090 [1:07:16<18:20,  2.68s/it] 62%|██████▏   | 681/1090 [1:07:19<18:37,  2.73s/it] 63%|██████▎   | 682/1090 [1:07:21<18:40,  2.75s/it] 63%|██████▎   | 683/1090 [1:07:24<17:50,  2.63s/it] 63%|██████▎   | 684/1090 [1:07:26<17:33,  2.59s/it] 63%|██████▎   | 685/1090 [1:07:29<17:20,  2.57s/it] 63%|██████▎   | 686/1090 [1:07:31<17:19,  2.57s/it] 63%|██████▎   | 687/1090 [1:07:34<17:10,  2.56s/it] 63%|██████▎   | 688/1090 [1:07:36<16:59,  2.54s/it] 63%|██████▎   | 689/1090 [1:07:40<17:56,  2.69s/it] 63%|██████▎   | 690/1090 [1:07:42<17:59,  2.70s/it] 63%|██████▎   | 691/1090 [1:07:45<17:44,  2.67s/it] 63%|██████▎   | 692/1090 [1:07:47<17:25,  2.63s/it] 64%|██████▎   | 693/1090 [1:07:50<17:10,  2.60s/it] 64%|██████▎   | 694/1090 [1:07:52<17:08,  2.60s/it] 64%|██████▍   | 695/1090 [1:07:55<16:39,  2.53s/it] 64%|██████▍   | 696/1090 [1:07:57<16:42,  2.54s/it] 64%|██████▍   | 697/1090 [1:08:00<17:06,  2.61s/it] 64%|██████▍   | 698/1090 [1:08:03<16:39,  2.55s/it] 64%|██████▍   | 699/1090 [1:08:05<16:44,  2.57s/it] 64%|██████▍   | 700/1090 [1:08:08<17:02,  2.62s/it] 64%|██████▍   | 701/1090 [1:08:10<16:36,  2.56s/it] 64%|██████▍   | 702/1090 [1:08:13<17:05,  2.64s/it] 64%|██████▍   | 703/1090 [1:08:16<17:07,  2.66s/it] 65%|██████▍   | 704/1090 [1:08:18<16:57,  2.64s/it] 65%|██████▍   | 705/1090 [1:08:21<16:27,  2.56s/it] 65%|██████▍   | 706/1090 [1:08:24<16:36,  2.60s/it] 65%|██████▍   | 707/1090 [1:08:26<16:22,  2.56s/it] 65%|██████▍   | 708/1090 [1:08:29<16:14,  2.55s/it] 65%|██████▌   | 709/1090 [1:08:31<16:16,  2.56s/it] 65%|██████▌   | 710/1090 [1:08:34<16:34,  2.62s/it] 65%|██████▌   | 711/1090 [1:08:37<16:48,  2.66s/it] 65%|██████▌   | 712/1090 [1:08:39<17:04,  2.71s/it] 65%|██████▌   | 713/1090 [1:08:42<17:00,  2.71s/it] 66%|██████▌   | 714/1090 [1:08:45<17:07,  2.73s/it] 66%|██████▌   | 715/1090 [1:08:48<17:11,  2.75s/it] 66%|██████▌   | 716/1090 [1:08:50<17:01,  2.73s/it] 66%|██████▌   | 717/1090 [1:08:53<16:34,  2.66s/it] 66%|██████▌   | 718/1090 [1:08:56<16:34,  2.67s/it] 66%|██████▌   | 719/1090 [1:08:58<16:10,  2.62s/it] 66%|██████▌   | 720/1090 [1:09:01<15:57,  2.59s/it] 66%|██████▌   | 721/1090 [1:09:03<15:56,  2.59s/it] 66%|██████▌   | 722/1090 [1:09:06<16:00,  2.61s/it] 66%|██████▋   | 723/1090 [1:09:08<15:46,  2.58s/it] 66%|██████▋   | 724/1090 [1:09:11<15:46,  2.59s/it] 67%|██████▋   | 725/1090 [1:09:14<15:49,  2.60s/it] 67%|██████▋   | 726/1090 [1:09:16<15:52,  2.62s/it] 67%|██████▋   | 727/1090 [1:09:19<15:48,  2.61s/it] 67%|██████▋   | 728/1090 [1:09:22<15:43,  2.61s/it] 67%|██████▋   | 729/1090 [1:09:24<15:38,  2.60s/it] 67%|██████▋   | 730/1090 [1:09:27<15:28,  2.58s/it] 67%|██████▋   | 731/1090 [1:09:29<15:21,  2.57s/it] 67%|██████▋   | 732/1090 [1:09:32<15:29,  2.60s/it] 67%|██████▋   | 733/1090 [1:09:34<15:22,  2.58s/it] 67%|██████▋   | 734/1090 [1:09:37<15:13,  2.57s/it] 67%|██████▋   | 735/1090 [1:09:39<15:11,  2.57s/it] 68%|██████▊   | 736/1090 [1:09:42<15:02,  2.55s/it] 68%|██████▊   | 737/1090 [1:09:44<14:53,  2.53s/it] 68%|██████▊   | 738/1090 [1:09:47<15:10,  2.59s/it] 68%|██████▊   | 739/1090 [1:09:50<15:05,  2.58s/it] 68%|██████▊   | 740/1090 [1:09:52<15:09,  2.60s/it] 68%|██████▊   | 741/1090 [1:09:55<15:13,  2.62s/it] 68%|██████▊   | 742/1090 [1:09:58<14:58,  2.58s/it] 68%|██████▊   | 743/1090 [1:10:00<14:57,  2.59s/it] 68%|██████▊   | 744/1090 [1:10:03<14:48,  2.57s/it] 68%|██████▊   | 745/1090 [1:10:05<14:49,  2.58s/it] 68%|██████▊   | 746/1090 [1:10:08<15:07,  2.64s/it] 69%|██████▊   | 747/1090 [1:10:11<15:01,  2.63s/it] 69%|██████▊   | 748/1090 [1:10:13<14:54,  2.62s/it] 69%|██████▊   | 749/1090 [1:10:16<14:52,  2.62s/it] 69%|██████▉   | 750/1090 [1:10:18<14:21,  2.54s/it] 69%|██████▉   | 751/1090 [1:10:21<14:20,  2.54s/it] 69%|██████▉   | 752/1090 [1:10:23<14:16,  2.53s/it] 69%|██████▉   | 753/1090 [1:10:26<14:23,  2.56s/it] 69%|██████▉   | 754/1090 [1:10:29<14:28,  2.59s/it] 69%|██████▉   | 755/1090 [1:10:31<14:26,  2.59s/it] 69%|██████▉   | 756/1090 [1:10:34<14:20,  2.58s/it] 69%|██████▉   | 757/1090 [1:10:37<14:47,  2.66s/it] 70%|██████▉   | 758/1090 [1:10:39<14:39,  2.65s/it] 70%|██████▉   | 759/1090 [1:10:42<14:22,  2.61s/it] 70%|██████▉   | 760/1090 [1:10:44<14:35,  2.65s/it] 70%|██████▉   | 761/1090 [1:10:47<14:27,  2.64s/it] 70%|██████▉   | 762/1090 [1:10:50<14:26,  2.64s/it] 70%|███████   | 763/1090 [1:10:52<14:23,  2.64s/it] 70%|███████   | 764/1090 [1:10:55<14:59,  2.76s/it] 70%|███████   | 765/1090 [1:10:58<14:41,  2.71s/it] 70%|███████   | 766/1090 [1:11:01<14:51,  2.75s/it] 70%|███████   | 767/1090 [1:11:03<14:18,  2.66s/it] 70%|███████   | 768/1090 [1:11:06<14:20,  2.67s/it] 71%|███████   | 769/1090 [1:11:09<14:16,  2.67s/it] 71%|███████   | 770/1090 [1:11:11<13:47,  2.59s/it] 71%|███████   | 771/1090 [1:11:14<13:38,  2.57s/it] 71%|███████   | 772/1090 [1:11:17<14:14,  2.69s/it] 71%|███████   | 773/1090 [1:11:19<13:52,  2.63s/it] 71%|███████   | 774/1090 [1:11:22<13:53,  2.64s/it] 71%|███████   | 775/1090 [1:11:24<14:05,  2.68s/it] 71%|███████   | 776/1090 [1:11:27<14:07,  2.70s/it] 71%|███████▏  | 777/1090 [1:11:29<13:27,  2.58s/it] 71%|███████▏  | 778/1090 [1:11:32<13:55,  2.68s/it] 71%|███████▏  | 779/1090 [1:11:35<13:47,  2.66s/it] 72%|███████▏  | 780/1090 [1:11:37<13:23,  2.59s/it] 72%|███████▏  | 781/1090 [1:11:40<13:11,  2.56s/it] 72%|███████▏  | 782/1090 [1:11:43<13:13,  2.57s/it] 72%|███████▏  | 783/1090 [1:11:45<13:08,  2.57s/it] 72%|███████▏  | 784/1090 [1:11:48<12:57,  2.54s/it] 72%|███████▏  | 785/1090 [1:11:50<12:50,  2.53s/it] 72%|███████▏  | 786/1090 [1:11:53<13:00,  2.57s/it] 72%|███████▏  | 787/1090 [1:11:56<13:19,  2.64s/it] 72%|███████▏  | 788/1090 [1:11:58<13:03,  2.60s/it] 72%|███████▏  | 789/1090 [1:12:01<12:59,  2.59s/it] 72%|███████▏  | 790/1090 [1:12:03<12:51,  2.57s/it] 73%|███████▎  | 791/1090 [1:12:06<12:48,  2.57s/it] 73%|███████▎  | 792/1090 [1:12:08<12:44,  2.56s/it] 73%|███████▎  | 793/1090 [1:12:11<12:40,  2.56s/it] 73%|███████▎  | 794/1090 [1:12:13<12:48,  2.60s/it] 73%|███████▎  | 795/1090 [1:12:16<12:37,  2.57s/it] 73%|███████▎  | 796/1090 [1:12:19<12:30,  2.55s/it] 73%|███████▎  | 797/1090 [1:12:21<12:17,  2.52s/it] 73%|███████▎  | 798/1090 [1:12:23<12:14,  2.52s/it] 73%|███████▎  | 799/1090 [1:12:26<12:17,  2.53s/it] 73%|███████▎  | 800/1090 [1:12:29<12:18,  2.55s/it] 73%|███████▎  | 801/1090 [1:12:31<12:18,  2.56s/it] 74%|███████▎  | 802/1090 [1:12:34<12:10,  2.54s/it] 74%|███████▎  | 803/1090 [1:12:36<12:08,  2.54s/it] 74%|███████▍  | 804/1090 [1:12:39<12:30,  2.62s/it] 74%|███████▍  | 805/1090 [1:12:41<12:05,  2.55s/it] 74%|███████▍  | 806/1090 [1:12:44<12:12,  2.58s/it] 74%|███████▍  | 807/1090 [1:12:47<12:05,  2.56s/it] 74%|███████▍  | 808/1090 [1:12:49<11:46,  2.50s/it] 74%|███████▍  | 809/1090 [1:12:51<11:46,  2.51s/it] 74%|███████▍  | 810/1090 [1:12:54<11:47,  2.53s/it] 74%|███████▍  | 811/1090 [1:12:57<11:46,  2.53s/it] 74%|███████▍  | 812/1090 [1:12:59<11:40,  2.52s/it] 75%|███████▍  | 813/1090 [1:13:02<11:35,  2.51s/it] 75%|███████▍  | 814/1090 [1:13:04<11:31,  2.51s/it] 75%|███████▍  | 815/1090 [1:13:06<11:21,  2.48s/it] 75%|███████▍  | 816/1090 [1:13:09<11:22,  2.49s/it] 75%|███████▍  | 817/1090 [1:13:12<11:22,  2.50s/it] 75%|███████▌  | 818/1090 [1:13:14<11:33,  2.55s/it] 75%|███████▌  | 819/1090 [1:13:17<11:11,  2.48s/it] 75%|███████▌  | 820/1090 [1:13:19<11:16,  2.51s/it] 75%|███████▌  | 821/1090 [1:13:22<11:23,  2.54s/it] 75%|███████▌  | 822/1090 [1:13:24<11:33,  2.59s/it] 76%|███████▌  | 823/1090 [1:13:27<11:33,  2.60s/it] 76%|███████▌  | 824/1090 [1:13:30<11:41,  2.64s/it] 76%|███████▌  | 825/1090 [1:13:32<11:44,  2.66s/it] 76%|███████▌  | 826/1090 [1:13:35<11:19,  2.57s/it] 76%|███████▌  | 827/1090 [1:13:38<11:37,  2.65s/it] 76%|███████▌  | 828/1090 [1:13:40<11:15,  2.58s/it] 76%|███████▌  | 829/1090 [1:13:43<11:13,  2.58s/it] 76%|███████▌  | 830/1090 [1:13:45<11:03,  2.55s/it] 76%|███████▌  | 831/1090 [1:13:48<11:01,  2.55s/it] 76%|███████▋  | 832/1090 [1:13:50<11:12,  2.61s/it] 76%|███████▋  | 833/1090 [1:13:53<10:50,  2.53s/it] 77%|███████▋  | 834/1090 [1:13:55<10:45,  2.52s/it] 77%|███████▋  | 835/1090 [1:13:58<10:53,  2.56s/it] 77%|███████▋  | 836/1090 [1:14:01<10:57,  2.59s/it] 77%|███████▋  | 837/1090 [1:14:03<10:49,  2.57s/it] 77%|███████▋  | 838/1090 [1:14:06<10:41,  2.55s/it] 77%|███████▋  | 839/1090 [1:14:08<10:52,  2.60s/it] 77%|███████▋  | 840/1090 [1:14:11<11:04,  2.66s/it] 77%|███████▋  | 841/1090 [1:14:14<10:56,  2.64s/it] 77%|███████▋  | 842/1090 [1:14:16<10:55,  2.64s/it] 77%|███████▋  | 843/1090 [1:14:19<10:51,  2.64s/it] 77%|███████▋  | 844/1090 [1:14:21<10:31,  2.57s/it] 78%|███████▊  | 845/1090 [1:14:24<10:31,  2.58s/it] 78%|███████▊  | 846/1090 [1:14:27<10:25,  2.56s/it] 78%|███████▊  | 847/1090 [1:14:29<10:28,  2.59s/it] 78%|███████▊  | 848/1090 [1:14:32<10:19,  2.56s/it] 78%|███████▊  | 849/1090 [1:14:34<10:28,  2.61s/it] 78%|███████▊  | 850/1090 [1:14:37<10:23,  2.60s/it] 78%|███████▊  | 851/1090 [1:14:40<10:21,  2.60s/it] 78%|███████▊  | 852/1090 [1:14:42<10:21,  2.61s/it] 78%|███████▊  | 853/1090 [1:14:45<10:08,  2.57s/it] 78%|███████▊  | 854/1090 [1:14:47<10:08,  2.58s/it] 78%|███████▊  | 855/1090 [1:14:50<10:06,  2.58s/it] 79%|███████▊  | 856/1090 [1:14:52<10:01,  2.57s/it] 79%|███████▊  | 857/1090 [1:14:55<10:09,  2.61s/it] 79%|███████▊  | 858/1090 [1:14:58<10:06,  2.61s/it] 79%|███████▉  | 859/1090 [1:15:00<10:00,  2.60s/it] 79%|███████▉  | 860/1090 [1:15:03<09:58,  2.60s/it] 79%|███████▉  | 861/1090 [1:15:06<09:57,  2.61s/it] 79%|███████▉  | 862/1090 [1:15:08<09:49,  2.59s/it] 79%|███████▉  | 863/1090 [1:15:11<09:46,  2.59s/it] 79%|███████▉  | 864/1090 [1:15:13<09:55,  2.64s/it] 79%|███████▉  | 865/1090 [1:15:16<09:46,  2.61s/it] 79%|███████▉  | 866/1090 [1:15:19<09:45,  2.61s/it] 80%|███████▉  | 867/1090 [1:15:21<09:39,  2.60s/it] 80%|███████▉  | 868/1090 [1:15:24<09:34,  2.59s/it] 80%|███████▉  | 869/1090 [1:15:26<09:24,  2.55s/it] 80%|███████▉  | 870/1090 [1:15:29<09:25,  2.57s/it] 80%|███████▉  | 871/1090 [1:15:31<09:15,  2.54s/it] 80%|████████  | 872/1090 [1:15:34<09:15,  2.55s/it] 80%|████████  | 873/1090 [1:15:37<09:28,  2.62s/it] 80%|████████  | 874/1090 [1:15:39<09:39,  2.68s/it] 80%|████████  | 875/1090 [1:15:42<09:38,  2.69s/it] 80%|████████  | 876/1090 [1:15:45<09:25,  2.64s/it] 80%|████████  | 877/1090 [1:15:47<09:21,  2.64s/it] 81%|████████  | 878/1090 [1:15:50<09:19,  2.64s/it] 81%|████████  | 879/1090 [1:15:53<09:19,  2.65s/it] 81%|████████  | 880/1090 [1:15:55<09:07,  2.61s/it] 81%|████████  | 881/1090 [1:15:58<09:07,  2.62s/it] 81%|████████  | 882/1090 [1:16:00<08:59,  2.59s/it] 81%|████████  | 883/1090 [1:16:03<09:05,  2.63s/it] 81%|████████  | 884/1090 [1:16:06<09:05,  2.65s/it] 81%|████████  | 885/1090 [1:16:08<08:54,  2.61s/it] 81%|████████▏ | 886/1090 [1:16:11<08:52,  2.61s/it] 81%|████████▏ | 887/1090 [1:16:13<08:49,  2.61s/it] 81%|████████▏ | 888/1090 [1:16:16<08:46,  2.60s/it] 82%|████████▏ | 889/1090 [1:16:19<08:41,  2.59s/it] 82%|████████▏ | 890/1090 [1:16:21<08:34,  2.57s/it] 82%|████████▏ | 891/1090 [1:16:24<08:33,  2.58s/it] 82%|████████▏ | 892/1090 [1:16:26<08:28,  2.57s/it] 82%|████████▏ | 893/1090 [1:16:29<08:30,  2.59s/it] 82%|████████▏ | 894/1090 [1:16:32<08:33,  2.62s/it] 82%|████████▏ | 895/1090 [1:16:34<08:21,  2.57s/it] 82%|████████▏ | 896/1090 [1:16:37<08:27,  2.62s/it] 82%|████████▏ | 897/1090 [1:16:39<08:26,  2.62s/it] 82%|████████▏ | 898/1090 [1:16:42<08:23,  2.62s/it] 82%|████████▏ | 899/1090 [1:16:45<08:21,  2.63s/it] 83%|████████▎ | 900/1090 [1:16:47<08:15,  2.61s/it] 83%|████████▎ | 901/1090 [1:16:50<08:08,  2.58s/it] 83%|████████▎ | 902/1090 [1:16:52<08:06,  2.59s/it] 83%|████████▎ | 903/1090 [1:16:55<08:10,  2.62s/it] 83%|████████▎ | 904/1090 [1:16:58<08:06,  2.61s/it] 83%|████████▎ | 905/1090 [1:17:00<08:03,  2.61s/it] 83%|████████▎ | 906/1090 [1:17:03<07:57,  2.59s/it] 83%|████████▎ | 907/1090 [1:17:06<08:00,  2.62s/it] 83%|████████▎ | 908/1090 [1:17:08<08:00,  2.64s/it] 83%|████████▎ | 909/1090 [1:17:11<07:49,  2.60s/it] 83%|████████▎ | 910/1090 [1:17:13<07:45,  2.59s/it] 84%|████████▎ | 911/1090 [1:17:16<07:38,  2.56s/it] 84%|████████▎ | 912/1090 [1:17:18<07:41,  2.60s/it] 84%|████████▍ | 913/1090 [1:17:21<07:41,  2.61s/it] 84%|████████▍ | 914/1090 [1:17:24<07:42,  2.63s/it] 84%|████████▍ | 915/1090 [1:17:26<07:39,  2.63s/it] 84%|████████▍ | 916/1090 [1:17:29<07:34,  2.61s/it] 84%|████████▍ | 917/1090 [1:17:32<07:37,  2.64s/it] 84%|████████▍ | 918/1090 [1:17:34<07:45,  2.70s/it] 84%|████████▍ | 919/1090 [1:17:37<07:44,  2.72s/it] 84%|████████▍ | 920/1090 [1:17:40<07:36,  2.68s/it] 84%|████████▍ | 921/1090 [1:17:42<07:27,  2.65s/it] 85%|████████▍ | 922/1090 [1:17:45<07:16,  2.60s/it] 85%|████████▍ | 923/1090 [1:17:48<07:17,  2.62s/it] 85%|████████▍ | 924/1090 [1:17:50<07:13,  2.61s/it] 85%|████████▍ | 925/1090 [1:17:53<07:09,  2.60s/it] 85%|████████▍ | 926/1090 [1:17:55<07:03,  2.58s/it] 85%|████████▌ | 927/1090 [1:17:58<07:04,  2.60s/it] 85%|████████▌ | 928/1090 [1:18:01<07:06,  2.63s/it] 85%|████████▌ | 929/1090 [1:18:03<06:57,  2.59s/it] 85%|████████▌ | 930/1090 [1:18:06<06:58,  2.62s/it] 85%|████████▌ | 931/1090 [1:18:09<07:03,  2.67s/it] 86%|████████▌ | 932/1090 [1:18:11<07:03,  2.68s/it] 86%|████████▌ | 933/1090 [1:18:14<06:52,  2.63s/it] 86%|████████▌ | 934/1090 [1:18:16<06:46,  2.60s/it] 86%|████████▌ | 935/1090 [1:18:19<06:44,  2.61s/it] 86%|████████▌ | 936/1090 [1:18:21<06:37,  2.58s/it] 86%|████████▌ | 937/1090 [1:18:24<06:29,  2.55s/it] 86%|████████▌ | 938/1090 [1:18:27<06:50,  2.70s/it] 86%|████████▌ | 939/1090 [1:18:30<06:47,  2.70s/it] 86%|████████▌ | 940/1090 [1:18:32<06:38,  2.65s/it] 86%|████████▋ | 941/1090 [1:18:35<06:33,  2.64s/it] 86%|████████▋ | 942/1090 [1:18:37<06:23,  2.59s/it] 87%|████████▋ | 943/1090 [1:18:40<06:24,  2.61s/it] 87%|████████▋ | 944/1090 [1:18:42<06:17,  2.58s/it] 87%|████████▋ | 945/1090 [1:18:45<06:20,  2.62s/it] 87%|████████▋ | 946/1090 [1:18:48<06:19,  2.64s/it] 87%|████████▋ | 947/1090 [1:18:50<06:09,  2.59s/it] 87%|████████▋ | 948/1090 [1:18:53<06:03,  2.56s/it] 87%|████████▋ | 949/1090 [1:18:55<05:58,  2.54s/it] 87%|████████▋ | 950/1090 [1:18:58<05:56,  2.54s/it] 87%|████████▋ | 951/1090 [1:19:01<05:58,  2.58s/it] 87%|████████▋ | 952/1090 [1:19:03<06:01,  2.62s/it] 87%|████████▋ | 953/1090 [1:19:06<05:58,  2.62s/it] 88%|████████▊ | 954/1090 [1:19:09<05:56,  2.62s/it] 88%|████████▊ | 955/1090 [1:19:11<05:47,  2.57s/it] 88%|████████▊ | 956/1090 [1:19:14<05:46,  2.58s/it] 88%|████████▊ | 957/1090 [1:19:16<05:46,  2.61s/it] 88%|████████▊ | 958/1090 [1:19:19<05:46,  2.62s/it] 88%|████████▊ | 959/1090 [1:19:21<05:39,  2.59s/it] 88%|████████▊ | 960/1090 [1:19:24<05:41,  2.62s/it] 88%|████████▊ | 961/1090 [1:19:27<05:34,  2.59s/it] 88%|████████▊ | 962/1090 [1:19:29<05:28,  2.57s/it] 88%|████████▊ | 963/1090 [1:19:32<05:27,  2.58s/it] 88%|████████▊ | 964/1090 [1:19:34<05:25,  2.58s/it] 89%|████████▊ | 965/1090 [1:19:37<05:21,  2.57s/it] 89%|████████▊ | 966/1090 [1:19:39<05:16,  2.56s/it] 89%|████████▊ | 967/1090 [1:19:42<05:19,  2.60s/it] 89%|████████▉ | 968/1090 [1:19:45<05:17,  2.60s/it] 89%|████████▉ | 969/1090 [1:19:47<05:15,  2.60s/it] 89%|████████▉ | 970/1090 [1:19:50<05:13,  2.61s/it] 89%|████████▉ | 971/1090 [1:19:52<05:06,  2.58s/it] 89%|████████▉ | 972/1090 [1:19:55<05:02,  2.56s/it] 89%|████████▉ | 973/1090 [1:19:58<05:05,  2.61s/it] 89%|████████▉ | 974/1090 [1:20:00<05:08,  2.66s/it] 89%|████████▉ | 975/1090 [1:20:03<05:10,  2.70s/it] 90%|████████▉ | 976/1090 [1:20:06<05:01,  2.64s/it] 90%|████████▉ | 977/1090 [1:20:08<04:54,  2.60s/it] 90%|████████▉ | 978/1090 [1:20:11<04:52,  2.61s/it] 90%|████████▉ | 979/1090 [1:20:14<04:55,  2.67s/it] 90%|████████▉ | 980/1090 [1:20:16<04:51,  2.65s/it] 90%|█████████ | 981/1090 [1:20:19<04:47,  2.64s/it] 90%|█████████ | 982/1090 [1:20:21<04:41,  2.61s/it] 90%|█████████ | 983/1090 [1:20:24<04:40,  2.62s/it] 90%|█████████ | 984/1090 [1:20:27<04:35,  2.60s/it] 90%|█████████ | 985/1090 [1:20:29<04:33,  2.61s/it] 90%|█████████ | 986/1090 [1:20:32<04:28,  2.58s/it] 91%|█████████ | 987/1090 [1:20:34<04:26,  2.59s/it] 91%|█████████ | 988/1090 [1:20:37<04:24,  2.59s/it] 91%|█████████ | 989/1090 [1:20:40<04:22,  2.60s/it] 91%|█████████ | 990/1090 [1:20:42<04:17,  2.57s/it] 91%|█████████ | 991/1090 [1:20:45<04:12,  2.55s/it] 91%|█████████ | 992/1090 [1:20:47<04:12,  2.57s/it] 91%|█████████ | 993/1090 [1:20:50<04:05,  2.53s/it] 91%|█████████ | 994/1090 [1:20:52<04:05,  2.56s/it] 91%|█████████▏| 995/1090 [1:20:55<04:00,  2.53s/it] 91%|█████████▏| 996/1090 [1:20:58<04:05,  2.61s/it] 91%|█████████▏| 997/1090 [1:21:00<04:00,  2.58s/it] 92%|█████████▏| 998/1090 [1:21:03<03:59,  2.60s/it] 92%|█████████▏| 999/1090 [1:21:05<03:55,  2.59s/it] 92%|█████████▏| 1000/1090 [1:21:08<03:57,  2.64s/it]                                                     {'loss': 0.466, 'learning_rate': 4.128440366972477e-06, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:21:08<03:57,  2.64s/it]
  0%|          | 0/93 [00:00<?, ?it/s][A
  2%|▏         | 2/93 [00:24<18:36, 12.27s/it][A
  3%|▎         | 3/93 [00:49<26:13, 17.49s/it][A
  4%|▍         | 4/93 [01:09<27:41, 18.66s/it][A
  5%|▌         | 5/93 [01:35<31:03, 21.18s/it][A
  6%|▋         | 6/93 [02:00<32:23, 22.34s/it][A
  8%|▊         | 7/93 [02:26<33:39, 23.48s/it][A
  9%|▊         | 8/93 [02:50<33:23, 23.57s/it][A
 10%|▉         | 9/93 [03:12<32:29, 23.21s/it][A
 11%|█         | 10/93 [03:36<32:26, 23.45s/it][A
 12%|█▏        | 11/93 [04:00<32:20, 23.67s/it][A
 13%|█▎        | 12/93 [04:24<32:00, 23.71s/it][A
 14%|█▍        | 13/93 [04:49<31:55, 23.94s/it][A
 15%|█▌        | 14/93 [05:14<32:18, 24.54s/it][A
 16%|█▌        | 15/93 [05:36<30:46, 23.68s/it][A
 17%|█▋        | 16/93 [05:55<28:25, 22.14s/it][A
 18%|█▊        | 17/93 [06:15<27:26, 21.66s/it][A
 19%|█▉        | 18/93 [06:41<28:44, 22.99s/it][A
 20%|██        | 19/93 [07:07<29:17, 23.75s/it][A
 22%|██▏       | 20/93 [07:31<29:10, 23.98s/it][A
 23%|██▎       | 21/93 [07:56<28:50, 24.04s/it][A
 24%|██▎       | 22/93 [08:19<28:21, 23.96s/it][A
 25%|██▍       | 23/93 [08:45<28:37, 24.54s/it][A
 26%|██▌       | 24/93 [09:08<27:32, 23.95s/it][A
 27%|██▋       | 25/93 [09:32<27:12, 24.01s/it][A
 28%|██▊       | 26/93 [09:58<27:25, 24.56s/it][A
 29%|██▉       | 27/93 [10:23<27:08, 24.68s/it][A
 30%|███       | 28/93 [10:49<27:07, 25.04s/it][A
 31%|███       | 29/93 [11:15<27:00, 25.32s/it][A
 32%|███▏      | 30/93 [11:39<26:24, 25.15s/it][A
 33%|███▎      | 31/93 [12:05<26:15, 25.41s/it][A
 34%|███▍      | 32/93 [12:29<25:19, 24.91s/it][A
 35%|███▌      | 33/93 [12:53<24:29, 24.49s/it][A
 37%|███▋      | 34/93 [13:19<24:29, 24.91s/it][A
 38%|███▊      | 35/93 [13:45<24:25, 25.27s/it][A
 39%|███▊      | 36/93 [14:10<23:56, 25.21s/it][A
 40%|███▉      | 37/93 [14:33<23:05, 24.74s/it][A
 41%|████      | 38/93 [14:59<23:01, 25.11s/it][A
 42%|████▏     | 39/93 [15:24<22:33, 25.07s/it][A
 43%|████▎     | 40/93 [15:50<22:23, 25.34s/it][A
 44%|████▍     | 41/93 [16:16<22:06, 25.52s/it][A
 45%|████▌     | 42/93 [16:40<21:21, 25.12s/it][A
 46%|████▌     | 43/93 [17:04<20:38, 24.77s/it][A
 47%|████▋     | 44/93 [17:30<20:21, 24.93s/it][A
 48%|████▊     | 45/93 [17:56<20:10, 25.22s/it][A
 49%|████▉     | 46/93 [18:21<19:49, 25.31s/it][A
 51%|█████     | 47/93 [18:45<19:09, 24.98s/it][A
 52%|█████▏    | 48/93 [19:11<18:57, 25.28s/it][A
 53%|█████▎    | 49/93 [19:37<18:39, 25.45s/it][A
 54%|█████▍    | 50/93 [19:57<17:05, 23.85s/it][A
 55%|█████▍    | 51/93 [20:21<16:40, 23.83s/it][A
 56%|█████▌    | 52/93 [20:47<16:42, 24.45s/it][A
 57%|█████▋    | 53/93 [21:09<15:49, 23.73s/it][A
 58%|█████▊    | 54/93 [21:35<15:50, 24.37s/it][A
 59%|█████▉    | 55/93 [21:59<15:27, 24.41s/it][A
 60%|██████    | 56/93 [22:25<15:19, 24.85s/it][A
 61%|██████▏   | 57/93 [22:49<14:44, 24.58s/it][A
 62%|██████▏   | 58/93 [23:13<14:15, 24.45s/it][A
 63%|██████▎   | 59/93 [23:37<13:44, 24.24s/it][A
 65%|██████▍   | 60/93 [24:02<13:23, 24.34s/it][A
 66%|██████▌   | 61/93 [24:24<12:44, 23.88s/it][A
 67%|██████▋   | 62/93 [24:48<12:19, 23.84s/it][A
 68%|██████▊   | 63/93 [25:13<12:03, 24.12s/it][A
 69%|██████▉   | 64/93 [25:38<11:47, 24.39s/it][A
 70%|██████▉   | 65/93 [26:00<11:02, 23.68s/it][A
 71%|███████   | 66/93 [26:25<10:46, 23.95s/it][A
 72%|███████▏  | 67/93 [26:50<10:33, 24.36s/it][A
 73%|███████▎  | 68/93 [27:16<10:20, 24.82s/it][A
 74%|███████▍  | 69/93 [27:42<10:03, 25.13s/it][A
 75%|███████▌  | 70/93 [28:08<09:43, 25.38s/it][A
 76%|███████▋  | 71/93 [28:32<09:09, 24.96s/it][A
 77%|███████▋  | 72/93 [28:54<08:31, 24.34s/it][A
 78%|███████▊  | 73/93 [29:19<08:05, 24.26s/it][A
 80%|███████▉  | 74/93 [29:43<07:42, 24.34s/it][A
 81%|████████  | 75/93 [30:08<07:19, 24.39s/it][A
 82%|████████▏ | 76/93 [30:31<06:51, 24.22s/it][A
 83%|████████▎ | 77/93 [30:57<06:35, 24.72s/it][A
 84%|████████▍ | 78/93 [31:23<06:16, 25.09s/it][A
 85%|████████▍ | 79/93 [31:48<05:49, 24.94s/it][A
 86%|████████▌ | 80/93 [32:07<05:01, 23.19s/it][A
 87%|████████▋ | 81/93 [32:31<04:41, 23.46s/it][A
 88%|████████▊ | 82/93 [32:57<04:26, 24.23s/it][A
 89%|████████▉ | 83/93 [33:23<04:07, 24.76s/it][A
 90%|█████████ | 84/93 [33:48<03:44, 24.94s/it][A
 91%|█████████▏| 85/93 [34:11<03:13, 24.18s/it][A
 92%|█████████▏| 86/93 [34:35<02:49, 24.25s/it][A
 94%|█████████▎| 87/93 [34:59<02:24, 24.10s/it][A
 95%|█████████▍| 88/93 [35:21<01:58, 23.60s/it][A
 96%|█████████▌| 89/93 [35:46<01:35, 23.78s/it][A
 97%|█████████▋| 90/93 [36:12<01:13, 24.42s/it][A
 98%|█████████▊| 91/93 [36:35<00:48, 24.06s/it][A
 99%|█████████▉| 92/93 [36:58<00:23, 23.94s/it][A
100%|██████████| 93/93 [37:20<00:00, 23.31s/it][A                                                     
                                               [A{'eval_loss': 1.404759407043457, 'eval_rouge1': 39.3195, 'eval_rouge2': 17.7219, 'eval_rougeL': 28.4025, 'eval_rougeLsum': 36.9879, 'eval_gen_len': 64.5638440860215, 'eval_runtime': 2280.5125, 'eval_samples_per_second': 1.315, 'eval_steps_per_second': 0.041, 'eval_block_avg': 17.905383598783917, 'epoch': 4.59}
 92%|█████████▏| 1000/1090 [1:59:09<03:57,  2.64s/it]
100%|██████████| 93/93 [37:36<00:00, 23.31s/it][A
                                               [A[INFO|trainer.py:2868] 2024-05-24 12:19:55,288 >> Saving model checkpoint to src/save/cnndm_t5_large/checkpoint-1000
[INFO|configuration_utils.py:457] 2024-05-24 12:19:55,289 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/config.json
[INFO|configuration_utils.py:362] 2024-05-24 12:19:55,289 >> Configuration saved in src/save/cnndm_t5_large/checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 12:19:57,443 >> Model weights saved in src/save/cnndm_t5_large/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 12:19:57,444 >> tokenizer config file saved in src/save/cnndm_t5_large/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 12:19:57,444 >> Special tokens file saved in src/save/cnndm_t5_large/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 12:19:57,476 >> Copy vocab file to src/save/cnndm_t5_large/checkpoint-1000/spiece.model
 92%|█████████▏| 1001/1090 [1:59:13<16:59:43, 687.45s/it] 92%|█████████▏| 1002/1090 [1:59:16<11:46:58, 482.02s/it] 92%|█████████▏| 1003/1090 [1:59:19<8:10:26, 338.24s/it]  92%|█████████▏| 1004/1090 [1:59:22<5:40:30, 237.56s/it] 92%|█████████▏| 1005/1090 [1:59:24<3:56:42, 167.09s/it] 92%|█████████▏| 1006/1090 [1:59:27<2:44:51, 117.75s/it] 92%|█████████▏| 1007/1090 [1:59:29<1:55:06, 83.21s/it]  92%|█████████▏| 1008/1090 [1:59:32<1:20:39, 59.02s/it] 93%|█████████▎| 1009/1090 [1:59:35<56:50, 42.11s/it]   93%|█████████▎| 1010/1090 [1:59:37<40:21, 30.26s/it] 93%|█████████▎| 1011/1090 [1:59:40<28:50, 21.91s/it] 93%|█████████▎| 1012/1090 [1:59:42<20:57, 16.12s/it] 93%|█████████▎| 1013/1090 [1:59:45<15:22, 11.98s/it] 93%|█████████▎| 1014/1090 [1:59:47<11:41,  9.23s/it] 93%|█████████▎| 1015/1090 [1:59:50<08:59,  7.19s/it] 93%|█████████▎| 1016/1090 [1:59:52<07:08,  5.79s/it] 93%|█████████▎| 1017/1090 [1:59:55<05:50,  4.81s/it] 93%|█████████▎| 1018/1090 [1:59:58<05:01,  4.19s/it] 93%|█████████▎| 1019/1090 [2:00:00<04:23,  3.71s/it] 94%|█████████▎| 1020/1090 [2:00:03<03:57,  3.39s/it] 94%|█████████▎| 1021/1090 [2:00:05<03:35,  3.13s/it] 94%|█████████▍| 1022/1090 [2:00:08<03:23,  3.00s/it] 94%|█████████▍| 1023/1090 [2:00:11<03:15,  2.92s/it] 94%|█████████▍| 1024/1090 [2:00:13<03:04,  2.80s/it] 94%|█████████▍| 1025/1090 [2:00:16<03:06,  2.86s/it] 94%|█████████▍| 1026/1090 [2:00:19<02:59,  2.80s/it] 94%|█████████▍| 1027/1090 [2:00:22<02:52,  2.74s/it] 94%|█████████▍| 1028/1090 [2:00:24<02:49,  2.73s/it] 94%|█████████▍| 1029/1090 [2:00:27<02:42,  2.67s/it] 94%|█████████▍| 1030/1090 [2:00:29<02:34,  2.58s/it] 95%|█████████▍| 1031/1090 [2:00:32<02:33,  2.60s/it] 95%|█████████▍| 1032/1090 [2:00:35<02:34,  2.66s/it] 95%|█████████▍| 1033/1090 [2:00:37<02:27,  2.59s/it] 95%|█████████▍| 1034/1090 [2:00:40<02:25,  2.59s/it] 95%|█████████▍| 1035/1090 [2:00:42<02:20,  2.55s/it] 95%|█████████▌| 1036/1090 [2:00:45<02:18,  2.56s/it] 95%|█████████▌| 1037/1090 [2:00:47<02:15,  2.56s/it] 95%|█████████▌| 1038/1090 [2:00:50<02:12,  2.56s/it] 95%|█████████▌| 1039/1090 [2:00:53<02:12,  2.61s/it] 95%|█████████▌| 1040/1090 [2:00:55<02:13,  2.66s/it] 96%|█████████▌| 1041/1090 [2:00:58<02:09,  2.65s/it] 96%|█████████▌| 1042/1090 [2:01:01<02:07,  2.66s/it] 96%|█████████▌| 1043/1090 [2:01:03<02:04,  2.66s/it] 96%|█████████▌| 1044/1090 [2:01:06<01:59,  2.59s/it] 96%|█████████▌| 1045/1090 [2:01:08<01:55,  2.57s/it] 96%|█████████▌| 1046/1090 [2:01:11<01:52,  2.57s/it] 96%|█████████▌| 1047/1090 [2:01:13<01:50,  2.57s/it] 96%|█████████▌| 1048/1090 [2:01:16<01:47,  2.57s/it] 96%|█████████▌| 1049/1090 [2:01:19<01:45,  2.56s/it] 96%|█████████▋| 1050/1090 [2:01:21<01:42,  2.56s/it] 96%|█████████▋| 1051/1090 [2:01:24<01:41,  2.59s/it] 97%|█████████▋| 1052/1090 [2:01:26<01:38,  2.60s/it] 97%|█████████▋| 1053/1090 [2:01:29<01:35,  2.59s/it] 97%|█████████▋| 1054/1090 [2:01:31<01:31,  2.55s/it] 97%|█████████▋| 1055/1090 [2:01:34<01:29,  2.56s/it] 97%|█████████▋| 1056/1090 [2:01:36<01:25,  2.53s/it] 97%|█████████▋| 1057/1090 [2:01:39<01:24,  2.57s/it] 97%|█████████▋| 1058/1090 [2:01:42<01:21,  2.54s/it] 97%|█████████▋| 1059/1090 [2:01:45<01:23,  2.68s/it] 97%|█████████▋| 1060/1090 [2:01:47<01:18,  2.63s/it] 97%|█████████▋| 1061/1090 [2:01:50<01:17,  2.67s/it] 97%|█████████▋| 1062/1090 [2:01:52<01:14,  2.66s/it] 98%|█████████▊| 1063/1090 [2:01:55<01:11,  2.63s/it] 98%|█████████▊| 1064/1090 [2:01:57<01:06,  2.57s/it] 98%|█████████▊| 1065/1090 [2:02:00<01:04,  2.57s/it] 98%|█████████▊| 1066/1090 [2:02:03<01:03,  2.66s/it] 98%|█████████▊| 1067/1090 [2:02:05<00:59,  2.58s/it] 98%|█████████▊| 1068/1090 [2:02:08<00:56,  2.59s/it] 98%|█████████▊| 1069/1090 [2:02:11<00:55,  2.64s/it] 98%|█████████▊| 1070/1090 [2:02:13<00:53,  2.67s/it] 98%|█████████▊| 1071/1090 [2:02:16<00:48,  2.57s/it] 98%|█████████▊| 1072/1090 [2:02:18<00:45,  2.56s/it] 98%|█████████▊| 1073/1090 [2:02:21<00:43,  2.58s/it] 99%|█████████▊| 1074/1090 [2:02:23<00:41,  2.57s/it] 99%|█████████▊| 1075/1090 [2:02:26<00:38,  2.53s/it] 99%|█████████▊| 1076/1090 [2:02:29<00:35,  2.55s/it] 99%|█████████▉| 1077/1090 [2:02:31<00:33,  2.54s/it] 99%|█████████▉| 1078/1090 [2:02:34<00:30,  2.53s/it] 99%|█████████▉| 1079/1090 [2:02:36<00:28,  2.58s/it] 99%|█████████▉| 1080/1090 [2:02:39<00:26,  2.65s/it] 99%|█████████▉| 1081/1090 [2:02:41<00:23,  2.58s/it] 99%|█████████▉| 1082/1090 [2:02:44<00:20,  2.59s/it] 99%|█████████▉| 1083/1090 [2:02:47<00:18,  2.64s/it] 99%|█████████▉| 1084/1090 [2:02:49<00:15,  2.56s/it]100%|█████████▉| 1085/1090 [2:02:52<00:12,  2.58s/it]100%|█████████▉| 1086/1090 [2:02:55<00:10,  2.63s/it]100%|█████████▉| 1087/1090 [2:02:57<00:07,  2.55s/it]100%|█████████▉| 1088/1090 [2:02:59<00:05,  2.54s/it]100%|█████████▉| 1089/1090 [2:03:02<00:02,  2.56s/it]100%|██████████| 1090/1090 [2:03:05<00:00,  2.56s/it][INFO|trainer.py:2039] 2024-05-24 12:23:51,311 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2172] 2024-05-24 12:23:51,312 >> Loading best model from src/save/cnndm_t5_large/checkpoint-500 (score: 40.0724).
                                                     {'train_runtime': 7386.0239, 'train_samples_per_second': 4.739, 'train_steps_per_second': 0.148, 'train_loss': 0.48431097258121597, 'epoch': 5.0}
100%|██████████| 1090/1090 [2:03:06<00:00,  2.56s/it][INFO|trainer.py:2073] 2024-05-24 12:23:52,204 >> Deleting older checkpoint [src/save/cnndm_t5_large/checkpoint-1000] due to args.save_total_limit
100%|██████████| 1090/1090 [2:03:06<00:00,  6.78s/it]
[INFO|trainer.py:2868] 2024-05-24 12:23:52,409 >> Saving model checkpoint to src/save/cnndm_t5_large/
[INFO|configuration_utils.py:457] 2024-05-24 12:23:52,410 >> Configuration saved in src/save/cnndm_t5_large/config.json
[INFO|configuration_utils.py:362] 2024-05-24 12:23:52,410 >> Configuration saved in src/save/cnndm_t5_large/generation_config.json
[INFO|modeling_utils.py:1847] 2024-05-24 12:23:55,566 >> Model weights saved in src/save/cnndm_t5_large/pytorch_model.bin
[INFO|tokenization_utils_base.py:2171] 2024-05-24 12:23:55,567 >> tokenizer config file saved in src/save/cnndm_t5_large/tokenizer_config.json
[INFO|tokenization_utils_base.py:2178] 2024-05-24 12:23:55,567 >> Special tokens file saved in src/save/cnndm_t5_large/special_tokens_map.json
[INFO|tokenization_t5_fast.py:186] 2024-05-24 12:23:55,600 >> Copy vocab file to src/save/cnndm_t5_large/spiece.model
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4843
  train_runtime            = 2:03:06.02
  train_samples            =       7000
  train_samples_per_second =      4.739
  train_steps_per_second   =      0.148
05/24/2024 12:23:55 - INFO - __main__ - *** Evaluate ***
  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:23<18:04, 11.91s/it]  3%|▎         | 3/93 [00:48<26:02, 17.36s/it]  4%|▍         | 4/93 [01:14<30:28, 20.54s/it]  5%|▌         | 5/93 [01:40<32:53, 22.43s/it]  6%|▋         | 6/93 [02:06<34:11, 23.58s/it]  8%|▊         | 7/93 [02:32<34:51, 24.32s/it]  9%|▊         | 8/93 [02:53<33:00, 23.30s/it] 10%|▉         | 9/93 [03:18<33:10, 23.70s/it] 11%|█         | 10/93 [03:43<33:33, 24.26s/it] 12%|█▏        | 11/93 [04:08<33:22, 24.43s/it] 13%|█▎        | 12/93 [04:31<32:28, 24.05s/it] 14%|█▍        | 13/93 [04:55<31:57, 23.97s/it] 15%|█▌        | 14/93 [05:15<29:52, 22.68s/it] 16%|█▌        | 15/93 [05:36<29:10, 22.44s/it] 17%|█▋        | 16/93 [05:57<28:06, 21.90s/it] 18%|█▊        | 17/93 [06:22<28:45, 22.70s/it] 19%|█▉        | 18/93 [06:47<29:27, 23.56s/it] 20%|██        | 19/93 [07:13<29:55, 24.27s/it] 22%|██▏       | 20/93 [07:37<29:12, 24.00s/it] 23%|██▎       | 21/93 [08:01<29:03, 24.21s/it] 24%|██▎       | 22/93 [08:25<28:33, 24.13s/it] 25%|██▍       | 23/93 [08:49<28:12, 24.18s/it] 26%|██▌       | 24/93 [09:13<27:28, 23.89s/it] 27%|██▋       | 25/93 [09:36<26:54, 23.74s/it] 28%|██▊       | 26/93 [09:59<26:19, 23.58s/it] 29%|██▉       | 27/93 [10:25<26:42, 24.27s/it] 30%|███       | 28/93 [10:49<26:11, 24.18s/it] 31%|███       | 29/93 [11:15<26:19, 24.68s/it] 32%|███▏      | 30/93 [11:38<25:15, 24.06s/it] 33%|███▎      | 31/93 [12:04<25:26, 24.61s/it] 34%|███▍      | 32/93 [12:29<25:20, 24.92s/it] 35%|███▌      | 33/93 [12:53<24:29, 24.48s/it] 37%|███▋      | 34/93 [13:19<24:29, 24.90s/it] 38%|███▊      | 35/93 [13:41<23:20, 24.14s/it] 39%|███▊      | 36/93 [14:07<23:25, 24.66s/it] 40%|███▉      | 37/93 [14:30<22:33, 24.17s/it] 41%|████      | 38/93 [14:56<22:37, 24.67s/it] 42%|████▏     | 39/93 [15:20<22:03, 24.51s/it] 43%|████▎     | 40/93 [15:46<22:00, 24.92s/it] 44%|████▍     | 41/93 [16:09<21:17, 24.58s/it] 45%|████▌     | 42/93 [16:35<21:15, 25.01s/it] 46%|████▌     | 43/93 [17:01<21:03, 25.28s/it] 47%|████▋     | 44/93 [17:27<20:47, 25.46s/it] 48%|████▊     | 45/93 [17:52<20:09, 25.21s/it] 49%|████▉     | 46/93 [18:15<19:22, 24.73s/it] 51%|█████     | 47/93 [18:41<19:02, 24.84s/it] 52%|█████▏    | 48/93 [19:05<18:27, 24.62s/it] 53%|█████▎    | 49/93 [19:31<18:20, 25.02s/it] 54%|█████▍    | 50/93 [19:52<17:05, 23.85s/it] 55%|█████▍    | 51/93 [20:18<17:09, 24.51s/it] 56%|█████▌    | 52/93 [20:44<17:04, 24.98s/it] 57%|█████▋    | 53/93 [21:10<16:51, 25.29s/it] 58%|█████▊    | 54/93 [21:36<16:34, 25.49s/it] 59%|█████▉    | 55/93 [22:00<15:50, 25.00s/it] 60%|██████    | 56/93 [22:24<15:12, 24.67s/it] 61%|██████▏   | 57/93 [22:49<14:54, 24.84s/it] 62%|██████▏   | 58/93 [23:12<14:14, 24.42s/it] 63%|██████▎   | 59/93 [23:33<13:08, 23.20s/it] 65%|██████▍   | 60/93 [23:57<13:00, 23.65s/it] 66%|██████▌   | 61/93 [24:22<12:42, 23.82s/it] 67%|██████▋   | 62/93 [24:47<12:34, 24.33s/it] 68%|██████▊   | 63/93 [25:09<11:44, 23.47s/it] 69%|██████▉   | 64/93 [25:35<11:42, 24.23s/it] 70%|██████▉   | 65/93 [25:55<10:50, 23.24s/it] 71%|███████   | 66/93 [26:16<10:08, 22.53s/it] 72%|███████▏  | 67/93 [26:42<10:11, 23.50s/it] 73%|███████▎  | 68/93 [27:04<09:35, 23.01s/it] 74%|███████▍  | 69/93 [27:29<09:28, 23.69s/it] 75%|███████▌  | 70/93 [27:54<09:09, 23.89s/it] 76%|███████▋  | 71/93 [28:15<08:26, 23.01s/it] 77%|███████▋  | 72/93 [28:41<08:22, 23.93s/it] 78%|███████▊  | 73/93 [29:06<08:09, 24.47s/it] 80%|███████▉  | 74/93 [29:32<07:50, 24.74s/it] 81%|████████  | 75/93 [29:58<07:31, 25.10s/it] 82%|████████▏ | 76/93 [30:18<06:42, 23.68s/it] 83%|████████▎ | 77/93 [30:44<06:29, 24.37s/it] 84%|████████▍ | 78/93 [31:09<06:09, 24.66s/it] 85%|████████▍ | 79/93 [31:35<05:50, 25.03s/it] 86%|████████▌ | 80/93 [31:55<05:04, 23.39s/it] 87%|████████▋ | 81/93 [32:19<04:42, 23.50s/it] 88%|████████▊ | 82/93 [32:43<04:21, 23.77s/it] 89%|████████▉ | 83/93 [33:03<03:46, 22.66s/it] 90%|█████████ | 84/93 [33:29<03:32, 23.64s/it] 91%|█████████▏| 85/93 [33:49<03:01, 22.70s/it] 92%|█████████▏| 86/93 [34:15<02:45, 23.69s/it] 94%|█████████▎| 87/93 [34:41<02:26, 24.35s/it] 95%|█████████▍| 88/93 [35:07<02:04, 24.81s/it] 96%|█████████▌| 89/93 [35:33<01:40, 25.15s/it] 97%|█████████▋| 90/93 [35:59<01:16, 25.40s/it] 98%|█████████▊| 91/93 [36:21<00:48, 24.45s/it] 99%|█████████▉| 92/93 [36:43<00:23, 23.49s/it]100%|██████████| 93/93 [37:03<00:00, 22.55s/it]100%|██████████| 93/93 [37:19<00:00, 24.08s/it]
***** eval metrics *****
  epoch                   =        5.0
  eval_block_avg          =    17.9841
  eval_gen_len            =    65.8364
  eval_loss               =     1.4048
  eval_rouge1             =    42.5955
  eval_rouge2             =    20.3095
  eval_rougeL             =    30.8883
  eval_rougeLsum          =    40.0724
  eval_runtime            = 0:37:45.81
  eval_samples            =       3000
  eval_samples_per_second =      1.324
  eval_steps_per_second   =      0.041
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 13:01:51 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 13:01:51 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_13-01-50_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 13:01:57 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:01:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 13:01:57 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:01:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 13:01:57,351 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:01:57,352 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 13:01:57,472 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 13:01:57,595 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:01:57,597 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:01:57,833 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:01:57,834 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:01:57,834 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:01:57,834 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:01:57,834 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 13:01:57,834 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:01:57,836 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 13:01:57,889 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 13:01:59,137 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 13:02:25,499 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[INFO|modeling_utils.py:3198] 2024-05-24 13:02:25,500 >> All the weights of EffT5ForConditionalGeneration were initialized from the model checkpoint at checkpoints/CNNDM.
If your task is similar to the task the model of the checkpoint was trained on, you can already use EffT5ForConditionalGeneration for predictions without further training.
[INFO|modeling_utils.py:2839] 2024-05-24 13:02:25,507 >> Generation config file not found, using a generation config created from the model config.
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 13:02:25 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:02:25 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:02:27 - INFO - __main__ - *** Evaluate ***
[WARNING|logging.py:280] 2024-05-24 13:02:27,180 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[INFO|configuration_utils.py:575] 2024-05-24 13:02:27,189 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:06<05:01,  3.31s/it]  3%|▎         | 3/93 [00:25<14:52,  9.92s/it]  4%|▍         | 4/93 [00:35<14:31,  9.79s/it]  5%|▌         | 5/93 [00:59<21:32, 14.69s/it]  6%|▋         | 6/93 [01:08<18:51, 13.01s/it]  8%|▊         | 7/93 [01:21<18:31, 12.92s/it]  9%|▊         | 8/93 [01:29<16:05, 11.36s/it] 10%|▉         | 9/93 [01:40<15:49, 11.31s/it] 11%|█         | 10/93 [01:46<13:08,  9.50s/it] 12%|█▏        | 11/93 [02:10<18:58, 13.88s/it] 13%|█▎        | 12/93 [02:21<17:45, 13.16s/it] 14%|█▍        | 13/93 [02:34<17:28, 13.10s/it] 15%|█▌        | 14/93 [02:57<21:10, 16.08s/it] 16%|█▌        | 15/93 [03:09<19:22, 14.90s/it] 17%|█▋        | 16/93 [03:25<19:30, 15.20s/it] 18%|█▊        | 17/93 [03:38<18:31, 14.62s/it] 19%|█▉        | 18/93 [03:47<16:02, 12.84s/it] 20%|██        | 19/93 [04:01<16:21, 13.27s/it] 22%|██▏       | 20/93 [04:12<15:17, 12.57s/it] 23%|██▎       | 21/93 [04:25<15:10, 12.64s/it] 24%|██▎       | 22/93 [04:37<14:36, 12.34s/it] 25%|██▍       | 23/93 [04:47<13:46, 11.80s/it] 26%|██▌       | 24/93 [04:56<12:29, 10.86s/it] 27%|██▋       | 25/93 [05:05<11:32, 10.19s/it] 28%|██▊       | 26/93 [05:14<11:16, 10.09s/it] 29%|██▉       | 27/93 [05:34<14:17, 12.99s/it] 30%|███       | 28/93 [05:44<13:08, 12.13s/it] 31%|███       | 29/93 [05:56<12:51, 12.05s/it] 32%|███▏      | 30/93 [06:09<12:46, 12.17s/it] 33%|███▎      | 31/93 [06:24<13:44, 13.29s/it] 34%|███▍      | 32/93 [06:36<12:56, 12.73s/it] 35%|███▌      | 33/93 [06:46<11:55, 11.92s/it] 37%|███▋      | 34/93 [06:54<10:34, 10.76s/it] 38%|███▊      | 35/93 [07:08<11:14, 11.62s/it] 39%|███▊      | 36/93 [07:14<09:39, 10.16s/it] 40%|███▉      | 37/93 [07:28<10:26, 11.18s/it] 41%|████      | 38/93 [07:36<09:21, 10.21s/it] 42%|████▏     | 39/93 [07:47<09:20, 10.39s/it] 43%|████▎     | 40/93 [07:55<08:41,  9.83s/it] 44%|████▍     | 41/93 [08:04<08:20,  9.62s/it] 45%|████▌     | 42/93 [08:21<09:54, 11.65s/it] 46%|████▌     | 43/93 [08:30<09:06, 10.92s/it] 47%|████▋     | 44/93 [08:40<08:41, 10.64s/it] 48%|████▊     | 45/93 [08:55<09:38, 12.05s/it] 49%|████▉     | 46/93 [09:06<09:09, 11.70s/it] 51%|█████     | 47/93 [09:18<08:58, 11.71s/it] 52%|█████▏    | 48/93 [09:27<08:16, 11.02s/it] 53%|█████▎    | 49/93 [09:44<09:16, 12.65s/it] 54%|█████▍    | 50/93 [09:56<09:02, 12.61s/it] 55%|█████▍    | 51/93 [10:08<08:37, 12.33s/it] 56%|█████▌    | 52/93 [10:27<09:45, 14.29s/it] 57%|█████▋    | 53/93 [10:35<08:18, 12.45s/it] 58%|█████▊    | 54/93 [10:46<07:53, 12.13s/it] 59%|█████▉    | 55/93 [10:54<06:50, 10.79s/it] 60%|██████    | 56/93 [11:10<07:42, 12.49s/it] 61%|██████▏   | 57/93 [11:19<06:42, 11.18s/it] 62%|██████▏   | 58/93 [11:29<06:24, 11.00s/it] 63%|██████▎   | 59/93 [11:36<05:32,  9.78s/it] 65%|██████▍   | 60/93 [11:47<05:30, 10.01s/it] 66%|██████▌   | 61/93 [11:58<05:29, 10.29s/it] 67%|██████▋   | 62/93 [12:09<05:27, 10.57s/it] 68%|██████▊   | 63/93 [12:19<05:15, 10.50s/it] 69%|██████▉   | 64/93 [12:27<04:42,  9.74s/it] 70%|██████▉   | 65/93 [12:42<05:12, 11.17s/it] 71%|███████   | 66/93 [12:53<05:03, 11.24s/it] 72%|███████▏  | 67/93 [13:01<04:25, 10.20s/it] 73%|███████▎  | 68/93 [13:21<05:27, 13.10s/it] 74%|███████▍  | 69/93 [13:31<04:56, 12.35s/it] 75%|███████▌  | 70/93 [13:45<04:51, 12.68s/it] 76%|███████▋  | 71/93 [13:54<04:13, 11.53s/it] 77%|███████▋  | 72/93 [14:13<04:48, 13.75s/it] 78%|███████▊  | 73/93 [14:19<03:52, 11.61s/it] 80%|███████▉  | 74/93 [14:32<03:46, 11.93s/it] 81%|████████  | 75/93 [14:38<03:04, 10.24s/it] 82%|████████▏ | 76/93 [14:56<03:33, 12.58s/it] 83%|████████▎ | 77/93 [15:06<03:08, 11.80s/it] 84%|████████▍ | 78/93 [15:21<03:10, 12.68s/it] 85%|████████▍ | 79/93 [15:29<02:40, 11.45s/it] 86%|████████▌ | 80/93 [15:41<02:27, 11.33s/it] 87%|████████▋ | 81/93 [16:04<03:01, 15.09s/it] 88%|████████▊ | 82/93 [16:14<02:27, 13.43s/it] 89%|████████▉ | 83/93 [16:30<02:22, 14.25s/it] 90%|█████████ | 84/93 [16:39<01:54, 12.69s/it] 91%|█████████▏| 85/93 [16:51<01:39, 12.48s/it] 92%|█████████▏| 86/93 [17:04<01:29, 12.74s/it] 94%|█████████▎| 87/93 [17:28<01:36, 16.09s/it] 95%|█████████▍| 88/93 [17:39<01:12, 14.58s/it] 96%|█████████▌| 89/93 [17:51<00:54, 13.64s/it] 97%|█████████▋| 90/93 [18:07<00:42, 14.25s/it] 98%|█████████▊| 91/93 [18:16<00:25, 12.76s/it] 99%|█████████▉| 92/93 [18:26<00:12, 12.11s/it]100%|██████████| 93/93 [18:36<00:00, 11.32s/it]100%|██████████| 93/93 [19:03<00:00, 12.29s/it]
***** eval metrics *****
  eval_block_avg          =     2.6629
  eval_gen_len            =   119.9654
  eval_loss               =     1.4048
  eval_rouge1             =    12.8757
  eval_rouge2             =     6.0649
  eval_rougeL             =    10.3285
  eval_rougeLsum          =    12.2589
  eval_runtime            = 0:19:16.37
  eval_samples            =       3000
  eval_samples_per_second =      2.594
  eval_steps_per_second   =      0.081
[INFO|modelcard.py:451] 2024-05-24 13:21:43,805 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'cnn_dailymail 3.0.0', 'type': 'cnn_dailymail', 'args': '3.0.0'}}
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 13:21:53 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 13:21:53 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_13-21-53_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 13:21:59 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:21:59 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 13:21:59 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:21:59 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 13:21:59,974 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:21:59,975 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 13:22:00,103 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 13:22:00,223 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:22:00,224 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:22:00,466 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:22:00,466 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:22:00,466 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:22:00,467 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:22:00,467 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 13:22:00,467 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:22:00,469 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 13:22:00,517 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 13:22:01,759 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 13:22:28,581 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[INFO|modeling_utils.py:3198] 2024-05-24 13:22:28,581 >> All the weights of EffT5ForConditionalGeneration were initialized from the model checkpoint at checkpoints/CNNDM.
If your task is similar to the task the model of the checkpoint was trained on, you can already use EffT5ForConditionalGeneration for predictions without further training.
[INFO|modeling_utils.py:2839] 2024-05-24 13:22:28,590 >> Generation config file not found, using a generation config created from the model config.
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 13:22:28 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:22:28 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:22:30 - INFO - __main__ - *** Evaluate ***
[WARNING|logging.py:280] 2024-05-24 13:22:30,240 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[INFO|configuration_utils.py:575] 2024-05-24 13:22:30,249 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:03<02:21,  1.55s/it]  3%|▎         | 3/93 [00:06<03:17,  2.20s/it]  4%|▍         | 4/93 [00:09<03:45,  2.54s/it]  5%|▌         | 5/93 [00:12<04:00,  2.73s/it]  6%|▋         | 6/93 [00:15<04:09,  2.86s/it]  8%|▊         | 7/93 [00:18<04:12,  2.94s/it]  9%|▊         | 8/93 [00:21<04:14,  3.00s/it] 10%|▉         | 9/93 [00:24<04:14,  3.03s/it] 11%|█         | 10/93 [00:27<04:13,  3.06s/it] 12%|█▏        | 11/93 [00:31<04:11,  3.07s/it] 13%|█▎        | 12/93 [00:34<04:09,  3.08s/it] 14%|█▍        | 13/93 [00:37<04:07,  3.09s/it] 15%|█▌        | 14/93 [00:40<04:04,  3.10s/it] 16%|█▌        | 15/93 [00:43<04:01,  3.10s/it] 17%|█▋        | 16/93 [00:46<03:58,  3.10s/it] 18%|█▊        | 17/93 [00:49<03:55,  3.10s/it] 19%|█▉        | 18/93 [00:52<03:52,  3.11s/it] 20%|██        | 19/93 [00:55<03:49,  3.11s/it] 22%|██▏       | 20/93 [00:59<03:46,  3.11s/it] 23%|██▎       | 21/93 [01:02<03:43,  3.11s/it] 24%|██▎       | 22/93 [01:05<03:40,  3.11s/it] 25%|██▍       | 23/93 [01:08<03:37,  3.11s/it] 26%|██▌       | 24/93 [01:11<03:34,  3.11s/it] 27%|██▋       | 25/93 [01:14<03:31,  3.11s/it] 28%|██▊       | 26/93 [01:17<03:28,  3.11s/it] 29%|██▉       | 27/93 [01:20<03:25,  3.11s/it] 30%|███       | 28/93 [01:23<03:22,  3.11s/it] 31%|███       | 29/93 [01:27<03:19,  3.11s/it] 32%|███▏      | 30/93 [01:30<03:16,  3.11s/it] 33%|███▎      | 31/93 [01:33<03:13,  3.12s/it] 34%|███▍      | 32/93 [01:36<03:10,  3.12s/it] 35%|███▌      | 33/93 [01:39<03:06,  3.11s/it] 37%|███▋      | 34/93 [01:42<03:03,  3.11s/it] 38%|███▊      | 35/93 [01:45<03:00,  3.11s/it] 39%|███▊      | 36/93 [01:48<02:57,  3.11s/it] 40%|███▉      | 37/93 [01:51<02:54,  3.12s/it] 41%|████      | 38/93 [01:55<02:51,  3.11s/it] 42%|████▏     | 39/93 [01:58<02:48,  3.11s/it] 43%|████▎     | 40/93 [02:01<02:44,  3.11s/it] 44%|████▍     | 41/93 [02:04<02:41,  3.11s/it] 45%|████▌     | 42/93 [02:07<02:38,  3.11s/it] 46%|████▌     | 43/93 [02:10<02:35,  3.11s/it] 47%|████▋     | 44/93 [02:13<02:32,  3.11s/it] 48%|████▊     | 45/93 [02:16<02:29,  3.11s/it] 49%|████▉     | 46/93 [02:19<02:26,  3.11s/it] 51%|█████     | 47/93 [02:23<02:23,  3.11s/it] 52%|█████▏    | 48/93 [02:26<02:20,  3.11s/it] 53%|█████▎    | 49/93 [02:29<02:16,  3.11s/it] 54%|█████▍    | 50/93 [02:32<02:13,  3.11s/it] 55%|█████▍    | 51/93 [02:35<02:10,  3.11s/it] 56%|█████▌    | 52/93 [02:38<02:07,  3.11s/it] 57%|█████▋    | 53/93 [02:41<02:04,  3.11s/it] 58%|█████▊    | 54/93 [02:44<02:01,  3.11s/it] 59%|█████▉    | 55/93 [02:47<01:58,  3.11s/it] 60%|██████    | 56/93 [02:51<01:55,  3.11s/it] 61%|██████▏   | 57/93 [02:54<01:51,  3.11s/it] 62%|██████▏   | 58/93 [02:57<01:48,  3.11s/it] 63%|██████▎   | 59/93 [03:00<01:45,  3.11s/it] 65%|██████▍   | 60/93 [03:03<01:42,  3.11s/it] 66%|██████▌   | 61/93 [03:06<01:39,  3.11s/it] 67%|██████▋   | 62/93 [03:09<01:36,  3.11s/it] 68%|██████▊   | 63/93 [03:12<01:33,  3.11s/it] 69%|██████▉   | 64/93 [03:15<01:30,  3.11s/it] 70%|██████▉   | 65/93 [03:19<01:27,  3.11s/it] 71%|███████   | 66/93 [03:22<01:24,  3.11s/it] 72%|███████▏  | 67/93 [03:25<01:20,  3.11s/it] 73%|███████▎  | 68/93 [03:28<01:17,  3.11s/it] 74%|███████▍  | 69/93 [03:31<01:14,  3.11s/it] 75%|███████▌  | 70/93 [03:34<01:11,  3.11s/it] 76%|███████▋  | 71/93 [03:37<01:08,  3.11s/it] 77%|███████▋  | 72/93 [03:40<01:05,  3.11s/it] 78%|███████▊  | 73/93 [03:43<01:02,  3.11s/it] 80%|███████▉  | 74/93 [03:47<00:59,  3.12s/it] 81%|████████  | 75/93 [03:50<00:56,  3.12s/it] 82%|████████▏ | 76/93 [03:53<00:52,  3.11s/it] 83%|████████▎ | 77/93 [03:56<00:49,  3.11s/it] 84%|████████▍ | 78/93 [03:59<00:46,  3.11s/it] 85%|████████▍ | 79/93 [04:02<00:43,  3.11s/it] 86%|████████▌ | 80/93 [04:05<00:40,  3.11s/it] 87%|████████▋ | 81/93 [04:08<00:37,  3.11s/it] 88%|████████▊ | 82/93 [04:12<00:34,  3.12s/it] 89%|████████▉ | 83/93 [04:15<00:31,  3.11s/it] 90%|█████████ | 84/93 [04:18<00:28,  3.11s/it] 91%|█████████▏| 85/93 [04:21<00:24,  3.11s/it] 92%|█████████▏| 86/93 [04:24<00:21,  3.12s/it] 94%|█████████▎| 87/93 [04:27<00:18,  3.12s/it] 95%|█████████▍| 88/93 [04:30<00:15,  3.12s/it] 96%|█████████▌| 89/93 [04:33<00:12,  3.11s/it] 97%|█████████▋| 90/93 [04:36<00:09,  3.11s/it] 98%|█████████▊| 91/93 [04:40<00:06,  3.11s/it] 99%|█████████▉| 92/93 [04:43<00:03,  3.11s/it]100%|██████████| 93/93 [04:46<00:00,  3.11s/it]100%|██████████| 93/93 [05:06<00:00,  3.30s/it]
***** eval metrics *****
  eval_block_avg          =        2.0
  eval_gen_len            =   125.4271
  eval_loss               =     1.4048
  eval_rouge1             =       3.32
  eval_rouge2             =     0.0538
  eval_rougeL             =     3.1352
  eval_rougeLsum          =     3.2698
  eval_runtime            = 0:05:10.72
  eval_samples            =       3000
  eval_samples_per_second =      9.655
  eval_steps_per_second   =      0.303
[INFO|modelcard.py:451] 2024-05-24 13:27:41,221 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'cnn_dailymail 3.0.0', 'type': 'cnn_dailymail', 'args': '3.0.0'}}
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/24/2024 13:27:50 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/24/2024 13:27:50 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=src/save/cnndm_t5_large/runs/May24_13-27-50_30153d35c293,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_hf,
optim_args=None,
output_dir=src/save/cnndm_t5_large/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=src/save/cnndm_t5_large/,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Overwrite dataset info from restored data version if exists.
05/24/2024 13:27:56 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:27:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
05/24/2024 13:27:56 - INFO - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d)
Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
05/24/2024 13:27:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d
[INFO|configuration_utils.py:666] 2024-05-24 13:27:56,254 >> loading configuration file checkpoints/CNNDM/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:27:56,255 >> Model config T5Config {
  "_name_or_path": "checkpoints/CNNDM",
  "architectures": [
    "EffT5ForConditionalGeneration"
  ],
  "copy_skipped_hidden_states": true,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "distill_alpha": null,
  "distill_layer_alpha": null,
  "distill_layer_map": "dyna",
  "distill_temp": null,
  "do_layer_distill": false,
  "do_layer_transformation": false,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "exit_conf_threshold": 1.0,
  "exit_conf_type": null,
  "exit_position_temp": null,
  "fallback_conf_threshold": 1.0,
  "fallback_conf_type": null,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "intermediate_loss_fn": "weighted_ce",
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "max_answer_length": 128,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_hidden_states_decoder": true,
  "output_past": true,
  "pad_token_id": 0,
  "parallel_gen_token": false,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "rollback_conf_threshold": null,
  "small_exit_layer": null,
  "static_exit_layer": null,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "train_meta_cm_head": false,
  "transformers_version": "4.28.1",
  "use_big_small": false,
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|tokenization_auto.py:502] 2024-05-24 13:27:56,386 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:668] 2024-05-24 13:27:56,501 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:27:56,503 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:27:56,735 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:27:56,735 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:27:56,736 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:27:56,736 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1809] 2024-05-24 13:27:56,736 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:668] 2024-05-24 13:27:56,736 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:720] 2024-05-24 13:27:56,737 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 32128
}

/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
[INFO|modeling_utils.py:2531] 2024-05-24 13:27:56,785 >> loading weights file checkpoints/CNNDM/pytorch_model.bin
[INFO|configuration_utils.py:575] 2024-05-24 13:27:58,047 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

[INFO|modeling_utils.py:3190] 2024-05-24 13:28:24,281 >> All model checkpoint weights were used when initializing EffT5ForConditionalGeneration.

[INFO|modeling_utils.py:3198] 2024-05-24 13:28:24,281 >> All the weights of EffT5ForConditionalGeneration were initialized from the model checkpoint at checkpoints/CNNDM.
If your task is similar to the task the model of the checkpoint was trained on, you can already use EffT5ForConditionalGeneration for predictions without further training.
[INFO|modeling_utils.py:2839] 2024-05-24 13:28:24,290 >> Generation config file not found, using a generation config created from the model config.
Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
05/24/2024 13:28:24 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-5ee6340f3c46ef9e.arrow
Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:28:24 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cache-aa0b8b23db4fcfd0.arrow
05/24/2024 13:28:25 - INFO - __main__ - *** Evaluate ***
[WARNING|logging.py:280] 2024-05-24 13:28:25,919 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[INFO|configuration_utils.py:575] 2024-05-24 13:28:25,928 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.28.1"
}

  0%|          | 0/93 [00:00<?, ?it/s]  2%|▏         | 2/93 [00:23<17:46, 11.72s/it]  3%|▎         | 3/93 [00:47<25:20, 16.89s/it]  4%|▍         | 4/93 [01:11<29:06, 19.63s/it]  5%|▌         | 5/93 [01:34<30:20, 20.69s/it]  6%|▋         | 6/93 [01:58<31:38, 21.82s/it]  8%|▊         | 7/93 [02:21<31:55, 22.27s/it]  9%|▊         | 8/93 [02:41<30:33, 21.57s/it] 10%|▉         | 9/93 [03:05<30:57, 22.12s/it] 11%|█         | 10/93 [03:29<31:27, 22.74s/it] 12%|█▏        | 11/93 [03:52<31:05, 22.75s/it] 13%|█▎        | 12/93 [04:16<31:18, 23.19s/it] 14%|█▍        | 13/93 [04:40<31:09, 23.37s/it] 15%|█▌        | 14/93 [05:04<31:05, 23.61s/it] 16%|█▌        | 15/93 [05:28<30:54, 23.78s/it] 17%|█▋        | 16/93 [05:51<30:10, 23.51s/it] 18%|█▊        | 17/93 [06:13<29:25, 23.24s/it] 19%|█▉        | 18/93 [06:36<28:51, 23.09s/it] 20%|██        | 19/93 [07:00<28:37, 23.21s/it] 22%|██▏       | 20/93 [07:24<28:34, 23.49s/it] 23%|██▎       | 21/93 [07:48<28:25, 23.69s/it] 24%|██▎       | 22/93 [08:12<28:07, 23.77s/it] 25%|██▍       | 23/93 [08:36<27:54, 23.91s/it] 26%|██▌       | 24/93 [09:00<27:35, 24.00s/it] 27%|██▋       | 25/93 [09:25<27:16, 24.06s/it] 28%|██▊       | 26/93 [09:48<26:41, 23.90s/it] 29%|██▉       | 27/93 [10:12<26:22, 23.98s/it] 30%|███       | 28/93 [10:36<26:03, 24.06s/it] 31%|███       | 29/93 [11:01<25:41, 24.09s/it] 32%|███▏      | 30/93 [11:25<25:19, 24.11s/it] 33%|███▎      | 31/93 [11:48<24:47, 23.99s/it] 34%|███▍      | 32/93 [12:09<23:28, 23.09s/it] 35%|███▌      | 33/93 [12:34<23:25, 23.42s/it] 37%|███▋      | 34/93 [12:58<23:15, 23.66s/it] 38%|███▊      | 35/93 [13:19<22:14, 23.02s/it] 39%|███▊      | 36/93 [13:43<21:56, 23.09s/it] 40%|███▉      | 37/93 [14:06<21:35, 23.14s/it] 41%|████      | 38/93 [14:30<21:30, 23.47s/it] 42%|████▏     | 39/93 [14:53<20:53, 23.21s/it] 43%|████▎     | 40/93 [15:16<20:28, 23.18s/it] 44%|████▍     | 41/93 [15:40<20:21, 23.49s/it] 45%|████▌     | 42/93 [15:59<18:43, 22.02s/it] 46%|████▌     | 43/93 [16:23<18:52, 22.66s/it] 47%|████▋     | 44/93 [16:45<18:26, 22.57s/it] 48%|████▊     | 45/93 [17:09<18:26, 23.05s/it] 49%|████▉     | 46/93 [17:34<18:18, 23.38s/it] 51%|█████     | 47/93 [17:56<17:39, 23.03s/it] 52%|█████▏    | 48/93 [18:18<17:12, 22.94s/it] 53%|█████▎    | 49/93 [18:42<16:52, 23.02s/it] 54%|█████▍    | 50/93 [19:03<16:05, 22.45s/it] 55%|█████▍    | 51/93 [19:27<16:03, 22.95s/it] 56%|█████▌    | 52/93 [19:51<15:55, 23.31s/it] 57%|█████▋    | 53/93 [20:15<15:42, 23.57s/it] 58%|█████▊    | 54/93 [20:39<15:26, 23.76s/it] 59%|█████▉    | 55/93 [21:04<15:07, 23.89s/it] 60%|██████    | 56/93 [21:26<14:29, 23.50s/it] 61%|██████▏   | 57/93 [21:50<14:12, 23.69s/it] 62%|██████▏   | 58/93 [22:13<13:40, 23.45s/it] 63%|██████▎   | 59/93 [22:34<12:48, 22.62s/it] 65%|██████▍   | 60/93 [22:58<12:41, 23.07s/it] 66%|██████▌   | 61/93 [23:22<12:28, 23.39s/it] 67%|██████▋   | 62/93 [23:46<12:11, 23.60s/it] 68%|██████▊   | 63/93 [24:07<11:22, 22.74s/it] 69%|██████▉   | 64/93 [24:28<10:40, 22.08s/it] 70%|██████▉   | 65/93 [24:50<10:20, 22.16s/it] 71%|███████   | 66/93 [25:12<09:55, 22.05s/it] 72%|███████▏  | 67/93 [25:36<09:49, 22.67s/it] 73%|███████▎  | 68/93 [26:00<09:34, 23.00s/it] 74%|███████▍  | 69/93 [26:24<09:18, 23.28s/it] 75%|███████▌  | 70/93 [26:48<09:01, 23.56s/it] 76%|███████▋  | 71/93 [27:12<08:42, 23.75s/it] 77%|███████▋  | 72/93 [27:34<08:07, 23.20s/it] 78%|███████▊  | 73/93 [27:56<07:37, 22.90s/it] 80%|███████▉  | 74/93 [28:17<07:04, 22.32s/it] 81%|████████  | 75/93 [28:41<06:51, 22.89s/it] 82%|████████▏ | 76/93 [29:03<06:21, 22.42s/it] 83%|████████▎ | 77/93 [29:27<06:07, 22.94s/it] 84%|████████▍ | 78/93 [29:48<05:36, 22.44s/it] 85%|████████▍ | 79/93 [30:12<05:19, 22.81s/it] 86%|████████▌ | 80/93 [30:34<04:54, 22.63s/it] 87%|████████▋ | 81/93 [30:57<04:33, 22.75s/it] 88%|████████▊ | 82/93 [31:21<04:15, 23.19s/it] 89%|████████▉ | 83/93 [31:45<03:52, 23.30s/it] 90%|█████████ | 84/93 [32:09<03:31, 23.48s/it] 91%|█████████▏| 85/93 [32:28<02:57, 22.24s/it] 92%|█████████▏| 86/93 [32:47<02:29, 21.32s/it] 94%|█████████▎| 87/93 [33:10<02:10, 21.73s/it] 95%|█████████▍| 88/93 [33:30<01:45, 21.18s/it] 96%|█████████▌| 89/93 [33:54<01:28, 22.07s/it] 97%|█████████▋| 90/93 [34:18<01:08, 22.69s/it] 98%|█████████▊| 91/93 [34:40<00:45, 22.65s/it] 99%|█████████▉| 92/93 [35:01<00:21, 21.98s/it]100%|██████████| 93/93 [35:22<00:00, 21.58s/it]100%|██████████| 93/93 [35:39<00:00, 23.00s/it]
***** eval metrics *****
  eval_block_avg          =    22.5814
  eval_gen_len            =    70.1603
  eval_loss               =     1.4048
  eval_rouge1             =    43.4379
  eval_rouge2             =    20.7069
  eval_rougeL             =    31.1691
  eval_rougeLsum          =    40.6403
  eval_runtime            = 0:36:03.89
  eval_samples            =       3000
  eval_samples_per_second =      1.386
  eval_steps_per_second   =      0.043
[INFO|modelcard.py:451] 2024-05-24 14:04:30,055 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'cnn_dailymail 3.0.0', 'type': 'cnn_dailymail', 'args': '3.0.0'}}
